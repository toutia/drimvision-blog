[
 {
    "question_id": "1",
    "question_text": "Which of the following are examples of risks that should be considered by the Technical Test\n        Analyst?\n Select 2 option(s).",
    "options": {
      "A": "A high number of reliability defects were found compared with the previous version",
      "B": "Required updates to the security testing tool database are poorly configured",
      "C": "Documentation from the legacy system to verify the accuracy of computations is lacking",
      "D": "The budget allocated to the testing on the project has been reduced",
      "E": "The change rate of business use cases is higher than expected"
    },
    "answers": [
      "A",
      "B"
    ],
    "explanation": "a) Is correct. A large number of defects relating to technical quality TTA-1.2.1 K2 1\n                              characteristics is a generic risk factor\n                            b) Is correct. Tools and technology is a generic risk factor\n                            c) Is not correct. Accuracy of the computations is a concern for the TA, not\n                              the TTA\n                            d) Is not correct. Budgetary issues should be handled by the TM, not the\n                              TTA\n                            e) Is not correct. High change rates in business use cases affect the\n                              functionality testing",
    "learning_objective": "TTA-1.2.1",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "2",
    "question_text": "When participating in a risk analysis, the Technical Test Analyst is expected to work closely with\n        which of the following sets of people?\n Select 1 option(s).",
    "options": {
      "A": "Users",
      "B": "Business analysts",
      "C": "Project sponsors",
      "D": "Developers"
    },
    "answers": [
      "D"
    ],
    "explanation": "a) Is not correct. The TA would be expected to work with users TTA-1.2.2 K2 1\n                            b) Is not correct. The TA would be expected to work with business\n                              analysts\n                            c) Is not correct. The TA would be expected to work with project sponsors\n                            d) Is correct. The TTA is expected to work with the technical stakeholders\n                              on the project, including the developers",
    "learning_objective": "TTA-1.2.2",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "3",
    "question_text": "Consider the simplified logic of a tea-making machine:                    \n                                                                                  \n           Turn on the machine                                                    \n            IF enough water THEN                                                  \n                Boil water                                                        \n                Add tea                                                           \n                Show message “milk?”                                              \n                IF milk = yes THEN                                                \n                    Show message “low fat?”                                       \n                    IF low fat = yes THEN                                         \n                       Add low fat milk                                           \n                    ELSE                                                          \n                       Add normal milk                                            \n                    ENDIF                                                         \n                ENDIF                                                             \n                Show message “sugar?”                                             \n                IF sugar = yes THEN                                               \n                    Add sugar                                                     \n                ENDIF                                                             \n                Stir                                                              \n                Wait 3 minutes                                                    \n                Show message “please take your tea”                               \n            ELSE                                                                  \n                Show message “please fill up water”                               \n            ENDIF                                                                 \n        What is the minimum number of test cases required to achieve 100% statement coverage of the\n        logic for the tea-making machine?\n Select 1 option(s).",
    "options": {
      "A": "3",
      "B": "2",
      "C": "5",
      "D": "6"
    },
    "answers": [
      "A"
    ],
    "explanation": "a) Is correct. The three test cases are defined by the following inputs: TTA-2.2.1 K3 2\n                                Enough water, low fat milk, sugar\n                                Enough water, normal milk, sugar or not sugar\n                                Not enough water\n                            b) Is not correct. With two tests, one of the paths covered by the tests of\n                              answer (a) will be missed, and the lines of code in this path will not be\n                              tested failing to achieve 100% statement coverage\n                            c) Is not correct. The question asked for the minimal number of tests to\n                              achieve 100% statement coverage. This can be achieved with 3 tests,\n                              as shown in (a)\n                            d) Is not correct. The question asked for the minimal number of tests to\n                              achieve 100% statement coverage. This can be achieved with 3 tests,\n                              as shown in (a)",
    "learning_objective": "TTA-2.2.1",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "4",
    "question_text": "The simplified logic of a program is as follows:                          \n                                                                                  \n            Statement P                                                           \n            IF A THEN                                                             \n                IF B THEN                                                         \n                    Statement Q                                                   \n                ELSE                                                              \n                    Statement R                                                   \n                ENDIF                                                             \n            ELSE                                                                  \n                Statement S                                                       \n                IF C THEN                                                         \n                    Statement T                                                   \n                ELSE                                                              \n                    Statement U                                                   \n                ENDIF                                                             \n            ENDIF                                                                 \n            Statement V                                                           \n        Assume that decisions B and C are independent of each other. What is the minimum number of\n        test cases required to achieve 100% decision coverage?\n Select 1 option(s).",
    "options": {
      "A": "2",
      "B": "3",
      "C": "4",
      "D": "5"
    },
    "answers": [
      "C"
    ],
    "explanation": "a) Is not correct. As shown in (c), 4 tests are needed to achieve 100% TTA-2.3.1 K3 2\n                              decision coverage\n                            b) Is not correct. As shown in (c), 4 tests are needed to achieve 100%\n                              decision coverage\n                            c) Is correct. The following conditions ensure that all decision outcomes\n                              are tested:\n                              1) A = true, B = true\n                              2) A = true, B = false\n                              3) A = false, C = true\n                              4) A = false, C= false\n                            d) Is not correct. As shown in (c), 4 tests are enough to achieve 100%\n                              decision coverage",
    "learning_objective": "TTA-2.3.1",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "5",
    "question_text": "You are testing code whose control flow graph is presented below. Node 1 is the entry point and\n        node 9 is the exit point.                                                 \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n                                                                                  \n        Assuming that all decisions in this code are independent, what is the minimum number of test\n        cases required to achieve 100% decision coverage?\n Select 1 option(s).",
    "options": {
      "A": "2",
      "B": "3",
      "C": "4",
      "D": "5"
    },
    "answers": ["A"],
    "explanation": "There are 4 decision points in the graph, in nodes 1, 2, 4 and 6. Hence, we TTA-2.3.1 K3 2\n                            need to cover 8 decision outcomes: TRUE and FALSE for each of the four\n                            decisions. These correspond to the branches 1→2, 1→5, 2→3, 2→4, 4→2,\n                            4→6, 6→7 and 6→8. One test is not enough, because it will not be able to\n                            cover both 1→2 and 1→5. Two tests, however, will be enough; for example,\n                            the first one can go along t\n                                             he path 1→2→3→4→2→4→6→7→9 and the\n                            second one along the path 1→5→6→8→9. The first test exercises decision\n                            outcomes 1→2, 2→3, 2→4, 4→2, 4→6 and 6→7. The second one\n                            exercises the decision outcomes 1→5 and 6→8. Hence, both tests cover all\n                            eight decision outcomes, achieving 100% decision coverage.\n                            Thus:\n                            a) Is correct\n                            b) Is not correct\n                            c) Is not correct\n                            d) Is not correct",
    "learning_objective": "TTA-2.3.1",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "6",
    "question_text": "You are testing a photo-enforcement system for traffic control at an intersection. The requirements\n        state a photo shall be taken if the signal light is red (RED), or the car is speeding (SPEED), and if\n        the front wheels of the car are over the line marking the beginning of the intersection (WHEELS).\n                                                                                  \n        The logic in the code looks like the following:                           \n                                                                                  \n        IF ((RED OR SPEED) AND WHEELS) THEN                                       \n             Take the photo                                                       \n        ELSE                                                                      \n            Do not take the photo                                                 \n        ENDIF                                                                     \n                                                                                  \n        Consider these test input values:                                         \n            1.  RED + SPEED + WHEELS                                              \n            2.  RED + SPEED + not WHEELS                                          \n            3.  RED + not SPEED + WHEELS                                          \n            4.  RED + not SPEED + not WHEELS                                      \n            5.  not RED + SPEED + WHEELS                                          \n            6.  not RED + SPEED + not WHEELS                                      \n            7.  not RED + not SPEED + WHEELS                                      \n            8.  not RED + not SPEED + not WHEELS                                  \n        Assuming there is no short-circuiting, which set of test input values is required to achieve full\n        modified condition/decision coverage?\n Select 1 option(s).",
    "options": {
      "A": "1, 3, 8",
      "B": "2, 6, 8",
      "C": "3, 4, 5, 7",
      "D": "1, 5, 7, 8"
    },
    "answers": [
      "C"
    ],
    "explanation": "a) Is not correct. Covers the outcomes but not the atomic conditions that TTA-2.4.1 K3 2\n                              affect the decision outcome. Also, for three independent atomic\n                              conditions, then four tests are needed to achieve MC/DC level of\n                              coverage\n                            b) Is not correct. Does not sufficiently cover the atomic conditions affecting\n                              the decision outcome. Also, for three independent atomic conditions,\n                              then four tests are needed to achieve MC/DC level of coverage.\n                            c) Is correct. This answer provides the following:\n                               Test inputs for (RED or SPEED) and WHEELS OUTCOME\n                                3.   RED + not SPEED + WHEELS   TRUE\n                                4.   RED + not SPEED + not WHEELS FALSE\n                                5.   not RED + SPEED + WHEELS   TRUE\n                                7.   not RED + not SPEED + WHEELS FALSE\n                              #3 and #7 show that RED can independently affect the overall outcome.\n                              #5 and #7 show that SPEED can independently affect the overall\n                              outcome\n                              #3 and #4 show that WHEELS can independently affect the outcome.\n                           d) Is not correct. Does not sufficiently cover the atomic conditions affecting\n                              the decision outcome. #1 combined with any of the other three (#5, #7,\n                              #8) cannot show that any single condition can independently affect the\n                              overall outcome",
    "learning_objective": "TTA-2.4.1",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "7",
    "question_text": "You are testing a photo-enforcement system for traffic control at an intersection. The requirements\n        state a photo shall be taken if the signal light is red (RED), or the car is speeding (SPEED), and if\n        the front wheels of the car are over the line marking the beginning of the intersection (WHEELS).\n                                                                                  \n        The logic in the code looks like the following:                           \n                                                                                  \n        IF ((RED OR SPEED) AND WHEELS) THEN                                       \n             Take the photo                                                       \n        ELSE                                                                      \n            Do not take the photo                                                 \n        ENDIF                                                                     \n                                                                                  \n        Consider these test input values:                                         \n            1.  RED + SPEED + WHEELS                                              \n            2.  RED + SPEED + not WHEELS                                          \n            3.  RED + not SPEED + WHEELS                                          \n            4.  RED + not SPEED + not WHEELS                                      \n            5.  not RED + SPEED + WHEELS                                          \n            6.  not RED + SPEED + not WHEELS                                      \n            7.  not RED + not SPEED + WHEELS                                      \n            8.  not RED + not SPEED + not WHEELS                                  \n        Assuming no short-circuiting, which set of test input values is required to achieve 50% multiple\n        condition coverage?\n Select 1 option(s).",
    "options": {
      "A": "3, 4, 5, 8",
      "B": "1, 3, 5",
      "C": "2, 4, 6, 7, 8",
      "D": "2, 7"
    },
    "answers": [
      "A"
    ],
    "explanation": "a) Is correct. Multiple condition testing requires testing the entire truth TTA-2.5.1 K3 2\n                              table (all combinations of true and false possible which equals 2N,\n                              where N is the number of uncoupled atomic conditions). So, this\n                              example requires 8 tests. 50% coverage is achieved with any 4\n                              separate tests from the list\n                            b) Is not correct. This answer provides 3/8 (37.5%) coverage of the\n                              multiple condition testing\n                            c) Is not correct. This answer provides 5/8 (62.5%) coverage of the\n                              multiple condition testing\n                            d) Is not correct. This answer provides 2/8 (25%) coverage of the multiple\n                              condition testing",
    "learning_objective": "TTA-2.5.1",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "8",
    "question_text": "Which of the following are examples of defects targeted by API testing?\n Select 2 option(s).",
    "options": {
      "A": "Issues in transaction processing of HTTP requests",
      "B": "standards Committed code violates the project’s coding",
      "C": "System web service reacting incorrectly to different data in requests",
      "D": "Division by zero errors",
      "E": "Functional errors occurring on the GUI"
    },
    "answers": [
      "A",
      "C"
    ],
    "explanation": "a) Is correct. Transaction issues are listed under types of defects found by TTA-2.7.1 K2 1\n                              API testing\n                            b) Is not correct. Code standards violations are targeted by maintainability\n                              testing\n                            c) Is correct. Data handling issues are listed under types of defects found\n                              by API testing\n                            d) Is not correct. This low-level programming issues are addressed by unit\n                              testing\n                            e) Is not correct. Issues on GUI cannot be targeted by API testing since it\n                              is executed on lower levels of system architecture than GUI",
    "learning_objective": "TTA-2.7.1",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "9",
    "question_text": "You are the Technical Test Analyst working on the testing of software that will control the\n        movement of the roof on a new national sports stadium that seats 100,000 spectators. A failure\n        analysis has shown that if the software system fails it may cause the roof to break up and fall on\n        the spectators. The government has requested that the level of testing for this software exceeds\n        that required by the IEC 61508 standard.                                  \n                                                                                  \n        Which level of test coverage would you expect to be achieved in the testing of the control software\n        for the stadium roof?\n Select 1 option(s).",
    "options": {
      "A": "Decision coverage + Modified Condition/Decision coverage",
      "B": "Decision coverage + Statement coverage",
      "C": "Modified Condition/Decision coverage",
      "D": "Multiple Condition coverage"
    },
    "answers": [
      "D"
    ],
    "explanation": "a) Is not correct. This is the same as MC/DC, because decision coverage TTA-2.8.1 K4 3\n                              is subsumed by MC/DC\n                            b) Is not correct. This is the same as decision coverage because\n                              statement coverage is subsumed by decision coverage. Decision\n                              coverage, however, provides a lower level of rigor than MC/DC or\n                              multiple condition coverage\n                            c) Is not correct. MC/DC is required for the highest-level criticality software\n                              according to IEC 61508, but this scenario requires the level of testing to\n                              exceed this, so this is not a correct option\n                            d) Is correct. MC/DC is required for the highest-level criticality software\n                              according to IEC 61508, which is presumably because several\n                              thousand spectators could be killed/injured. Multiple condition coverage\n                              provides a higher level of coverage than MC/DC and as this ‘exceeds’\n                              that provided by MC/DC this is the correct option for this scenario",
    "learning_objective": "TTA-2.8.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "10",
    "question_text": "You work for a software house that provides software solutions for medical systems. Currently you\n        are testing a software component that operates the defibrillator machine controlling the dose of\n        electric current delivered to the heart. During the code review, the reviewers noticed that one\n        decision in the module under test consists of 20 independent atomic conditions. You are obliged to\n        perform white-box testing for this module and you are expected to finish it in one month.\n                                                                                  \n        Which white-box test technique should you choose for this scenario?\n Select 1 option(s).",
    "options": {
      "A": "Multiple condition testing",
      "B": "MC/DC testing",
      "C": "Decision testing",
      "D": "API testing"
    },
    "answers": [
      "B"
    ],
    "explanation": "a) Is not correct. Multiple condition testing is the most thorough technique, TTA-2.8.1 K4 3\n                              but for a decision with 20 independent atomic conditions we would have\n                              to design 220 = 1,048,576 tests to achieve full multiple condition\n                              coverage, which would be impossible to finish in one month (if at all)\n                            b) Is correct. This is a medical, safety-critical system, whose failure or\n                              malfunction may result in death or serious injury to people. Therefore, it\n                              must be tested thoroughly. Full multiple condition coverage is\n                              impossible to achieve (see answer a), hence, MC/DC is the most\n                              reasonable choice as it is stronger than decision testing, but, compared\n                              to multiple condition testing, requires only a linear number of test cases\n                               for example, the decision with 20 conditions requires only 21 test\n                              cases to achieve full MC/DC coverage\n                            c) Is not correct. Decision testing is a relatively weak criterion compared to\n                              MC/DC, and so not suitable for a safety-critical system\n                            d) Is not correct. There is no information about API in this scenario. Also,\n                              this would not guarantee the thorough level of testing required for such\n                              a safety-critical system",
    "learning_objective": "TTA-2.8.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "11",
    "question_text": "Below is the pseudo-code for a TRICKY program:                            \n                                                                                  \n            0   program TRICKY                                                    \n            1   var1, var2, var3 : integer                                        \n            2   begin                                                             \n            3       read(var2)                                                    \n            4       read(var1)                                                    \n            5       while var2 < 10 loop                                          \n            6          var3 = var2 + var1                                         \n            7          var2 = 4                                                   \n            8          var1 = var2 + 1                                            \n            9          print(var3)                                                \n            10         if var1 = 5 then                                           \n            11             print(var1)                                            \n            12         else                                                       \n            13             print(var1+1)                                          \n            14         endif                                                      \n            15         var2 = var2 + 1                                            \n            16      endloop                                                       \n            17      print                                                         \n                        (“Wow – that was tricky!”)                                \n            18      print                                                         \n                        (“But the answer is...”)                                  \n            19      print(var2+var1)                                              \n            20  end program TRICKY                                                \n        Which of the following statements about the TRICKY program MOST correctly describes any\n        control flow anomalies in it?\n Select 1 option(s).",
    "options": {
      "A": "The TRICKY program contains no control flow anomalies",
      "B": "The TRICKY program contains unreachable code and an infinite loop",
      "C": "The TRICKY program contains unreachable code and no infinite loop",
      "D": "The TRICKY program contains a loop with multiple entry points"
    },
    "answers": [
      "B"
    ],
    "explanation": "a) Is not correct. See the correct justification for details TTA-3.2.1 K3 2\n                            b) Is correct. The decision at line 10 will always be true as var1 will always\n                              be 5 at line 10, thus line 13 is unreachable. The loop at line 5 can only\n                              be left if var2 is 10 or more, but each time through the loop var2 is reset\n                              at line 7 back to 4 and only incremented by 1 in the loop at line 15, so it\n                              only ever reaches 5\n                            c) Is not correct. See the correct justification for details\n                            d) Is not correct. There is only one entry point to the WHILE loop (with the\n                              control flow 4 5)\n                                        →",
    "learning_objective": "TTA-3.2.1",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "12",
    "question_text": "The programmers have designed three versions of a function that finds the largest number among\n        three integers: findMax1, findMax2 and findMax3. One of them must be chosen for the next\n        release. The codes look as follows:                                       \n                                                                                  \n            int findMax1(int n1, int n2, int n3) {                                \n               int max;                                                           \n               if (n1 >= n2 && n1 >= n3)                                          \n                  max = n1;                                                       \n               if (n2 >= n1 && n2 >= n3)                                          \n                  max = n2;                                                       \n               if (n3 >= n1 && n3 >= n2)                                          \n                  max = n3;                                                       \n               return max;                                                        \n            }                                                                     \n            int findMax2(int n1, int n2, int n3) {                                \n               int max;                                                           \n               if (n1 >= n2 && n1 >= n3)                                          \n                  max = n1;                                                       \n               else if (n2 >= n1 && n2 >= n3)                                     \n                  max = n2;                                                       \n               else                                                               \n                  max = n3;                                                       \n               return max;                                                        \n            }                                                                     \n                                                                                  \n            int findMax3(int n1, int n2, int n3) {                                \n               int max;                                                           \n               if (n1 >= n2) {                                                    \n                  if (n1 >= n3)                                                   \n                      max = n1;                                                   \n                  else                                                            \n                      max = n3;                                                   \n               } else {                                                           \n                  if (n2 >= n3)                                                   \n                      max = n2;                                                   \n                  else                                                            \n                      max = n3;                                                   \n               }                                                                  \n               return max;                                                        \n            }                                                                     \n        You were asked to select the one with the lowest cyclomatic complexity. Which ONE should you\n        choose?\n Select 1 option(s).",
    "options": {
      "A": "findMax1",
      "B": "findMax2",
      "C": "findMax3",
      "D": "You can choose any of them, because all three functions have the same cyclomatic complexity"
    },
    "answers": ["B"],
    "explanation": "TTA-3.2.1   K3     2\n                            The control flow graphs of all three functions are presented in the figure.\n                            One can see that findMax2 has 2 decision points (marked with symbol “D”),\n                            so its cyclomatic complexity equals 3, while findMax1 and findMax3 have 3\n                            decision points, so their cyclomatic complexity equals 4. Hence:\n                            Thus:\n                            a) Is not correct\n                            b) Is correct\n                            c) Is not correct\n                            d) Is not correct",
    "learning_objective": "TTA-3.2.1",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "13",
    "question_text": "Below is the pseudo-code for a program that calculates and prints sales commissions:\n                                                                                  \n            0   program Calculate Commission                                      \n            1   total, number : integer                                           \n            2   commission_hi, commission_lo : real                               \n            3   begin                                                             \n            4       read(number)                                                  \n            5                    -1) loop                                         \n                    while (number ≠                                               \n            6          total = total + number                                     \n            7          read(number)                                               \n            8       endloop                                                       \n            9       if (total > 1000) then                                        \n            10         commission_hi = 100 + 0.2 * ( total 1000 )                 \n                                                     –                            \n            11      else                                                          \n            12         commission_lo = 0.15 * total                               \n            13      endif                                                         \n            14                                                                    \n                    write(“This salesman’s commission is:”)                       \n            15      write(commission_hi)                                          \n            16  end program Calculate Commission                                  \n        The code contains data flow anomalies on lines 6 and 12 (highlighted text). Which examples of\n        data flow anomalies can be found on these lines?\n Select 1 option(s).",
    "options": {
      "A": "using it line 6: variable “total” is not assigned a value before line 12: variable “commission_lo” is defined but subsequently not used",
      "B": "line 6: an invalid value is assigned to variable “total” line 12: variable “commission_lo” is redefined before it is used",
      "C": "line 6: variable “total” is out of scope line 12: th - e “hard coded” value “0.15” should not be used",
      "D": "line 6: the variable “number” is undefined line 12: the variable “total” is redefined before it is used"
    },
    "answers": [
      "A"
    ],
    "explanation": "a) Is correct.     total is used at line 6 before it is defined. TTA-3.2.2 K3 2\n                                     The variable ‘ ’\n                                       commission_lo efined at line 12 with no subsequent\n                              The variable ‘     ’ is d\n                              use\n                            b) Is not correct.   number is a valid value to assign to the\n                                        The variable ‘ ’\n                              variable total :\n                                    ‘  ’\n                                       commission_lo is not defined before line 12\n                              The variable ‘     ’\n                            c) Is not correct. The variable total is in scope at line 6\n                                                 ‘  ’\n                              Use of the -             is not a data flow anomaly\n                                      “hard coded” value “0.15”\n                            d) Is not correct. The variable number is defined at line 4. The variable\n                                                 ‘    ’\n                               total is defined at line 6, and not redefined before line 12\n                              ‘   ’",
    "learning_objective": "TTA-3.2.2",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "14",
    "question_text": "You have been asked to analyze the following program that calculates a sales commission:\n                                                                                  \n               PROGRAM Commission                                                 \n               barrels, totalBarrels : INTEGER                                    \n               price, sales, commission : REAL                                    \n            1  price = 35.0                                                       \n            2  totalBarrels = 0                                                   \n            3  INPUT(barrels)                                                     \n            4  WHILE NOT(barrels == -1) DO                                        \n            5     totalBarrels = totalBarrels + barrels                           \n            6     INPUT(barrels)                                                  \n            7  ENDWHILE                                                           \n            8  sales = price * totalBarrels                                       \n            9  IF (sales > 1800.0)                                                \n            10    commission = 0.10 * 1000.0 + 0.15 * 800.0                       \n            11    commission = commission + 0.20 * (sales 1800.0)                 \n                                                   –                              \n            12 ELSE IF (sales > 1000.0)                                           \n            13    commission = 0.10 * 1000.0                                      \n            14    commission = 0.15 * (sales 1000)                                \n                                         –                                        \n            15 ELSE                                                               \n            16    commission = 0.10 * sales                                       \n            17 ENDIF                                                              \n            18 totalBarrels = 0                                                   \n            19 barrels = 0                                                        \n            20 OUTPUT                                                             \n                    (“Total commission = “,commission)                            \n               END PROGRAM                                                        \n        Which pair of lines represents a data flow anomaly?\n Select 1 option(s).",
    "options": {
      "A": "8 9 –",
      "B": "3 19 –",
      "C": "2 18 –",
      "D": "13 14 –"
    },
    "answers": [
      "D"
    ],
    "explanation": "a) Is not correct. This pair represents a correct definition-use (du) TTA-3.2.2 K3 2\n                              sequence for sales\n                            b) Is not correct. Barrels is defined at line 3 and used at line 4, so the\n                              definition at line 19 takes place after a use. A use then definition\n                              sequence is not an anomaly\n                            c) Is not correct. totalBarrels is defined at line 2, then may be used at line\n                              5, and is used at line 8, so the definition at line 18 takes place after a\n                              use of totalBarrels a use then definition sequence is not an anomaly\n                            d) Is correct. At line 13 commission is defined and then in line 14 it is\n                              defined again, without any use between these two definitions. This is a\n                              definition-definition sequence, which is an anomaly",
    "learning_objective": "TTA-3.2.2",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "15",
    "question_text": "You have been provided with the following system-wide average measures for the four systems,\n        W, X, Y and Z, using static code analysis.                                \n                                                                                  \n                                                    SYSTEM                        \n                                                                                  \n                                           W      X       Y      Z                \n                    Cyclomatic Complexity (CC) 23 8      12      7                \n                    Cohesion (CH)         High  Medium   Low    High              \n                    Coupling (CP)         Low    High  Medium  Medium             \n             Metric                                                               \n                    Commented Code (CO)   60%    10%     45%     8%               \n                    Repeated code instances 9     2       3      12               \n                    (RE)                                                          \n        Budget is available to improve the maintainability of the code in each of the four systems by\n        applying the results of static analysis to the individual components.     \n                                                                                  \n        Which of the following is the BEST way to improve maintainability of the code if you can address\n        only two metrics per system?\n Select 1 option(s).",
    "options": {
      "A": "W CO, RE X CC, CH Y CP, CO Z CC, RE – – – –",
      "B": "W CC, CP X CH, CO Y CC, CH Z CO, RE – – – –",
      "C": "W CC, RE X CP, CO Y CC, CH Z CO, RE – – – –",
      "D": "W CH, CO X CC, RE Y CP, RE Z CC, CH – – – –"
    },
    "answers": ["C"],
    "explanation": "Cyclomatic Complexity (CC) indicates the number of independent paths TTA-3.2.3 K3 2\n                            tough the code. The higher the CC number, the worse code maintainability\n                            is likely to be, hence system W and Y should be addressed in this area.\n                            Cohesion (CH) is a measure to which a module is self-contained and\n                            focused on a single task. The lower it is, the worse the code maintainability\n                            is likely to be. Hence system Y should be addressed in this area.\n                            Coupling (CP) is a measure of the degree to which modules rely on each\n                            other. The higher it is, the worse the code maintainability is likely to be.\n                            Hence system X should be addressed in this area.\n                            Commented Code (CO) indicates how much of the code is documented by\n                            comments. Less comments indicates worse code maintainability. Hence\n                            systems X and Z should be addressed in this area.\n                            Repeated code instances (RE) count how many code instances are\n                            duplicated. The higher the number, the worse the code maintainability is\n                            likely to be. Hence systems W and Z should be addressed in this area.\n                            Thus:\n                            a) Is not correct\n                            b) Is not correct\n                            c) Is correct (W CC & RE, X CP & CO, Y CC & CH, Z CO & RE)\n                                       –         –         –        –\n                            d) Is not correct",
    "learning_objective": "TTA-3.2.3",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "16",
    "question_text": "Below is the pseudo-code for a TRICKY program:                            \n                                                                                  \n            0   program TRICKY                                                    \n            1   var1, var2, var3 : integer                                        \n            2   begin                                                             \n            3       read(var2)                                                    \n            4       read(var1)                                                    \n            5       while (var2 < 10) loop                                        \n            6          var3 = var2 + var1                                         \n            7          var2 = 4                                                   \n            8          var1 = var2 + 1                                            \n            9          print(var3)                                                \n            10         if (var1 == 5) then                                        \n            11             print(var1)                                            \n            12         else                                                       \n            13             print(var1+1)                                          \n            14         endif                                                      \n            15         var2 = var2 + 1                                            \n            16      endloop                                                       \n            17      print                                                         \n                        (“Wow – that was tricky!”)                                \n            18      print                                                         \n                        (“But the answer is...”)                                  \n            19      print(var2+var1)                                              \n            20  end program TRICKY                                                \n        Which TWO fixes to improve code maintainability would MOST likely be proposed after performing\n        static analysis?\n Select 2 option(s).",
    "options": {
      "A": "Restructuring the code",
      "B": "Improving the naming of variables",
      "C": "Reduce program coupling",
      "D": "Improving the amount of comments",
      "E": "Improving the indentation of code"
    },
    "answers": [
      "B",
      "D"
    ],
    "explanation": "a) Is not correct. The code is clearly structured with control elements (e.g., TTA-3.2.3 K3 2\n                              loop, if-then-else). Static analysis is unlikely to identify any\n                              improvements to the control structure\n                            b) Is correct. Variable naming used in the program does not clearly\n                              indicate what the variable represents. Static analysis can apply naming\n                              convention rules which would identify these maintenance issues in the\n                              program and recommend that the variables be given names that are\n                              readable and conform to any applicable naming rules\n                            c) Is not correct. There are no global variables defined and no other\n                              programs called. Coupling is not an improvement area\n                            d) Is correct. Static analysis identifies code which has a low level of\n                              commenting compared to executable code. Since the program has no\n                              comments at all, this would be highlighted as an area for improving\n                              code maintainability\n                            e) Is not correct. Static analysis can apply indentation rules but in the case\n                              of the TRICKY program there is already adequate indentation",
    "learning_objective": "TTA-3.2.3",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "17",
    "question_text": "You are the Technical Test Analyst working on a project developing a new Ambulance Dispatch\n        System (ADS). This ADS assists operators in taking calls about incidents, identifying available\n        ambulances, and mobilizing ambulances to handle the incidents. You know that the ADS was\n        designed using an object-oriented approach and implemented using a language with automated\n        garbage collection. During system and acceptance testing the system has been perceived to be\n        generally performing correctly, but also rather slowly, and it has also occasionally ‘crashed’; the\n        subsequent (brief) investigations were inconclusive.                      \n                                                                                  \n        Which of the following statements would BEST justify the use of dynamic analysis in this situation?\n Select 1 option(s).",
    "options": {
      "A": "Dynamic analysis could be used to measure response times on user actions to identify efficiency bottlenecks",
      "B": "Dynamic analysis could be used to generate control flow graphs of the system to allow targeted performance enhancement",
      "C": "Dynamic analysis could identify memory access violations caused by a wild pointer that result in the occasional ‘crashes’",
      "D": "Dynamic analysis could be used to determine if programmers introduced defects by not properly releasing allocated memory"
    },
    "answers": [
      "C"
    ],
    "explanation": "a) Is not correct. Dynamic analysis is not typically used for measuring TTA-3.3.1 K3 2\n                              response times (it requires instrumentation and so makes response\n                              time measurement impractical). Response times on user actions also\n                              cannot identify bottlenecks in the system. Dynamic analysis instead\n                              provides lower-level performance metrics to be used for performance\n                              tuning\n                            b) Is not correct. Control flow graphs are generated by static analysis\n                            c) Is correct. Dynamic analysis can identify memory access violations\n                              caused by a wild pointer and\n                                                  these could be causing the ‘occasional’\n                              crashes\n                            d) Is not correct. The scenario tells us that automated garbage collection\n                              was used, so it is unlikely programmers will need to release memory",
    "learning_objective": "TTA-3.3.1",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "18",
    "question_text": "Assume you are working as a Technical Test Analyst on a project where a new banking system is\n        being developed. This system will store customer financial data, including personal information,\n        account numbers, balances, and transaction histories, but no real customer data will become\n        available until after the system is deployed operationally.               \n                                                                                  \n        Based on this information, which of the following topics are you MOST likely to include in the\n        system test plan?\n Select 1 option(s).",
    "options": {
      "A": "Test data anonymization",
      "B": "Coordination of distributed components",
      "C": "Testing of data encryption",
      "D": "Testing in production"
    },
    "answers": [
      "C"
    ],
    "explanation": "a) Is not correct. While subsequent releases of this system may be tested TTA-4.2.1 K4 3\n                              with real customer data, this is a new system and no existing customer\n                              data is available\n                            b) Is not correct. There is no indication this is a distributed system\n                            c) Is correct. It is highly likely the bank is required by regulation to encrypt\n                              the customer financial data, which has testing implications\n                            d) Is not correct. It is not clear whether this system will be used in-house\n                              (thus a production environment might be available) or sold to customers\n                              (thus production environments would likely not be available)",
    "learning_objective": "TTA-4.2.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "19",
    "question_text": "Assume you are working as a Technical Test Analyst on the system integration testing of the\n        baggage handling system for a major airport. Most of the system components are developed by a\n        main contractor, but the system components for baggage redirection and for handling outsized\n        items are being developed off-shore by separate organizations. The airport operator is the\n        customer for the project and has indicated that the system must run fast even under peak morning\n        and evening loads. A fully representative test environment has been made available for the system\n        integration tests and a specialist tools team has been set up to support the functional and non-\n        functional testing. Some of the functional tests for systems integration have already been\n        implemented but progress is slow.                                         \n                                                                                  \n        Based on this information, which of the following topics are you MOST likely to identify as risks in\n        the system integration test plan?\n Select 2 option(s).",
    "options": {
      "A": "Stakeholder requirements",
      "B": "Required tool acquisition and training",
      "C": "Test environment requirements",
      "D": "Organizational considerations",
      "E": "Data security considerations"
    },
    "answers": [
      "A",
      "D"
    ],
    "explanation": "a) Is correct. The requirements stated by the customer for performance TTA-4.2.1 K4 3\n                              efficiency are vague and must be made more precise before the\n                              specialist tools team can implement the tests\n                            b) Is not correct. A specialist tools team can be assumed to have issues of\n                              tool acquisition and training under control\n                            c) Is not correct. A fully representative test environment has been made\n                              available\n                            d) Is correct. If components are distributed across different sites and\n                              organizations, the effort required to plan and co-ordinate the system\n                              integration tests may be significant and must be addressed in the test\n                              planning\n                            e) Is not correct. Data security considerations are not mentioned in the\n                              scenario",
    "learning_objective": "TTA-4.2.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "20",
    "question_text": "Consider the following product risk: Abnormal application termination due to network connection\n        failure.                                                                  \n                                                                                  \n        Which of the following is the MOST appropriate test type to address this risk?\n Select 1 option(s).",
    "options": {
      "A": "Reliability testing",
      "B": "Performance testing",
      "C": "Operability testing",
      "D": "Portability testing"
    },
    "answers": [
      "A"
    ],
    "explanation": "a) Is correct. Fault-tolerance testing is part of reliability TTA-4.2.2 K3 2\n                            b) Is not correct. We are not worried about response time, throughput, or\n                              resource utilization here\n                            c) Is not correct. This risk does not relate to usability\n                            d) Is not correct. A change of to a different environment is not in question\n                              here",
    "learning_objective": "TTA-4.2.2",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "21",
    "question_text": "Consider the following product risk: “The new database is not suitable for replacing the current\n        one”.                                                                     \n        Which of the following is the MOST appropriate test type to address this risk?\n Select 1 option(s).",
    "options": {
      "A": "Adaptability testing",
      "B": "Replaceability testing",
      "C": "Capacity testing",
      "D": "Co-existence testing"
    },
    "answers": [
      "B"
    ],
    "explanation": "a) Is not correct. Adaptability testing checks whether a given application TTA-4.2.2 K3 2\n                              can function correctly in all intended target environments\n                            b) Is correct. Replaceability testing focuses on the ability of software\n                              components (such as databases) to replace existing components\n                            c) Is not correct. Capacity testing relates to exercising the maximum limits\n                              of a system\n                            d) Is not correct. Co-existence testing considers the degree to which a test\n                              item can function satisfactorily alongside other independent products in\n                              a shared environment",
    "learning_objective": "TTA-4.2.2",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "22",
    "question_text": "Which of the following statements is CORRECT?\n Select 1 option(s).",
    "options": {
      "A": "It is desirable to conduct end-to-end turnaround time tests as early as possible, even if a production-like environment is not yet available",
      "B": "Availability testing using operational profiles is performed both before and after entering operational service",
      "C": "Security testing should start with component testing and go on through integration and system testing as security issues can be introduced anytime during development",
      "D": "Maintainability can be evaluated early in the lifecycle without having to wait for a complete and running system"
    },
    "answers": [
      "D"
    ],
    "explanation": "a) Is not correct. Performing turnaround time tests before a production-like TTA-4.2.3 K2 1\n                              test environment is available is not practical as any times recorded will\n                              be unlikely to be representative of the operational turnaround times\n                            b) Is not correct. Once the system is operational, the operational data can\n                              be used to determine availability, and so availability testing using\n                              operational profiles is unnecessary\n                            c) Is not correct. Security testing may be scheduled for the unit, integration\n                              and system testing levels, but for many projects it should start earlier\n                              with reviews and static analysis\n                            d) Is correct. Since maintainability is built into the code and the\n                              documentation for each individual code component, maintainability can\n                              be evaluated early in the lifecycle without having to wait for a completed\n                              and running system",
    "learning_objective": "TTA-4.2.3",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "23",
    "question_text": "Which of the following statements is CORRECT?\n Select 1 option(s).",
    "options": {
      "A": "Reliability tests are commonly done as part of system testing",
      "B": "Co-existence testing is normally performed immediately after component testing has been completed",
      "C": "Adaptability tests are often performed in conjunction with security tests",
      "D": "Replaceability testing is normally only performed once the overall system and potential replaceable components are available"
    },
    "answers": [
      "A"
    ],
    "explanation": "a) Is correct. Because reliability tests often require use of the entire TTA-4.2.3 K2 1\n                              system, reliability testing is most commonly performed as part of\n                              system testing\n                            b) Is not correct. Co-existence issues should be analyzed when planning\n                              the targeted production environment, but the actual tests are normally\n                              performed after system and user acceptance testing have been\n                              successfully completed\n                            c) Is not correct. Adaptability tests may be performed in conjunction with\n                              installability tests and are typically followed by functional tests to detect\n                              any faults which may have been introduced in adapting the software to\n                              a different environment\n                            d) Is not correct. Replaceability may also be evaluated by technical review\n                              or inspection at the architecture and design levels, where the emphasis\n                              is placed on the clear definition of interfaces to potential replaceable\n                              components",
    "learning_objective": "TTA-4.2.3",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "24",
    "question_text": "Assume that you are working for a start-up company with big ambitions but with limited initial\n        funding. They are creating a system that will provide customized loyalty and rewards programs for\n        small- and medium-sized businesses selling to customers on the web. These companies enroll\n                              store. This allows the companies to create customized buttons, to\n        themselves on the system’s web                                            \n        be placed on their websites, that let customers enroll in the companies’ loyalty and rewards\n        program. Each subsequent purchase earns points, and both companies and their customers can\n        manage the program; for example, companies can determine the number of points required for\n        customers to receive a free product or service, and customers can monitor their points.\n                                                                e discounts on    \n        Your employer’s marketing staff is heavily promoting the system, offering aggressiv\n        the first year’s fees to sign up new companies. The marketing materials state that the service will\n        be highly reliable and extremely fast for companies and their customers.  \n        At this time, the requirements are complete, and development of the software has just begun. The\n        current schedule will allow companies and their customers to start enrolling in three months.\n                                                                                  \n        Your employer intends to use cloud computing resources to host this service, and to have no\n        hardware resources other than ordinary office computers for its developers, testers, and other\n        engineers and managers. Industry-standard web-based application software components will be\n        used to build the system.                                                 \n                                                                                  \n        Assume that you are executing security tests against the system.          \n        Which of the following types of defect would you expect to find during this testing?\n Select 1 option(s).",
    "options": {
      "A": "System clears screen too quickly after login",
      "B": "System removes user temporary files after logout",
      "C": "System allows unauthorized access to data",
      "D": "System allows access from unsupported browser"
    },
    "answers": [
      "C"
    ],
    "explanation": "a) Is not correct. This is a usability failure, not a security defect TTA-4.2.4 K3 2\n                            b) Is not correct. This is a security feature, not a security defect\n                            c) Is correct. A typical security defect\n                            d) Is not correct. If it is a defect at all, is a portability defect",
    "learning_objective": "TTA-4.2.4",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "25",
    "question_text": "The system integration testing for a new version of a stocks trading system is being planned. You\n        are planning the performance efficiency tests as part of this testing. The new version has increased\n        functionality, but the basic architecture remains the same.               \n                                                                                  \n        The current system has so far received a positive response and the number of users has steadily\n        increased. It enables users to trade individual stocks with a simple transaction consisting only of\n        the user identity, stock number, quantity, and action (buy or sell).      \n                                                                                  \n        The current system’s response time to user inputs is regularly monitored by conducting\n        performance tests supported by a tool and using a fully representative test environment. At present\n        the system runs reliably and response times to user trading transactions are just below the\n        maximum specified.                                                        \n                                                                                  \n        The marketing department anticipates that with the new functionality being introduced in the next\n        version, the number of users is expected to double over the next 12 months. You have included\n        scalability tests into your performance testing strategy.                 \n                                                                                  \n        When planning the performance efficiency tests, which of the following types of defects would you\n        target in the system integration test plan as being the MOST likely to occur?\n Select 1 option(s).",
    "options": {
      "A": "The simulated increase in the number of users will result in data volumes exceeding the bandwidth of the test environment",
      "B": "The system fails to meet future response time requirements for the anticipated numbers of users",
      "C": "The disk capacity requirements will exceed the resources available once more users are added",
      "D": "The system’s response time will degrade when running the system for a long time under a nominal load"
    },
    "answers": [
      "B"
    ],
    "explanation": "a) Is not correct. The test plan does not target defects in the test TTA-4.2.4 K3 2\n                              environment, but it targets defects in the product\n                            b) Is correct. Scalability testing focuses on the ability of a system to meet\n                              future performance efficiency requirements, which may be beyond\n                              those currently re\n                                          quired. The scenario states that the current system’s\n                              response to user inputs is just below the maximum specified time, but\n                              that the number of users is expected to double over the next 12\n                              months. There is a high risk that the planned scalability tests will show\n                              that the system fails to meet future requirements for the expected\n                              numbers of users\n                            c) Is not correct. There is no indication in the scenario that the system\n                              uses disk capacity resources. Compared to option b this is less likely to\n                              be a source of defects\n                            d) Is not correct.\n                                        The scenario states that “At present the system runs\n                                    - which suggests it does not have issues related to long time\n                              reliably”\n                              operation under nominal load and it is unlikely that the increase in the\n                              number of users will cause a degradation in response times when the\n                              system is run for a long time",
    "learning_objective": "TTA-4.2.4",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "26",
    "question_text": "By entering the following phrase into the username field of the login form:\n                                                                                  \n                 abcd OR 1=1                                                      \n                                                                                  \n        a tester performed an SQL injection attack and consequently obtained a list of all valid usernames\n        for the system.                                                           \n                                                                                  \n        Which of the following security aspects was MOST likely to have been addressed by this test?\n Select 1 option(s).",
    "options": {
      "A": "Confidentiality",
      "B": "Non-repudiation",
      "C": "Accountability",
      "D": "Availability"
    },
    "answers": [
      "A"
    ],
    "explanation": "a) Is correct. This is an example of compromising confidentiality by gaining TTA-4.3.2 K2 1\n                              access to sensitive data by an unauthorized user\n                            b) Is not correct. We do not know if the event of gaining access to sensitive\n                              data can be proven to have taken place. To test for non-repudiation test\n                              steps concerning the server log-files are typically required\n                            c) Is not correct. We do not know if such an SQL injection attack can be\n                              traced uniquely to the person that performed it. To test for\n                              accountability, log-files must typically be checked against specific\n                              actions by authorized and non-authorized users\n                            d) Is not correct. Availability tests in the security context are typically\n                              performed by simulating denial-of-service scenarios",
    "learning_objective": "TTA-4.3.2",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "27",
    "question_text": "You work as the TTA on an agile project and you have been asked to calculate the mean time to\n        failure (MTTF) for the system under test under a normal load.             \n                                                                                  \n        Which of the following sources of information is MOST likely to provide you with the necessary\n        information about the load that you should generate in your tests?\n Select 1 option(s).",
    "options": {
      "A": "Product owner",
      "B": "Operational profile",
      "C": "Scrum master",
      "D": "Test environment requirements"
    },
    "answers": [
      "B"
    ],
    "explanation": "a) Is not correct. The Product owner may have provided input on what the TTA-4.4.2 K2 1\n                              load is expected to be, but they are unlikely to know the expected load\n                              in sufficient detail\n                            b) Is correct. The operational profile should define how the system is\n                              expected to be used in normal conditions\n                            c) Is not correct. The Scrum Master may not be a subject matter expert on\n                              reliability and is unlikely to know the expected load in sufficient detail\n                            d) Is not correct. Although the test environment requirements will include\n                              the ability to generate loads based on the operational profile, they will\n                              not define those loads",
    "learning_objective": "TTA-4.4.2",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "28",
    "question_text": "Which of the following statements about code reviews in the context of planning performance\n        efficiency testing is CORRECT?\n Select 1 option(s).",
    "options": {
      "A": "Code reviews are not useful in performance efficiency testing, because performance can be measured only with dynamic testing on a running system",
      "B": "Code reviews are useful in performance efficiency testing, because they may detect inefficient algorithm implementation that may cause performance issues",
      "C": "Code reviews are not useful in performance efficiency testing, because performance efficiency testing usually requires the entire system to be implemented, so it is typically performed as part of system testing, which requires dynamic testing, not static testing",
      "D": "Code reviews are useful in performance efficiency testing, because static testing is not dependent on the test environment, so the testers do not need to spend time on defining and building the test environment"
    },
    "answers": [
      "B"
    ],
    "explanation": "a) Is not correct. Code reviews are useful in performance efficiency testing TTA-4.5.2 K2 1\n                              (see the justification for the correct answer)\n                            b) Is correct. According to syllabus (4.5.7) reviews are of particular\n                              relevance when planning performance efficiency tests. Performance\n                              issues may result from poorly designed code, for example from\n                              inefficient algorithms. Code reviews can detect such issues\n                            c) Is not correct. Code reviews are useful in performance efficiency testing\n                              (see the justification for the correct answer)\n                            d) Is not correct. The test environment has nothing to do with the fact that\n                              code reviews are useful in performance efficiency testing. Hence,\n                              although the statement that test environments do not need to be\n                              designed for code reviews is correct, this is not the reason that code\n                              reviews are useful for performance efficiency testing",
    "learning_objective": "TTA-4.5.2",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "29",
    "question_text": "Which of the following statements provides the BEST rationale for including maintainability testing\n        in a test approach?\n Select 1 option(s).",
    "options": {
      "A": "Analyzability should be considered if you expect a lot of combinations need to be tested",
      "B": "Modifiability should be considered if you expect several problems to be identified within the system",
      "C": "Modularity should be considered if you are testing a system provided as commercial off-the- shelf (COT",
      "S": "software",
      "D": "Reusability should be considered if you expect different versions of the same product to be developed"
    },
    "answers": [
      "D"
    ],
    "explanation": "a) Is not correct. Analyzability should be considered if you do expect a lot TTA-4.6.1 K2 1\n                              of problems identified within the system\n                            b) Is not correct. Modifiability should be considered if you do expect\n                              several problems to be identified within the system\n                            c) Is not correct. Modularity should be considered in the context of\n                              changes to components, while the responsibility for the maintainability\n                              of a COTS system normally lies with the providers of the system, who\n                              will have to maintain it\n                            d) Is correct. Reusability addresses the degree to which an asset can be\n                              used in more than one system, or in building other assets",
    "learning_objective": "TTA-4.6.1",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "30",
    "question_text": "You work as a tester in a company that develops a desktop financial application for accountants.\n        The users reported problems with the following scenario, and you have been tasked with testing\n        the fix.                                                                  \n                                                                                  \n            Download app from the producer website                               \n            Install it using the installation wizard                             \n            Check if the app is installed properly                               \n            Uninstall the app                                                    \n            Check if everything was uninstalled properly                         \n                                                                                  \n        What is the reason for performing this test?\n Select 1 option(s).",
    "options": {
      "A": "To test maintainability",
      "B": "To test reliability",
      "C": "To test portability",
      "D": "To test compatibility"
    },
    "answers": [
      "C"
    ],
    "explanation": "a) Is not correct. The test appears to be for installability, which is not a TTA-4.7.1 K2 1\n                              form of maintainability testing, it is a type of portability testing\n                            b) Is not correct. The test appears to be for installability, which is not a\n                              form of reliability testing, it is a type of portability testing\n                            c) Is correct. The test appears to be for installability, which is a type of\n                              portability testing\n                            d) Is not correct. The test appears to be for installability, which is not a\n                              form of compatibility testing, it is a type of portability testing",
    "learning_objective": "TTA-4.7.1",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "31",
    "question_text": "A Technical Test Analyst has been invited to the formal review of an architectural design\n        specification. The review has been called at short notice for the following day and although there is\n        nothing in the                                                            \n                 analyst’s diary for that time, there is no time to prepare.      \n        Which of the following would be the most appropriate response to the invitation?\n Select 1 option(s).",
    "options": {
      "A": "I am free at that time, so I have no problem in attending",
      "B": "I do not have time to prepare but I will attend rather than cause a delay",
      "C": "I do not have time to prepare so I suggest the review is postponed",
      "D": "I do not have time to prepare, but I still might contribute some useful input"
    },
    "answers": [
      "C"
    ],
    "explanation": "a) Is not correct. This response indicates a willingness to co-operate in TTA-5.1.1 K2 1\n                              getting the review done but the analyst will be unable to make a full\n                              contribution without preparation and the review would therefore be less\n                              effective than it should be\n                            b) Is not correct. This response flags up the lack of preparation time but\n                              does not insist on allowing time for adequate preparation\n                            c) Is correct. The reviewer has raised the lack of preparation time and has\n                              suggested a solution to solve this issue\n                            d) Is not correct. This response is accurate, but preparation is about\n                              making a review as effective and efficient as possible. This is a\n                              requirement and an advantage of formal reviews",
    "learning_objective": "TTA-5.1.1",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "32",
    "question_text": "You are participating in an architectural review of a new product design. This is an embedded\n        product that has severe memory restrictions. Consider the following programming practices and\n        problems that can result from using those practices.                      \n                                                                                  \n        Programming Practices:                                                    \n                                                                                  \n             1. Connection pooling                                                \n             2. Data caching                                                      \n             3. Lazy instantiation                                                \n             4. Transaction concurrency                                           \n                                                                                  \n        Problems:                                                                 \n                                                                                  \n             A. Performance impact when the instantiation is needed               \n             B. Transaction loss due to processor unavailability                  \n             C. Errors in multi-threading logic                                   \n             D. Stale data                                                        \n                                                                                  \n        Which of the above programming practices could be used to reduce unnecessary memory use in\n        this scenario and what are the possible problems in using this practice?\n Select 1 option(s).",
    "options": {
      "A": "Practice 2, Problem D",
      "B": "Practice 4, Problem C",
      "C": "Practice 3, Problem A",
      "D": "Practice 1, Problem B"
    },
    "answers": [
      "C"
    ],
    "explanation": "a) Is not correct. Data caching helps with performance, not memory use TTA-5.2.1 K4 3\n                            b) Is not correct. Transaction concurrency uses more memory than\n                              running transactions sequentially\n                            c) Is correct. This would reduce unnecessary memory use but does have\n                              the possible problem of a delayed response when instantiation is\n                              performed\n                            d) Is not correct. Connection pooling can help memory and performance,\n                              but the possible problem is running out of connections, not losing a\n                              transaction",
    "learning_objective": "TTA-5.2.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "33",
    "question_text": "You are participating in an architectural design review of a new product design. This is a web-\n        based currency trading product that provides real-time information on prices for currencies\n        selected by the user.                                                     \n                                                                                  \n        The following list of practices are mentioned in the design as options for ensuring response times\n        of less than 1 second and real-time data accuracy under maximum expected loads.\n                                                                                  \n        Which of the following practices would you highlight as the MOST promising for achieving the\n        requirement?\n Select 1 option(s).",
    "options": {
      "A": "Load balancing",
      "B": "Data caching",
      "C": "Object orientation",
      "D": "Data replication"
    },
    "answers": [
      "A"
    ],
    "explanation": "a) Is correct. Load balancing should ensure that peak volumes of traffic TTA-5.2.1 K4 3\n                              can be handled by spreading the load among available servers\n                            b) Is not correct. Caching data may provide fast response times but may\n                              not guarantee that rapidly changing currency rates are accurately\n                              shown in real-time\n                            c) Is not correct. Object orientation practices do not target performance\n                              efficiency\n                            d) Is not correct. Data replication may not guarantee that the constantly\n                              changing currency rates are accurately shown in real-time",
    "learning_objective": "TTA-5.2.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "34",
    "question_text": "You are participating in a code review and have noticed a problem in the following section of\n        pseudo-code (assume *** indicates a comment).                             \n                                                                                  \n        *** this code checks for the validity of a card type ***                  \n            if                          then                                      \n              credit card is type “Discover”                                      \n                Display error message 437                                         \n            else if                                   then                        \n                  credit card is type “Visa” or “MasterCard”                      \n                Process purchase                                                  \n            else if                               then                            \n                  credit card is type “AmericanExpress”                           \n                Display error message 439                                         \n            else                                                                  \n                Display error message 440                                         \n            end if                                                                \n        Which of the following problems is demonstrated in this section of code and why should it be\n        corrected?\n Select 1 option(s).",
    "options": {
      "A": "The comment in the code is incorrect, resulting in a maintainability impact",
      "B": "An external library should be used to validate the credit card; thus, the code is inefficient because it does not re-use existing components",
      "C": "The most likely case is not tested first, resulting in a potential performance impact",
      "D": "There is no default clause, resulting in potential cases not being handled"
    },
    "answers": [
      "C"
    ],
    "explanation": "a) Is not correct. The comment is correct the code does check the TTA-5.2.2 K4 3\n                              validity of the card\n                            b) Is not correct. It is unlikely that there is an external library available that\n                              provides this functionality\n                            c) Is c                         cards will be entered more\n                                 orrect. It is unlikely that invalid ‘Discover’\n                              often than valid cards, so it is most likely the card will be Visa or\n                              MasterCard, and so that check should be performed first\n                            d) Is not correct. The else handles all conditions not met by the preceding\n                                           ‘  ’\n                               if\n                              ‘ ’ statements",
    "learning_objective": "TTA-5.2.2",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "35",
    "question_text": "You are participating in a code review and have noticed a problem in the following section of\n        pseudo-code (assume *** indicates a comment).                             \n                                                                                  \n        *** this pseudo-code calculates the average sales per month achieved by an\n        organization ***                                                          \n            0   program SALES                                                     \n            1   month_counter, sales_in_month, total_sales, fileID, number_of_months:\n            integer                                                               \n            2   average_sales: float                                              \n            3   begin                                                             \n            4       *** open the sales file***                                    \n            5                                                                     \n                    fileID = open file ( “Sales” )                                \n            6       if (fileID = 0) then                                          \n            7          *** File cannot be opened***                               \n            8          Display error message 333                                  \n            9       else                                                          \n            10         *** get the number of months you want to consider          \n            11         Read (number_of_months)                                    \n            12         month_counter = 1                                          \n            13         total_sales = 0                                            \n            14         while month_counter <= number_of_months loop               \n            15             *** get sales for month from sales file using the      \n            GetSales function***                                                  \n            16             sales_in_month = GetSales (month_counter, fileID)      \n            17             *** add the sales to the total***                      \n            18             total_sales = total_sales + sales_in_month             \n            19             month_counter = month_counter + 1                      \n            20         endloop                                                    \n            21         *** calculate the average monthly sales and output that    \n            value***                                                              \n            22         average_sales = total_sales / number_of_months             \n            23         Write (average_sales)                                      \n            24      endif                                                         \n            25  end program SALES                                                 \n        Which of the following problems is demonstrated in this section of code?\n Select 1 option(s).",
    "options": {
      "A": "Files are not checked for existence before attempting to access",
      "B": "Divisors are not tested for zero",
      "C": "Comments are inconsistent with the code",
      "D": "There are unused variables"
    },
    "answers": [
      "B"
    ],
    "explanation": "a) Is not correct.                                   TTA-5.2.2   K4     3\n                                        The variable “fileID” is checked before attempting to\n                              access the sales file (see lines 6, 7 and 8)\n                            b) Is correct. On line 22\n                                             the divisor “number_of_months” is not checked for\n                              0. This should be checked before line 22 is executed\n                            c) Is not correct. Comments and code are consistent\n                            d) Is not correct. All declared variables (lines 1 and 2) are used in the code",
    "learning_objective": "TTA-5.2.2",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "36",
    "question_text": "Which of the following are typical activities performed by a Technical Test Analyst when setting up\n        a test automation project?\n Select 2 option(s).",
    "options": {
      "A": "Designing the test data for the automated test cases",
      "B": "Reserving time for working on the test automation project in agreement with the test manager",
      "C": "Writing the test scripts based on keywords and data provided by Test Analysts",
      "D": "Determining who will be responsible for the analysis and design of test cases to be automated",
      "E": "Defining how the project’s test management tool will communicate with the new test automation tool"
    },
    "answers": [
      "B",
      "E"
    ],
    "explanation": "a) Is not correct. Test data design is normally the responsibility of the test TTA-6.1.1 K2 1\n                              analysts or business analysts\n                            b) Is correct. Scheduling the automation project and allocating time for\n                              maintenance are typically the responsibility of the TTA\n                            c) Is not correct. Writing test scripts is not part of the set-up of a test\n                              automation project\n                            d) Is not correct. Who performs test analysis and design (even of\n                              automated test cases) is not decided by the TTA\n                            e) Is correct. Defining the interface requirements between the automation\n                              tool and the existing test management tool is typically the responsibility\n                              of the TTA",
    "learning_objective": "TTA-6.1.1",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "37",
    "question_text": "Which of the following statements BEST captures the difference between data-driven and\n        keyword-driven test automation?\n Select 1 option(s).",
    "options": {
      "A": "Keyword-driven test automation can extend data-driven automation by defining keywords corresponding to actions in business processes",
      "B": "Data-driven test automation extends keyword-driven automation by storing test data in spreadsheets or databases",
      "C": "Data-driven test automation is more maintainable than keyword-driven test automation",
      "D": "Keyword-driven test automation requires fewer skills to develop than data-driven test automation"
    },
    "answers": [
      "A"
    ],
    "explanation": "a) Is correct. Keyword-driven tests can use a data-driven approach, but TTA-6.1.2 K2 1\n                              also have process-based keywords\n                            b) Is not correct. Data-driven test automation is not keyword-driven and so\n                              does not extend it. Keyword-driven testing requires test scripts that\n                              contain high-level keywords and supporting files (e.g., also data files)\n                              that contain low-level scripts, whereas data-driven testing only uses\n                              data files to contain the test data and expected results\n                            c) Is not correct. Keyword-driven tests are typically easier to maintain (due\n                              to the additional separation of business logic from test script\n                              implementation)\n                            d) Is not correct. Additional skills in the implementation of keywords as test\n                              automation code and the design of the keyword-driven framework mean\n                              that keyword-driven test automation typically requires more skills than\n                              data-driven test automation",
    "learning_objective": "TTA-6.1.2",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "38",
    "question_text": "Which of the following describes a common technical issue that causes test automation projects to\n        fail to achieve the planned return on investment?\n Select 1 option(s).",
    "options": {
      "A": "Elimination of duplication of information across tools",
      "B": "Removal of manual checking of data exchanges between tools",
      "C": "Use of an integrated development environment to simplify integration between tools",
      "D": "Failure to include software that automatically handles test failures"
    },
    "answers": [
      "D"
    ],
    "explanation": "a) Is not correct. The elimination of duplicated information across tools is a TTA-6.1.3 K2 1\n                              positive for a toolset\n                            b) Is not correct. Ideally data should be exchanged between tools with no\n                              manual intervention\n                            c) Is not correct. Using an IDE is often worthwhile if the\n                                                                  tools ‘fit’ the IDE\n                            d) Is correct. In any test automation design, it is important to anticipate\n                              and handle software failures",
    "learning_objective": "TTA-6.1.3",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "39",
    "question_text": "Assume that you are involved in testing a mature application. This application is an online dating\n        service that allows users: to enter a profile of themselves; to meet orientation-appropriate people\n        who would be a good match for them; to arrange social events with those people; and, to block\n        people they do not want to contact them.                                  \n                                                                                  \n        Defects and test cases are managed in an existing commercial test management tool, which is\n        working well. Source code and other project work products are stored in an open-source\n        configuration management system.                                          \n                                                                                  \n        Your manager directs you to help her select a test execution automation tool to automate most of\n        the regression testing.                                                   \n                                                                                  \n        Assume you are using a keyword-driven automation approach. Which of the options would be the\n        MOST LIKELY keywords for this application?\n Select 2 option(s).",
    "options": {
      "A": "Enter_Test_Data",
      "B": "Remove_Test_Data",
      "C": "Enter_Profile",
      "D": "Find_Match",
      "E": "Pay_Bill"
    },
    "answers": [
      "C",
      "D"
    ],
    "explanation": "a) Is not correct. The keywords are supposed to be about the business TTA-6.1.4 K3 2\n                              process supported by the application, not the test process\n                            b) Is not correct. The keywords are supposed to be about the business\n                              process supported by the application, not the test process\n                            c) Is correct. It is explicitly mentioned in the scenario as being a capability\n                              of the application\n                            d) Is correct. It is explicitly mentioned in the scenario as being a capability\n                              of the application\n                            e) Is not correct. This might be a capability of the application, but it is not\n                              mentioned in the scenario, so it is not the most likely keyword on the\n                              list, and also since there was no mention that the product charges its\n                              customers",
    "learning_objective": "TTA-6.1.4",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "40",
    "question_text": "Which of the following statements about fault seeding tools is correct?\n Select 1 option(s).",
    "options": {
      "A": "These tools insert defects into the source code to test the input checking capabilities of the software",
      "B": "These tools insert defects into the source code to check the level of fault tolerance of the software",
      "C": "These tools insert defects into the source code to test the effectiveness of the test suite",
      "D": "These tools are generally used by the test analyst to measure the coverage achieved by specified tests"
    },
    "answers": [
      "C"
    ],
    "explanation": "a) Is not correct. Input checking can be done by mutating test inputs, but TTA-6.2.1 K2 1\n                              to test input checking the inputs would need to be mutated\n                            b) Is not correct. This is the task of the fault injection tools\n                            c) Is correct. The mutated code is executed against the test suite to\n                              determine how well the test suite can detect the mutations (defects)\n                            d) Is not correct. These tools are generally used by the technical test\n                              analyst, or the developer when testing newly developed code",
    "learning_objective": "TTA-6.2.1",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "41",
    "question_text": "Which of the following statements about performance testing tools is CORRECT?\n Select 1 option(s).",
    "options": {
      "A": "These tools drive the application at the communications protocol level rather than through its user interface to measure response times more accurately",
      "B": "These tools generate a load by simulating many virtual users using operational profiles to generate input test data",
      "C": "These tools capture a script from one individual user interaction and multiple identical copies of this script are then replayed in parallel to represent the full range of possible users",
      "D": "These tools take a wide range of measurements after test execution to enable the analysis of the most significant performance characteristics of the test object"
    },
    "answers": [
      "B"
    ],
    "explanation": "a) Is not correct. If the accurate measurement of response times was an TTA-6.2.2 K2 1\n                              issue, then the tools would have to drive the application using its user\n                              interface\n                            b) Is correct. Performance testing tools are used to generate defined loads\n                              based on operational profiles\n                            c) Is not correct. The script needs to be changed to take account of the\n                              variability of different users and their transactions\n                            d) Is not correct. Measurements need to be taken during execution",
    "learning_objective": "TTA-6.2.2",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "42",
    "question_text": "Which of the following CORRECTLY describe the objectives of tools supporting web-based\n        testing?\n Select 2 option(s).",
    "options": {
      "A": "To generate test cases by executing a model of the test object’s required behavior",
      "B": "To isolate faults in the user interface by changing variable values during line-by-line code execution",
      "C": "To measure the quality of a test suite by injecting defects into the test object",
      "D": "To check for accessibility standards violations",
      "E": "To check for orphaned files by scanning through the server"
    },
    "answers": [
      "D",
      "E"
    ],
    "explanation": "a) Is not correct. This describes an MBT tool        TTA-6.2.3   K2     1\n                            b) Is not correct. This describes a debugger\n                            c) Is not correct. This describes a fault seeding tool\n                            d) Is correct. Tools for testing websites may include the functionality to\n                              check for violations of accessibility standards, such as Section 508 in\n                              the U.S. or M/376 in Europe\n                            e) Is correct. Tools for testing websites may include the functionality to\n                              scan through server code, checking for orphaned (unlinked) files\n                              previously accessed by the website",
    "learning_objective": "TTA-6.2.3",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "43",
    "question_text": "Which of the following BEST describes how tools can support the practice of model-based testing\n        (MBT)?\n Select 1 option(s).",
    "options": {
      "A": "MBT tools are used to generate test cases that reflect the required behavior presented in a model of the test object",
      "B": "MBT tools execute the model of the test object’s behavior to identify defects rather than executing tests on the test object",
      "C": "MBT tools provide an internal view of the test object and are used to automatically generate white-box test cases",
      "D": "MBT tools automatically generate test cases to achieve a required level of coverage of the test object source code"
    },
    "answers": [
      "A"
    ],
    "explanation": "a) Is correct. The required behavior represented in the model (e.g., state TTA-6.2.4 K2 1\n                              model, Petri Net) is typically used to automatically generate many test\n                              cases corresponding to the required behavior\n                            b) Is not correct. MBT tools do\n                                                 execute the model of the test object’s\n                              behavior, but they do this to generate test cases which are then\n                              executed on the test object to identify defects\n                            c) Is not correct. MBT tools use a model of required behavior, not an\n                              internal view of the test object, to generate test cases\n                            d) Is not correct. MBT tools generate test cases to achieve a level of\n                              coverage of the model of required behavior, rather than of the test\n                              object source code (to which they have no access)",
    "learning_objective": "TTA-6.2.4",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "44",
    "question_text": "Which of the following statements about component testing tools and build automation tools is\n        TRUE?\n Select 1 option(s).",
    "options": {
      "A": "An xUnit framework can be used to automate component testing; build automation tools execute automated component tests",
      "B": "A JUnit framework can simplify automation of component testing in a Java environment; build automation tools automatically trigger the component tests whenever a component changes in a build",
      "C": "Component testing frameworks can simplify automation of component testing; build automation tools cause a new build to be triggered when a component is changed",
      "D": "Component testing tools can be used against multiple programming languages; build automation tools are triggered when a component is tested"
    },
    "answers": [
      "C"
    ],
    "explanation": "a) Is not correct. According to the syllabus, component tests are executed TTA-6.2.5 K2 1\n                              by other tools after build is completed\n                            b) Is not correct. The statement about component test tools is true,\n                              especially with Java. The statement about build automation tools is not\n                              correct. Component test execution is triggered after build completion,\n                              by other tools\n                            c) Is correct. Both statements are true\n                            d) Is not correct. Most component testing tools are language-specific, and\n                              the build must be done before component test execution",
    "learning_objective": "TTA-6.2.5",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "45",
    "question_text": "Which of the following statements BEST captures the purpose of an emulator when used to\n        support mobile application testing?\n Select 1 option(s).",
    "options": {
      "A": "A mobile emulator is used to replace real mobile devices in testing but is limited to initial functional testing",
      "B": "A mobile emulator is used to replace real mobile devices in testing but does not allow early- on usability testing such as evaluating user interface aesthetics",
      "C": "A mobile emulator is used to test different features of a mobile application early on, using specially compiled versions of the software, that would not run on a real device",
      "D": "A mobile emulator allows dynamic testing of a mobile application that has been compiled and packaged for a specific platform without installing it on a real device"
    },
    "answers": [
      "D"
    ],
    "explanation": "a) Is not correct. An emulator is not restricted to initial functional tests it TTA-6.2.6 K2 1\n                              can also be used for tests later in the life cycle, and for non-functional\n                              tests\n                            b) Is not correct. An emulator may allow functional as well as non-\n                              functional tests. Although most usability testing will and should be done\n                              on real devices, early usability tests such as a heuristic evaluation\n                              might be done using an emulator\n                            c) Is not correct. Versions that run on an emulator should also run on the\n                              real devic\n                            d) Is correct. The purpose of an emulator is to test device-specific\n                              behaviour of an application as early as possible even if the device is\n                              not available to the tester\n            Appendix:  Answers   to Additional Questions",
    "learning_objective": "TTA-6.2.6",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "46",
    "question_text": "Which two white-box test techniques are most suited for detecting unreachable code paths within a component?\nSelect 2 option(s).",
    "options": {
      "A": "Statement coverage",
      "B": "Decision (branch) coverage",
      "C": "Modified Condition/Decision Coverage (MC/DC)",
      "D": "Path coverage",
      "E": "Equivalence partitioning"
    },
    "answers": ["C","D"],
    "explanation": "C) MC/DC is appropriate to detect combined condition coverage and thus can reveal unreachable code paths. D) Path coverage directly targets all possible paths, including unreachable ones. A) Statement coverage may leave unreachable paths untested. B) Decision coverage covers branches but might still miss complex paths. E) Equivalence partitioning is a black-box technique, not white-box.",
    "learning_objective": "TTA-2.2.2",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "47",
    "question_text": "Select two static analysis activities that a Technical Test Analyst can perform when reviewing source code.\nSelect 2 option(s).",
    "options": {
      "A": "Control flow analysis to identify loops with no exit condition",
      "B": "Creating automation scripts for performance testing",
      "C": "Data-flow analysis to find variables that are defined but not used",
      "D": "Running a dynamic memory leak test",
      "E": "Checking API endpoints for correct return values"
    },
    "answers": ["A","C"],
    "explanation": "A) Control flow analysis is a common static analysis activity. C) Data-flow analysis is also static and can identify defined-use anomalies. B) and D) are dynamic analysis. E) Checking API return values is typically dynamic or functional testing.",
    "learning_objective": "TTA-3.3.1",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "48",
    "question_text": "Which of the following are quality characteristics from the ISTQB perspective that a Technical Test Analyst should evaluate when assessing a component’s non-functional behaviour?\nSelect 2 option(s).",
    "options": {
      "A": "Usability",
      "B": "Maintainability",
      "C": "Functionality",
      "D": "Performance",
      "E": "User satisfaction"
    },
    "answers": ["B","D"],
    "explanation": "B) Maintainability is a technical quality characteristic in the TTA syllabus. D) Performance is likewise a non-functional characteristic tested by a TTA. A) Usability is typically a user-facing characteristic (TA domain). C) Functionality is covered by TA not specifically TTA. E) User satisfaction is too subjective and not a standard technical characteristic in the TTA syllabus.",
    "learning_objective": "TTA-4.2",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "49",
    "question_text": "A review of the system architecture reveals that a database transaction might hold locks for an indeterminate period causing potential deadlock. Which of the following actions should a Technical Test Analyst include?\nSelect 1 option.",
    "options": {
      "A": "Ignore since it’s the developer’s responsibility",
      "B": "Schedule a performance test with high concurrency to evaluate lock contention",
      "C": "Wait until functional testing is complete",
      "D": "Add this risk to the component test plan only"
    },
    "answers": ["B"],
    "explanation": "B) Correct. High concurrency performance testing can reveal lock contention and deadlock risk. A) is incorrect – the TTA contributes to identifying technical risks. C) Waiting delays risk mitigation. D) A component test plan alone may not simulate real concurrency or performance conditions.",
    "learning_objective": "TTA-5.1",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "50",
   "question_text": "Which two considerations should be taken into account when selecting a test automation tool for component testing from a technical test analyst viewpoint?",
  "options": {
    "A": "Licensing cost only",
    "B": "Ability to instrument code to measure coverage",
    "C": "Support for the target technology stack at component level",
    "D": "Number of available business keywords",
    "E": "Integration with version control and CI/CD pipelines"
  },
  "answers": ["C", "E"],
  "explanation": "C) **Support for the target technology stack at the component level** is the most important consideration. A tool that supports the specific technology stack you're working with is essential for ensuring that the tests can interact with the system components properly. It also inherently subsumes the idea of measuring code coverage (as instrumentation typically comes as part of such support). B) While measuring coverage is important, **C** already covers this requirement. E) **Integration with version control and CI/CD pipelines** is important for continuous testing and automation, ensuring that tests can be seamlessly integrated into the development lifecycle. A) **Licensing cost** is important but should not be the primary consideration. D) **Number of available business keywords** is more relevant to test automation engineers rather than technical test analysts focused on component-level testing.",
  "learning_objective": "TTA-2.3",
  "klevel": "K3",
  "points": 2
},
  {
    "question_id": "51",
    "question_text": "In dynamic analysis of a component, which two defects are most likely to be identified?\nSelect 2 option(s).",
    "options": {
      "A": "Memory leak in a long-running loop",
      "B": "Dead code without unit tests",
      "C": "Syntax error in code",
      "D": "Unhandled exception thrown at runtime",
      "E": "Requirements omission in functional specification"
    },
    "answers": ["A","D"],
    "explanation": "A) Memory leak is uncovered by dynamic analysis. D) Unhandled runtime exception is also found when the component executes. B) Dead code is static. C) Syntax error is compile-time and caught earlier. E) Requirements omission is functional domain.",
    "learning_objective": "TTA-3.4",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "52",
    "question_text": "Which two structural coverage criteria are strictly stronger than Decision (branch) coverage?\nSelect 2 option(s).",
    "options": {
      "A": "Statement coverage",
      "B": "Condition coverage",
      "C": "Multiple condition coverage (MCC)",
      "D": "Modified condition/decision coverage (MC/DC)",
      "E": "Path coverage"
    },
    "answers": ["D","E"],
    "explanation": "D) MC/DC is stronger than decision coverage because it requires each condition to independently affect the outcome. E) Path coverage encompasses all possible paths, therefore stronger. A) Statement coverage is weaker. B) Condition coverage is not strictly stronger than decision coverage in all cases. C) MCC is strong but often equivalent or slightly different; MC/DC and path are standard stronger criteria.",
    "learning_objective": "TTA-2.2.3",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "53",
    "question_text": "When configuring a static source-code analysis tool for a component, which two issues should a Technical Test Analyst specifically configure rules for?\nSelect 2 option(s).",
    "options": {
      "A": "Enforcing consistent indentation style",
      "B": "Detecting unused variables and unreachable code",
      "C": "Detecting outdated comments",
      "D": "Finding insecure API endpoints",
      "E": "Ensuring the correct business logic workflow"
    },
    "answers": ["B","D"],
    "explanation": "B) Unused variables and unreachable code are structural defects detected by static analysis. D) Insecure API endpoints may be detected as part of security-related static analysis by TTA. A) Indentation is style only. C) Comments may not indicate functional problems. E) Business logic workflows are more functional/TA domain.",
    "learning_objective": "TTA-3.2",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "54",
    "question_text": "Which one of the following is the most appropriate objective when performing component-level performance testing as a Technical Test Analyst?\nSelect 1 option.",
    "options": {
      "A": "Measure end-to-end user satisfaction time",
      "B": "Determine maximum throughput of the component under stress",
      "C": "Validate user interface ergonomics",
      "D": "Assess readability of the code"
    },
    "answers": ["B"],
    "explanation": "B) Correct. At component level, the TTA aims to determine maximum throughput under stress. A) UI satisfaction is not component-level. C) Ergonomics is UI/UX domain. D) Code readability is not performance testing objective.",
    "learning_objective": "TTA-4.3",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "55",
    "question_text": "What is the primary goal of static testing techniques in component testing?\nSelect 1 option.",
    "options": {
      "A": "To measure the scalability of the component",
      "B": "To identify defects in the component's design and code early in the development cycle",
      "C": "To simulate real user interactions with the component",
      "D": "To assess the compatibility of the component with other components"
    },
    "answers": ["B"],
    "explanation": "B) Correct. Static testing techniques focus on early defect detection by reviewing the design and code without executing the component. A) Scalability is addressed by dynamic testing. C) User interaction testing is dynamic. D) Compatibility testing is a separate activity.",
    "learning_objective": "TTA-3.2",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "56",
    "question_text": "Which of the following tools would be most appropriate for a Technical Test Analyst to use when testing the performance of a component under high load conditions?\nSelect 1 option.",
    "options": {
      "A": "JUnit",
      "B": "LoadRunner",
      "C": "Selenium",
      "D": "SonarQube"
    },
    "answers": ["B"],
    "explanation": "B) Correct. LoadRunner is a performance testing tool used to simulate high loads and measure component performance. A) JUnit is for unit testing. C) Selenium is for functional testing. D) SonarQube is used for code quality analysis.",
    "learning_objective": "TTA-4.5",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "57",
    "question_text": "What is the focus of boundary value analysis in component testing?\nSelect 1 option.",
    "options": {
      "A": "To test the component's behavior under extreme values, including the boundaries of input ranges",
      "B": "To identify possible security vulnerabilities in the component",
      "C": "To measure the component’s performance under different stress levels",
      "D": "To ensure that the component’s UI meets the specified requirements"
    },
    "answers": ["A"],
    "explanation": "A) Correct. Boundary value analysis tests the component’s behavior at the edges of input ranges to identify defects. B) Security testing has a different focus. C) Performance testing focuses on load and stress but not boundary values. D) UI testing is a different type of testing.",
    "learning_objective": "TTA-3.3",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "58",
    "question_text": "During component testing, which of the following techniques would a Technical Test Analyst use to identify potential defects in the system's handling of input data?\nSelect up to 2 options.",
    "options": {
      "A": "Boundary Value Analysis",
      "B": "Equivalence Partitioning",
      "C": "State Transition Testing",
      "D": "Load Testing"
    },
    "answers": ["A", "B"],
    "explanation": "A) Correct. Boundary Value Analysis tests the behavior at the edges of input ranges. B) Correct. Equivalence Partitioning divides input data into valid and invalid partitions to simplify testing. C) State Transition Testing is for testing system behavior changes, not input data. D) Load Testing focuses on performance, not input handling.",
    "learning_objective": "TTA-3.4",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "59",
    "question_text": "Which of the following best describes the primary objective of regression testing for a component?\nSelect 1 option.",
    "options": {
      "A": "To ensure that the component continues to work as expected after changes or updates",
      "B": "To test the component’s ability to handle extreme load conditions",
      "C": "To check if the component integrates properly with other components",
      "D": "To verify the security of the component against common vulnerabilities"
    },
    "answers": ["A"],
    "explanation": "A) Correct. Regression testing ensures that changes to a component do not introduce new defects and that it still performs as expected. B) Load testing is a different type of testing. C) Integration testing focuses on interactions, not regression. D) Security testing is not the focus of regression testing.",
    "learning_objective": "TTA-4.2",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "60",
    "question_text": "Which of the following is the most appropriate objective when performing component-level performance testing as a Technical Test Analyst?\nSelect 1 option.",
    "options": {
      "A": "Measure end-to-end user satisfaction time",
      "B": "Determine maximum throughput of the component under stress",
      "C": "Validate user interface ergonomics",
      "D": "Assess readability of the code"
    },
    "answers": ["B"],
    "explanation": "B) Correct. At component level, the TTA aims to determine maximum throughput under stress. A) UI satisfaction is not component-level. C) Ergonomics is UI/UX domain. D) Code readability is not performance testing objective.",
    "learning_objective": "TTA-4.3",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "61",
    "question_text": "Which of the following best describes a key responsibility of a Technical Test Analyst during component integration testing?\nSelect 1 option.",
    "options": {
      "A": "To verify the component interfaces and interactions between components are working correctly",
      "B": "To ensure the component performs well under load",
      "C": "To test whether the component meets the user requirements",
      "D": "To review the component’s code for optimization opportunities"
    },
    "answers": ["A"],
    "explanation": "A) Correct. During component integration testing, the TTA ensures that the interfaces between components function correctly. B) Performance testing is done in a different context. C) User requirement testing is functional testing, not integration. D) Code review is done by developers, not testers.",
    "learning_objective": "TTA-6.1",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "62",
    "question_text": "When performing a security test on a component, which of the following activities should be prioritized?\nSelect up to 2 options.",
    "options": {
      "A": "Testing for common vulnerabilities such as SQL injection and cross-site scripting",
      "B": "Testing the component’s ability to handle normal load without performance degradation",
      "C": "Ensuring the component is resistant to unauthorized access or manipulation",
      "D": "Verifying that the component is compatible with the operating system"
    },
    "answers": ["A", "C"],
    "explanation": "A) Correct. Security testing focuses on identifying vulnerabilities like SQL injection. C) Correct. It’s crucial to test the component’s resistance to unauthorized access. B) Performance testing focuses on load handling, but it's not a primary security concern. D) Compatibility testing is a separate activity.",
    "learning_objective": "TTA-5.2",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "63",
    "question_text": "Which of the following best describes how a Technical Test Analyst might evaluate the efficiency of a component?\nSelect 1 option.",
    "options": {
      "A": "By measuring the resource consumption, such as CPU and memory usage during execution",
      "B": "By checking whether the component meets the specified user requirements",
      "C": "By verifying if the component integrates correctly with other components",
      "D": "By assessing the component's ability to handle different types of input data"
    },
    "answers": ["A"],
    "explanation": "A) Correct. Efficiency testing involves measuring resource consumption, such as CPU and memory usage. B) Checking user requirements is functional testing. C) Integration testing focuses on interactions, not efficiency. D) Handling different input data is functional testing, not efficiency testing.",
    "learning_objective": "TTA-4.6",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "64",
    "question_text": "Which of the following best describes a key objective when performing component-level performance testing?\nSelect up to 2 options.",
    "options": {
      "A": "Measure the response time and throughput under various load conditions",
      "B": "Check whether the component is working as per the functional specification",
      "C": "Determine the number of concurrent users the component can handle without failure",
      "D": "Verify if the component meets the UI design requirements"
    },
    "answers": ["A", "C"],
    "explanation": "A) Correct. Performance testing involves measuring response time and throughput under different load conditions. C) Correct. Determining concurrency is a core component of performance testing. B) Functional testing focuses on meeting specifications, not performance. D) UI design verification is not part of performance testing.",
    "learning_objective": "TTA-4.4",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "65",
    "question_text": "Given the following code snippet, which of the following statements is correct regarding the test coverage for this component?\n\n```java\npublic class Calculator {\n    public int add(int a, int b) {\n        return a + b;\n    }\n    public int subtract(int a, int b) {\n        return a - b;\n    }\n    public int multiply(int a, int b) {\n        return a * b;\n    }\n    public int divide(int a, int b) {\n        if (b == 0) {\n            throw new ArithmeticException('Division by zero');\n        }\n        return a / b;\n    }\n}\n```\n\nWhich of the following is the most appropriate testing approach to cover this code thoroughly?\nSelect 1 option.",
    "options": {
      "A": "Test all four methods (add, subtract, multiply, divide) using boundary value analysis",
      "B": "Test the divide method with normal and boundary values, focusing on zero as the divisor",
      "C": "Test the add, subtract, and multiply methods with a wide range of values, but omit the divide method",
      "D": "Test the divide method for division by zero and for valid input values only"
    },
    "answers": ["B"],
    "explanation": "B) Correct. The divide method requires testing for division by zero, which is a boundary case, and normal values. A) Boundary value analysis is not needed for all methods, especially for add, subtract, and multiply. C) Omitting the divide method misses critical edge cases, such as division by zero. D) Only testing for division by zero does not fully cover the method.",
    "learning_objective": "TTA-3.3",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "66",
    "question_text": "Consider the following state transition diagram for a component responsible for processing orders. Analyze the diagram and determine which of the following statements is most accurate.\n\n```plaintext\n +------------------+    Place Order    +-----------------+\n |                  | ----------------->|                 |\n | Idle             |                   | Order Placed    |\n |                  | <----------------|                 |\n +------------------+    Process Order  +-----------------+\n                        ----------------->|                 |\n                                    | Order Processed |\n                                    |                 |\n                                    +-----------------+ \n``` \n\nWhich of the following is the most accurate test strategy?",
    "options": {
      "A": "Test the transition from Idle to Order Placed, then from Order Placed to Order Processed, using valid inputs only",
      "B": "Test the transition from Idle to Order Placed and Order Placed to Order Processed, including invalid inputs such as placing an order while idle",
      "C": "Test only the transition from Idle to Order Placed with valid inputs and skip the rest of the diagram",
      "D": "Test only the transition from Order Placed to Order Processed for valid inputs"
    },
    "answers": ["B"],
    "explanation": "B) Correct. To ensure thorough testing, transitions from Idle to Order Placed and Order Placed to Order Processed should be tested with both valid and invalid inputs. A) Omitting invalid inputs would miss key edge cases. C) Only testing one transition is insufficient. D) Omitting other transitions reduces test coverage.",
    "learning_objective": "TTA-6.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "67",
    "question_text": "Given the following performance test results showing response times under various load conditions, analyze the data and select the correct conclusion.\n\n```plaintext\n Load (Users)  | Response Time (ms)\n-----------------------------------------\n 50            | 120\n 100           | 250\n 200           | 600\n 400           | 1200\n 800           | 3000\n``` \n\nWhich of the following conclusions can be drawn from this performance test data?",
    "options": {
      "A": "The system scales well up to 200 users, but performance starts to degrade rapidly after that",
      "B": "The system has consistent performance as the load increases, with little change in response time",
      "C": "The system is unable to handle more than 50 users effectively, as response times exceed acceptable limits",
      "D": "The system's performance does not degrade with increasing load, indicating high scalability"
    },
    "answers": ["A"],
    "explanation": "A) Correct. The response time increases dramatically as the load grows, especially after 200 users, indicating that the system starts to struggle with higher loads. B) The performance degrades significantly as load increases, so consistency is not observed. C) The system handles up to 200 users but begins to degrade after that. D) The performance degrades sharply, so scalability is not high.",
    "learning_objective": "TTA-4.3",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "68",
    "question_text": "Given a set of test cases for validating user input in a form, analyze the coverage based on the following input values:\n\n| Test Case ID | Age  | Email            | Valid Input? |\n|--------------|------|------------------|--------------|\n| TC01         | 25   | valid@example.com | Yes          |\n| TC02         | 15   | valid@example.com | No           |\n| TC03         | 30   | invalid.com       | No           |\n| TC04         | 45   | valid@example.com | Yes          |\n| TC05         | 20   | valid@example.com | Yes          |\n\nBased on the provided test cases, which additional test case should be included for comprehensive coverage?",
    "options": {
      "A": "Test with age 60 and email valid@example.com",
      "B": "Test with age 15 and email valid@example.com",
      "C": "Test with age 30 and email valid@example.com",
      "D": "Test with age 20 and email invalid@example.com"
    },
    "answers": ["D"],
    "explanation": "D) Correct. Testing with age 20 and an invalid email address will cover the case where the email is invalid while keeping age valid. A) Age 60 is not necessary since other values are already covered. B) Age 15 with a valid email is already covered in TC02. C) The age 30 and valid email is already covered in TC03.",
    "learning_objective": "TTA-3.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "69",
    "question_text": "Consider the following sequence diagram of a payment system. Based on the diagram, which of the following scenarios should be tested to ensure full functional coverage?\n\n```plaintext\n  User    -> PaymentService    -> BankAPI    -> PaymentGateway\n  |             |               |               |\n  |-------------|               |               |\n  | MakePayment |               |               |\n  |             | ProcessPayment|               |\n  |             |               | SendPayment   |\n  |             |               |               |\n  |             |               | ConfirmPayment|\n  |             |               |               | \n``` \n\nSelect the correct testing scenario.",
    "options": {
      "A": "Test the full payment flow with valid payment details only",
      "B": "Test the full payment flow including invalid payment details and failed payments from the BankAPI",
      "C": "Test only the User to PaymentService interaction and skip the rest",
      "D": "Test only the PaymentGateway response time under valid conditions"
    },
    "answers": ["B"],
    "explanation": "B) Correct. Testing the full payment flow with both valid and invalid inputs ensures comprehensive coverage. A) Valid payments are necessary but not sufficient. C) Omitting the BankAPI and PaymentGateway reduces coverage. D) Response time testing is important, but it doesn't cover all functional aspects.",
    "learning_objective": "TTA-6.2",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "70",
    "question_text": "Given the following graph showing the success rate of API requests over time, which of the following conclusions can be drawn?\n\n```plaintext\n Time (hrs)    | Success Rate (%)\n----------------------------------\n 0             | 100%\n 1             | 100%\n 2             | 90%\n 3             | 85%\n 4             | 60%\n 5             | 45%\n``` \n\nSelect the most accurate conclusion.",
    "options": {
      "A": "The API is performing well throughout the entire period with no significant issues",
      "B": "The API performance starts to degrade after 3 hours, indicating possible scalability issues",
      "C": "The API's performance is consistent and unaffected by time",
      "D": "The API reaches 0% success rate at the 5-hour mark, suggesting a complete failure"
    },
    "answers": ["B"],
    "explanation": "B) Correct. The performance degrades after 3 hours, suggesting scalability issues or an issue that worsens over time. A) The performance degradation is significant after 3 hours. C) The performance is not consistent and degrades significantly. D) The API doesn't reach 0%, but the decrease is a concern.",
    "learning_objective": "TTA-4.6",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "71",
    "question_text": "Given the following code snippet for handling login attempts, analyze the potential security vulnerabilities in the code:\n\n```python\nclass LoginHandler:\n    def login(self, username, password):\n        if username == 'admin' and password == 'password123':\n            return 'Login successful'\n        else:\n            return 'Login failed'\n``` \n\nWhich of the following vulnerabilities exists in this code?",
    "options": {
      "A": "The code uses hardcoded credentials, making it vulnerable to credential leakage",
      "B": "The password is not being hashed, making it vulnerable to theft if intercepted",
      "C": "The code does not limit the number of failed login attempts, making it vulnerable to brute force attacks",
      "D": "All of the above"
    },
    "answers": ["D"],
    "explanation": "D) Correct. The code has multiple security flaws: hardcoded credentials (A), lack of password hashing (B), and no limit on failed login attempts (C). These make it vulnerable to various attacks.",
    "learning_objective": "TTA-5.3",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "72",
    "question_text": "Analyze the following graph depicting the response times of a component under various levels of load. Based on the graph, which of the following actions would be appropriate to improve system performance?\n\n```plaintext\n Load (Users)  | Response Time (ms)\n----------------------------------------\n 0             | 100\n 50            | 200\n 100           | 400\n 200           | 1200\n 400           | 3500\n 800           | 9000\n``` \n\nSelect the most appropriate action to take.",
    "options": {
      "A": "Optimize the system for handling high numbers of users to reduce response times at higher loads",
      "B": "Increase the system's load limit without improving performance",
      "C": "Ignore the response time issue, as it only affects users beyond 400",
      "D": "Reduce the maximum allowed number of users to 100 to maintain performance"
    },
    "answers": ["A"],
    "explanation": "A) Correct. The response time increases significantly as the load grows, suggesting the need to optimize the system to handle more users efficiently. B) Increasing the load without addressing performance would worsen the problem. C) Ignoring the issue would result in poor performance for higher loads. D) Limiting the number of users would reduce load, but optimization is a better long-term solution.",
    "learning_objective": "TTA-4.3",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "73",
    "question_text": "Given the following SQL query, identify the potential performance issue when the query is executed on a large dataset:\n\n```sql\nSELECT * FROM orders WHERE customer_id = '12345' AND order_date > '2023-01-01';\n``` \n\nWhat is the potential performance issue with this query?",
    "options": {
      "A": "The query uses a wildcard (*) which can be inefficient for large datasets",
      "B": "The query lacks an index on the customer_id column, leading to a full table scan",
      "C": "The query's filter condition does not use partitioning, leading to inefficiency in querying large datasets",
      "D": "All of the above"
    },
    "answers": ["D"],
    "explanation": "D) Correct. All the mentioned factors contribute to poor performance: the use of wildcard (*), missing indexes, and the lack of partitioning in large datasets.",
    "learning_objective": "TTA-4.1",
    "klevel": "K4",
    "points": 3
  },
{
    "question_id": "74",
    "question_text": "Consider the following SQL injection vulnerability in the login form processing logic:\n\n```python\ndef authenticate_user(username, password):\n    query = \"SELECT * FROM users WHERE username = '\" + username + \"' AND password = '\" + password + \"'\";\n    result = db.execute(query)\n    return result\n``` \n\nWhich of the following best addresses this vulnerability?",
    "options": {
      "A": "Use parameterized queries to prevent SQL injection attacks",
      "B": "Escape the special characters in user input to prevent SQL injection",
      "C": "Implement input length validation to prevent SQL injection",
      "D": "Log all failed login attempts for analysis"
    },
    "answers": ["A"],
    "explanation": "A) Correct. Parameterized queries ensure that user input is treated as data, not code, preventing SQL injection. B) While escaping special characters helps, parameterized queries are the most secure method. C) Length validation is not enough to prevent SQL injection. D) Logging failed attempts is useful for security monitoring but does not prevent SQL injection.",
    "learning_objective": "TTA-5.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "75",
    "question_text": "Given the following risk assessment for a web application, identify the most critical area to test based on the provided severity and likelihood scores:\n\n```plaintext\n Risk           | Severity | Likelihood\n-------------------------------------------\n Cross-site Scripting | High    | High\n SQL Injection       | High    | Medium\n Session Fixation    | Medium  | Low\n``` \n\nWhich risk should be prioritized for testing?",
    "options": {
      "A": "Cross-site scripting, as it has the highest severity and likelihood",
      "B": "SQL injection, due to its high severity",
      "C": "Session fixation, because of its medium severity",
      "D": "None, as all risks have low likelihood"
    },
    "answers": ["A"],
    "explanation": "A) Correct. Cross-site scripting is the most critical risk to test because it has both high severity and high likelihood. B) While SQL injection is high severity, its likelihood is medium, making it less urgent than XSS. C) Session fixation has low likelihood and medium severity, making it less of a priority. D) Likelihood and severity should always guide testing priorities.",
    "learning_objective": "TTA-2.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "76",
    "question_text": "Analyze the following test execution results for a component under stress testing:\n\n```plaintext\n Load (Users)  | Response Time (ms) | Errors (%)\n-------------------------------------------------\n 50            | 120                | 0%\n 100           | 250                | 0%\n 200           | 800                | 5%\n 400           | 2000               | 15%\n 800           | 5000               | 40%\n``` \n\nWhat is the most appropriate conclusion about system performance?",
    "options": {
      "A": "The system performs well under low to moderate load, but performance degrades significantly at higher loads",
      "B": "The system can handle up to 800 users with no performance issues",
      "C": "The response time remains constant across all load levels, suggesting excellent scalability",
      "D": "The system is unable to handle even 200 users effectively"
    },
    "answers": ["A"],
    "explanation": "A) Correct. As the load increases, both response time and error rate significantly degrade, indicating performance issues under high load. B) The system struggles at 800 users, with significant performance degradation. C) Performance degradation is observed, especially above 200 users. D) The system handles up to 200 users, but struggles beyond that.",
    "learning_objective": "TTA-4.4",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "77",
    "question_text": "Given the following test scenario for a web form that accepts age input, analyze the potential test coverage gaps:\n\n| Test Case ID | Age  | Valid Input? |\n|--------------|------|--------------|\n| TC01         | 18   | Yes          |\n| TC02         | 65   | Yes          |\n| TC03         | 120  | No           |\n| TC04         | -5   | No           |\n| TC05         | 0    | No           |\n| TC06         | 25   | Yes          |\n\nWhat additional test case should be included for comprehensive coverage?",
    "options": {
      "A": "Test with age 100 and a valid email address",
      "B": "Test with age 30 and a valid email address",
      "C": "Test with age 17, just below the valid age limit",
      "D": "Test with age 50 and a valid email address"
    },
    "answers": ["C"],
    "explanation": "C) Correct. Testing with age 17 (just below the valid age limit) ensures that boundary conditions are thoroughly covered. A) Age 100 is unlikely to be relevant based on the valid range. B) Age 30 is already covered in TC06. D) Testing with age 50 is redundant as age 25 and 65 are already covered.",
    "learning_objective": "TTA-3.2",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "78",
    "question_text": "Consider the following state machine diagram for a login system:\n\n```plaintext\n +------------+  enter username  +------------+  enter password  +------------+ \n |            |----------------->|            |----------------->|            |\n |  Idle      |                 | Username   |                 | Password   |\n |            |<----------------| Validated  |<----------------| Validated  |\n +------------+  invalid username +------------+  invalid password +------------+ \n``` \n\nWhich of the following test cases is necessary to ensure complete functional coverage?",
    "options": {
      "A": "Test with valid username and valid password",
      "B": "Test with invalid username and valid password",
      "C": "Test with valid username and invalid password",
      "D": "Test with both invalid username and password"
    },
    "answers": ["A", "B", "C", "D"],
    "explanation": "A, B, C, D) Correct. To ensure complete functional coverage, all possible transitions should be tested, including both valid and invalid inputs for username and password.",
    "learning_objective": "TTA-6.2",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "79",
    "question_text": "Analyze the following test report indicating the results of testing an API under load:\n\n```plaintext\n Load (Users)  | Response Time (ms) | Success Rate (%) | Errors (%)\n------------------------------------------------------------\n 50            | 200                | 100%             | 0%\n 100           | 250                | 100%             | 0%\n 200           | 600                | 95%              | 5%\n 400           | 1000               | 90%              | 10%\n 800           | 3000               | 60%              | 20%\n``` \n\nBased on the above results, what would be the appropriate next steps to improve system performance?",
    "options": {
      "A": "Optimize the API to handle higher loads and reduce response times",
      "B": "Test with even more load to determine the system’s maximum capacity",
      "C": "Ignore errors and increase the load limit to 1000 users",
      "D": "Reduce the number of concurrent users to 50 to maintain performance"
    },
    "answers": ["A"],
    "explanation": "A) Correct. Optimizing the API to handle higher loads and reduce response times will improve performance and scalability. B) Testing with more load may not be useful until the current issues are resolved. C) Ignoring errors and increasing load would worsen the problem. D) Reducing the load would help short-term, but optimizing the system for scalability is the long-term solution.",
    "learning_objective": "TTA-4.3",
    "klevel": "K4",
    "points": 3
  },{
    "question_id": "80",
    "question_text": "Given the following sequence diagram for a file upload process, analyze the test strategy that would ensure thorough coverage of this scenario:\n\n```plaintext\n User  -> WebApp    -> FileServer  -> Database\n  |      |            |             |\n  |------> UploadFile |             |\n  |      |------------>|             |\n  |      |             | StoreFile   |\n  |      |             |             | SaveFileInfo\n  |      |<------------|             |\n  |<-----|             |             |\n``` \n\nWhich of the following test strategies would provide comprehensive coverage for this process?",
    "options": {
      "A": "Test only the file upload process, ensuring the WebApp can send files to the FileServer",
      "B": "Test the entire flow, including successful file uploads, error handling (e.g., invalid file format), and the interaction with the database",
      "C": "Test the interaction between the WebApp and FileServer, skipping database interactions",
      "D": "Test the file upload functionality with only valid file types and sizes"
    },
    "answers": ["B"],
    "explanation": "B) Correct. Testing the full flow ensures that all components (WebApp, FileServer, Database) are properly validated for both successful and erroneous scenarios, including error handling for invalid files and database interactions. A) Only testing the file upload misses the complete process. C) Omitting database interactions reduces test coverage. D) Only testing valid files misses critical error scenarios like unsupported file types.",
    "learning_objective": "TTA-6.3",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "81",
    "question_text": "Consider the following risk analysis for a mobile application that interacts with a cloud service. Based on the risk likelihood and impact assessment, which area should be prioritized for testing?\n\n```plaintext\n Risk             | Impact | Likelihood\n--------------------------------------------\n Data Leakage     | High   | Medium\n Service Downtime | High   | High\n Unauthorized Access | High   | Low\n```\n\nWhich risk should be prioritized for testing?",
    "options": {
      "A": "Data Leakage, as it has the highest potential impact",
      "B": "Service Downtime, as it has both high impact and likelihood",
      "C": "Unauthorized Access, as it is a critical security concern",
      "D": "None, as all risks have low likelihood"
    },
    "answers": ["B"],
    "explanation": "B) Correct. Service Downtime has both high impact and high likelihood, making it the most critical area for testing. A) While Data Leakage has a high impact, its likelihood is medium, so it is not as urgent. C) Unauthorized Access is critical, but its likelihood is low, so it should be prioritized lower than Service Downtime. D) Ignoring risk assessment would reduce the effectiveness of testing.",
    "learning_objective": "TTA-2.3",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "82",
    "question_text": "Given the following code snippet for a login system, identify the potential security vulnerability and the most effective mitigation strategy:\n\n```python\nclass LoginHandler:\n    def login(self, username, password):\n        if username == 'admin' and password == 'password123':\n            return 'Login successful'\n        else:\n            return 'Login failed'\n``` \n\nWhich of the following actions should be taken to mitigate the identified issue?",
    "options": {
      "A": "Replace the hardcoded password with a password stored securely in a database",
      "B": "Use SSL/TLS to encrypt the communication between client and server",
      "C": "Implement multi-factor authentication (MFA)",
      "D": "Add logging for every failed login attempt to detect malicious activity"
    },
    "answers": ["A", "B"],
    "explanation": "A, B) Correct. Hardcoded passwords are vulnerable to exposure, so they should be replaced with secure password storage mechanisms (A). Additionally, SSL/TLS encryption (B) ensures that sensitive data like passwords are transmitted securely over the network. C) Multi-factor authentication enhances security but is not the most direct fix for this specific vulnerability. D) Logging failed attempts helps with monitoring, but it doesn't directly mitigate the core vulnerability of hardcoded credentials.",
    "learning_objective": "TTA-5.2",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "83",
    "question_text": "Consider the following sequence diagram for an e-commerce system that processes payment transactions:\n\n```plaintext\n User -> WebApp -> PaymentGateway -> BankAPI\n  |      |            |              |\n  |------> InitiatePayment |            |\n  |      |----------------->|            |\n  |      |                  | ProcessPayment |\n  |      |                  |<-------------| TransactionConfirmed\n  |      |<----------------|              |\n``` \n\nWhich of the following test scenarios ensures complete coverage of the payment processing flow?",
    "options": {
      "A": "Test the payment initiation and confirmation with valid payment details only",
      "B": "Test the payment initiation with valid details, then test the system’s behavior when the BankAPI fails to confirm the transaction",
      "C": "Test only the interaction between the User and WebApp",
      "D": "Test the payment process with invalid payment details and ensure error handling occurs correctly"
    },
    "answers": ["B", "D"],
    "explanation": "B, D) Correct. Full test coverage should include valid payment initiation and handling of failures from the BankAPI (B), as well as testing for invalid payment details to ensure that error handling is robust (D). A) While valid transactions are necessary, they don’t fully cover error scenarios. C) Omitting the backend components like the PaymentGateway and BankAPI reduces test coverage.",
    "learning_objective": "TTA-6.2",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "84",
    "question_text": "Given the following test results of a component under load testing, analyze the performance issues:\n\n```plaintext\n Load (Users) | Response Time (ms) | Throughput (Requests/sec)\n------------------------------------------------------------\n 50           | 120                | 200\n 100          | 250                | 180\n 200          | 500                | 150\n 400          | 1500               | 100\n 800          | 4000               | 50\n``` \n\nWhich conclusion is most appropriate based on the test results?",
    "options": {
      "A": "The system performs well under low to moderate load but begins to degrade significantly after 200 users",
      "B": "The system handles up to 800 users without performance degradation",
      "C": "The system performs consistently across all load levels, suggesting good scalability",
      "D": "Throughput significantly decreases with increased load, indicating scalability issues"
    },
    "answers": ["D"],
    "explanation": "D) Correct. As the load increases, throughput decreases significantly, indicating that the system struggles to scale effectively. A) While performance degrades after 200 users, throughput issues are the main concern. B) The system doesn't handle 800 users effectively, as throughput drops sharply. C) The system does not perform consistently, especially at higher load levels.",
    "learning_objective": "TTA-4.3",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "85",
    "question_text": "Given the following test results from a security scan of a web application, analyze the vulnerability implications and recommend a remediation strategy:\n\n```plaintext\n Vulnerability        | Severity | Status\n--------------------------------------------\n Cross-site Scripting | High     | Open\n SQL Injection        | Medium   | Resolved\n CSRF                 | Low      | Open\n``` \n\nWhich of the following actions should be taken?",
    "options": {
      "A": "Focus on resolving the Cross-site Scripting (XSS) vulnerability as it is high severity",
      "B": "Address the Cross-site Scripting (XSS) vulnerability and the Cross-Site Request Forgery (CSRF) vulnerability",
      "C": "Since SQL injection is resolved, no further action is needed",
      "D": "Ignore the vulnerabilities with low likelihood of exploitation"
    },
    "answers": ["A", "B"],
    "explanation": "A, B) Correct. The Cross-site Scripting (XSS) vulnerability should be prioritized first due to its high severity. Addressing CSRF vulnerabilities (B) is also important to mitigate security risks. C) Ignoring vulnerabilities, even if they are resolved or low priority, can leave the system exposed. D) Ignoring vulnerabilities is not recommended, especially when they are open and have a security impact.",
    "learning_objective": "TTA-5.4",
    "klevel": "K4",
    "points": 3
  },
   {
    "question_id": "86",
    "question_text": "Given the following scenario where a login system is being tested, analyze the test design technique that would best achieve high coverage for invalid input scenarios:\n\nThe system should accept only usernames with alphanumeric characters and passwords that are at least 8 characters long. What is the most appropriate technique to design test cases for this scenario?",
    "options": {
      "A": "Equivalence Partitioning",
      "B": "Boundary Value Analysis",
      "C": "Decision Table Testing",
      "D": "State Transition Testing"
    },
    "answers": ["B"],
    "explanation": "B) Correct. Boundary Value Analysis (BVA) is suitable for testing boundary conditions like the minimum password length and the types of characters in the username. A) Equivalence Partitioning divides input data into partitions, but BVA is better for boundary-specific tests. C) Decision Table Testing is more suited for complex business rules. D) State Transition Testing is not applicable since there are no states or transitions based on input values in this scenario.",
    "learning_objective": "TTA-3.1",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "87",
    "question_text": "Given the following performance test results from a web application, analyze the system's behavior under load:\n\n```plaintext\n Load (Users) | Response Time (ms) | Errors (%)\n------------------------------------------------\n 100          | 200                | 0%\n 200          | 500                | 2%\n 400          | 1200               | 5%\n 800          | 3000               | 15%\n``` \n\nWhich of the following conclusions can be drawn from this data?",
    "options": {
      "A": "The system is able to handle 200 users without any performance degradation",
      "B": "The system's performance significantly degrades as the number of users increases",
      "C": "The system can scale well to 800 users without any noticeable issues",
      "D": "The error rate increases as the load decreases"
    },
    "answers": ["B"],
    "explanation": "B) Correct. The performance degradation (increased response time and error rate) becomes evident as the load increases. A) While performance degrades after 200 users, it's not correct to say the system handles 200 users without degradation. C) The system does not scale well to 800 users, as response times increase drastically. D) The error rate increases as the load increases, not decreases.",
    "learning_objective": "TTA-4.3",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "88",
    "question_text": "Given the following test case results for a shopping cart system, which of the following test cases would provide a good test for the system's functionality?\n\n```plaintext\n Test Case ID | Description                  | Result\n----------------------------------------------------------\n TC01         | Add item to cart             | Pass\n TC02         | Remove item from cart        | Pass\n TC03         | View cart contents           | Fail\n TC04         | Apply discount coupon         | Pass\n``` \n\nWhat action should be taken based on these results?",
    "options": {
      "A": "Re-test TC03 to determine why the view cart functionality failed",
      "B": "Skip re-testing TC03 as it is not critical to the system",
      "C": "Focus on re-testing TC04 as it is a discount-related functionality",
      "D": "Conclude testing because TC01, TC02, and TC04 passed"
    },
    "answers": ["A"],
    "explanation": "A) Correct. Since TC03 failed, it indicates an issue with viewing cart contents, which is critical to the shopping cart's functionality. B) TC03 failure must be addressed. C) TC04 passing doesn't reduce the priority of addressing TC03. D) Concluding testing is premature because TC03 failed.",
    "learning_objective": "TTA-6.1",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "89",
    "question_text": "Given the following scenario where a web application is being tested for load handling, what test strategy would be most effective in ensuring scalability under high load conditions?\n\nThe application is expected to handle up to 1000 concurrent users. What is the most appropriate approach for testing?",
    "options": {
      "A": "Test with only 100 users to ensure the system handles normal load conditions",
      "B": "Test with progressively higher loads (200, 400, 800, 1000 users) to observe performance degradation",
      "C": "Test with a single user to simulate individual user behavior",
      "D": "Test with 1000 users immediately to stress-test the system"
    },
    "answers": ["B"],
    "explanation": "B) Correct. Testing with progressively higher loads (200, 400, 800, 1000 users) ensures that the system's performance can be observed at various stages and any degradation can be identified. A) Testing only with 100 users doesn't provide enough insight into high-load performance. C) Testing with one user is not useful for load testing. D) Stress-testing the system immediately with 1000 users without prior analysis can result in unnecessary risks.",
    "learning_objective": "TTA-4.4",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "90",
    "question_text": "Given the following sequence diagram for a payment processing system, which test design technique would be most appropriate for ensuring complete coverage of the entire transaction flow?\n\n```plaintext\n User -> WebApp -> PaymentService -> BankAPI\n  |      |            |              |\n  |------> InitiatePayment |            |\n  |      |----------------->|            |\n  |      |                  | ProcessPayment |\n  |      |                  |<-------------| TransactionConfirmed\n  |      |<----------------|              |\n``` \n\nWhich test design technique should be used?",
    "options": {
      "A": "State Transition Testing",
      "B": "Boundary Value Analysis",
      "C": "Equivalence Partitioning",
      "D": "Decision Table Testing"
    },
    "answers": ["A"],
    "explanation": "A) Correct. State Transition Testing is appropriate for testing the flow of states in a system, such as the initiation of the payment and the transaction confirmation process. B) Boundary Value Analysis is more appropriate for numerical edge cases, not for testing state transitions. C) Equivalence Partitioning is useful for input validation but not for testing state transitions. D) Decision Table Testing is useful for testing complex decision logic, but not ideal for this state-based scenario.",
    "learning_objective": "TTA-3.3",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "91",
    "question_text": "Given the following test results for a security vulnerability scan of a web application, which of the following actions should be taken to address the identified vulnerabilities?\n\n```plaintext\n Vulnerability         | Severity | Status\n-------------------------------------------\n Cross-site Scripting  | High     | Open\n SQL Injection         | Low      | Resolved\n Brute Force Attack    | Medium   | Open\n``` \n\nWhat is the most appropriate course of action?",
    "options": {
      "A": "Fix the Cross-site Scripting and Brute Force Attack vulnerabilities as they are open and have medium/high severity",
      "B": "Fix the Cross-site Scripting vulnerability only, as it is high severity",
      "C": "Fix the Brute Force Attack vulnerability, as it is unresolved",
      "D": "Ignore the vulnerabilities, as SQL injection has been resolved"
    },
    "answers": ["A"],
    "explanation": "A) Correct. Both the Cross-site Scripting (high severity) and Brute Force Attack (medium severity) vulnerabilities should be prioritized for fixing, as they pose a security risk. B) Ignoring the Brute Force vulnerability could leave the system exposed. C) The Brute Force Attack vulnerability needs addressing, but it's important to also fix Cross-site Scripting. D) Ignoring unresolved vulnerabilities can leave the system at risk.",
    "learning_objective": "TTA-5.3",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "92",
    "question_text": "Given the following risk assessment for a web application, analyze which risk is most critical for testing based on its likelihood and impact:\n\n```plaintext\n Risk            | Likelihood | Impact\n------------------------------------------\n Data Leakage    | High       | High\n Service Downtime| Medium     | High\n Unauthorized Access | Low      | High\n``` \n\nWhich risk should be tested first?",
    "options": {
      "A": "Data Leakage, as it has both high likelihood and high impact",
      "B": "Service Downtime, as it has the highest impact",
      "C": "Unauthorized Access, as it is a high-impact risk",
      "D": "None of the risks should be tested first"
    },
    "answers": ["A"],
    "explanation": "A) Correct. Data Leakage is both highly likely and has a high impact, making it the most critical risk to prioritize for testing. B) Service Downtime is a high-impact risk but has a medium likelihood. C) Unauthorized Access has high impact but low likelihood, so it is not as critical to prioritize compared to Data Leakage. D) Ignoring high-risk vulnerabilities is not a good strategy.",
    "learning_objective": "TTA-2.2",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "93",
    "question_text": "Given the following scenario, what is the most effective way to test the compatibility of a mobile application across different devices and OS versions?\n\nThe application needs to be tested on Android and iOS devices running different versions of their respective OS. What is the best approach?",
    "options": {
      "A": "Test only on the latest versions of Android and iOS to minimize testing efforts",
      "B": "Test on a variety of devices with different screen sizes, OS versions, and resolutions",
      "C": "Test only on a single device to ensure thorough testing",
      "D": "Test on devices that are most commonly used by users"
    },
    "answers": ["B"],
    "explanation": "B) Correct. Testing on a variety of devices with different screen sizes, OS versions, and resolutions ensures that the app works properly for a broad range of users. A) Testing only the latest versions reduces coverage. C) Testing on a single device isn't sufficient for compatibility testing. D) Focusing only on common devices can leave out potential issues for less common configurations.",
    "learning_objective": "TTA-4.1",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "94",
    "question_text": "What is the primary advantage of using automated testing for regression testing?",
    "options": {
      "A": "Automated tests can be executed more quickly and repeatedly, ensuring faster feedback",
      "B": "Automated tests provide better test coverage compared to manual tests",
      "C": "Automated tests are more effective than manual tests in identifying defects",
      "D": "Automated tests eliminate the need for manual testing altogether"
    },
    "answers": ["A"],
    "explanation": "A) Correct. Automated tests can be run quickly and repeatedly, which is ideal for regression testing as it allows for fast feedback on code changes. B) Automated tests help with coverage but are not a guarantee of better coverage. C) Automated tests may identify defects, but manual testing is still useful for exploratory testing. D) While automation reduces the need for manual tests, it does not eliminate them entirely.",
    "learning_objective": "TTA-7.2",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "95",
    "question_text": "Given the following test results for a web service response, analyze the performance and decide what needs further investigation:\n\n```plaintext\n Request ID | Response Time (ms) | Status Code\n------------------------------------------------------\n 101        | 120                | 200\n 102        | 250                | 500\n 103        | 300                | 200\n 104        | 400                | 200\n``` \n\nWhich of the following actions should be taken?",
    "options": {
      "A": "Investigate the slow response time of request ID 104 as it exceeds expected limits",
      "B": "Investigate the server-side issue causing the 500 status code for request ID 102",
      "C": "Focus on the status code 200, as all requests with this status passed",
      "D": "There is no issue with the performance, as response times are within acceptable limits"
    },
    "answers": ["B"],
    "explanation": "B) Correct. The 500 status code for request ID 102 indicates an internal server error, which should be investigated immediately. A) While request ID 104 has a slow response, the key issue here is the server error. C) Status code 200 indicates a successful request, so no action is needed here. D) A 500 status code is a clear indication of an issue.",
    "learning_objective": "TTA-4.1",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "96",
    "question_text": "Given the following decision table for a login system, analyze the test coverage it provides. The system allows users to log in only if their account is active and the password is correct.\n\n| Account Status | Password Correct | Access Granted |\n|----------------|------------------|----------------|\n| Active         | Correct          | Yes            |\n| Active         | Incorrect        | No             |\n| Inactive       | Correct          | No             |\n| Inactive       | Incorrect        | No             |\n\nWhich of the following is the correct conclusion about this decision table?",
    "options": {
      "A": "The table covers all possible input combinations for account status and password correctness",
      "B": "The table misses the case where the account is active but the password is empty",
      "C": "The table does not cover invalid account status values",
      "D": "The decision table is incomplete as it does not address the scenario where the password is null"
    },
    "answers": ["A"],
    "explanation": "A) Correct. The decision table covers all combinations of account status and password correctness. B) The password being empty is not part of the current specification. C) The account status is correctly defined (Active/Inactive), so no invalid values are necessary. D) Null passwords are generally considered incorrect and are part of the incorrect password condition.",
    "learning_objective": "TTA-3.4",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "97",
    "question_text": "Given a scenario where a mobile app must handle both portrait and landscape modes on various devices, which test design technique would be most appropriate to ensure adequate coverage of the user interface across all screen orientations?",
    "options": {
      "A": "State Transition Testing",
      "B": "Boundary Value Analysis",
      "C": "Equivalence Partitioning",
      "D": "Exploratory Testing"
    },
    "answers": ["D"],
    "explanation": "D) Correct. Exploratory Testing is suitable for testing dynamic user interfaces across different orientations. It helps identify issues that automated scripts or predefined test cases might miss, especially for mobile apps. A) State Transition Testing is useful for state-based scenarios, not for UI orientation. B) and C) are more applicable to input validation, not UI behavior across orientations.",
    "learning_objective": "TTA-6.2",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "98",
    "question_text": "Given the following code for a payment processing system, identify the most critical test for ensuring secure processing of payments:\n\n```python\ndef process_payment(card_number, expiry_date, amount):\n    if card_number == '1234567890' and expiry_date == '12/23':\n        return 'Payment Processed'\n    else:\n        return 'Invalid Payment'\n``` \n\nWhich of the following actions should be taken to test this function?",
    "options": {
      "A": "Test for invalid card numbers and expiry dates to verify that the system rejects incorrect details",
      "B": "Test with valid card details to ensure the payment is processed",
      "C": "Test for SQL injection vulnerabilities in the input parameters",
      "D": "Test with expired card details to check if the system rejects payments from expired cards"
    },
    "answers": ["A", "C"],
    "explanation": "A, C) Correct. Testing invalid card details ensures the system rejects incorrect inputs, while SQL injection testing is essential for ensuring that the system doesn't accept malicious input. B) Valid card details are necessary but don't address security concerns. D) Testing with expired cards is useful but doesn't address potential vulnerabilities like SQL injection.",
    "learning_objective": "TTA-5.1",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "99",
    "question_text": "Given the following graph representing the load test results of an e-commerce site, analyze the system's performance based on the load and response time data:\n\n```plaintext\n Load (Users) | Response Time (ms)\n-------------------------------\n 50            | 300\n 100           | 350\n 200           | 600\n 300           | 1000\n 400           | 1500\n``` \n\nWhich of the following conclusions can be made?",
    "options": {
      "A": "The system performs well up to 200 users, but response times degrade significantly after 300 users",
      "B": "The system handles up to 400 users without any issues",
      "C": "The system performs consistently at all load levels, indicating good scalability",
      "D": "The system is underperforming even with low load, as response times are too high"
    },
    "answers": ["A"],
    "explanation": "A) Correct. The response time increases significantly after 200 users, suggesting that the system has limitations in handling higher loads. B) The system struggles with performance above 200 users. C) The system does not perform consistently, as response times degrade with increased load. D) While response times are not ideal, the system’s performance starts degrading noticeably after 300 users.",
    "learning_objective": "TTA-4.2",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "100",
    "question_text": "Given the following risk analysis for a web application, which of the following actions would be the most effective to mitigate the risks identified?\n\n```plaintext\n Risk                 | Impact  | Likelihood\n-------------------------------------------\n Data Loss            | High    | Medium\n Unauthorized Access  | High    | Low\n Service Downtime     | Medium  | High\n``` \n\nWhich action should be prioritized?",
    "options": {
      "A": "Mitigate the risk of Service Downtime, as it has both high likelihood and impact",
      "B": "Mitigate the risk of Data Loss first, as it has high impact",
      "C": "Mitigate the risk of Unauthorized Access first, as it is a high-impact risk",
      "D": "None, as all risks have similar priority"
    },
    "answers": ["A"],
    "explanation": "A) Correct. Service Downtime has both high impact and high likelihood, making it the most critical risk to mitigate first. B) Data Loss is important but less likely than Service Downtime. C) Unauthorized Access has high impact but low likelihood, so it should be addressed after Service Downtime. D) Prioritization based on likelihood and impact is essential for effective mitigation.",
    "learning_objective": "TTA-2.2",
    "klevel": "K3",
    "points": 2
  },
   {
    "question_id": "101",
    "question_text": "Given the following test execution results, which of the following actions would be most appropriate for the next phase of testing?\n\n```plaintext\n Test Case          | Status | Severity\n-----------------------------------------\n Test Case 1        | Failed | High\n Test Case 2        | Passed | Medium\n Test Case 3        | Passed | Low\n``` \n\nWhich action should be prioritized?",
    "options": {
      "A": "Investigate the failure of Test Case 1 and re-test after fixing the issue",
      "B": "Ignore Test Case 1 and focus on passing Test Case 2 and Test Case 3",
      "C": "Fix Test Case 1 as it has high severity, then re-test all failed tests",
      "D": "Focus on re-testing Test Case 2 and Test Case 3 as they are passed"
    },
    "answers": ["A", "C"],
    "explanation": "A) Correct. Test Case 1 has failed with high severity, which should be prioritized for fixing and re-testing. C) Correct. The high severity of Test Case 1 necessitates addressing the issue before continuing with other tests. B) Ignoring failed test cases with high severity is not appropriate. D) Re-testing passed test cases does not address the critical issue in Test Case 1.",
    "learning_objective": "TTA-2.3",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "102",
    "question_text": "Which of the following testing techniques is most suitable for verifying the performance of a web application under a heavy load?\n\nWhich action would be the most appropriate for load testing?",
    "options": {
      "A": "Static analysis",
      "B": "Load testing with a defined number of concurrent users",
      "C": "Performance profiling with real-time data",
      "D": "Unit testing with mock data"
    },
    "answers": ["B", "C"],
    "explanation": "B) Correct. Load testing with a defined number of concurrent users simulates the behavior of the application under heavy traffic. C) Correct. Performance profiling with real-time data helps identify bottlenecks and optimize performance. A) Static analysis and D) Unit testing focus on functionality, not performance.",
    "learning_objective": "TTA-4.2",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "103",
    "question_text": "You are performing a regression test on a complex software system. Which of the following test types would be most suitable for detecting unintended side effects after a new feature has been added?",
    "options": {
      "A": "Smoke testing",
      "B": "Sanity testing",
      "C": "Regression testing",
      "D": "Exploratory testing"
    },
    "answers": ["C"],
    "explanation": "C) Correct. Regression testing is specifically designed to detect unintended side effects of changes, such as new features or fixes. A) Smoke testing checks for basic system stability, B) Sanity testing checks for basic functionality, and D) Exploratory testing is unstructured and less systematic for regression purposes.",
    "learning_objective": "TTA-5.1",
    "klevel": "K2",
    "points": 2
  },
  {
    "question_id": "104",
    "question_text": "Which of the following is the most appropriate reason to perform boundary value analysis on a given test case?",
    "options": {
      "A": "To test edge cases that are likely to produce errors",
      "B": "To test typical user interactions",
      "C": "To verify the system’s response to normal input ranges",
      "D": "To simulate the real-world use of the system"
    },
    "answers": ["A"],
    "explanation": "A) Correct. Boundary value analysis is used to focus on edge cases, which are often where errors occur in a system. B) Testing typical user interactions falls under other testing techniques, like equivalence partitioning. C) Verifying normal ranges can be tested using other methods, such as equivalence partitioning. D) Real-world scenarios are often addressed by exploratory or user acceptance testing.",
    "learning_objective": "TTA-3.1",
    "klevel": "K2",
    "points": 2
  },
  {
    "question_id": "105",
    "question_text": "You are testing a web application where security is a top priority. Which of the following activities would be most critical to perform first during the testing phase?",
    "options": {
      "A": "Perform static code analysis to detect vulnerabilities",
      "B": "Test for cross-site scripting (XSS) vulnerabilities",
      "C": "Perform usability testing for the interface",
      "D": "Check compatibility with multiple browsers"
    },
    "answers": ["A", "B"],
    "explanation": "A) Correct. Static code analysis can help identify potential security vulnerabilities early in the testing phase. B) Correct. XSS vulnerabilities can have significant security implications and should be tested as a high priority. C) Usability testing is important but does not directly address security. D) Compatibility testing is useful but not a priority for security-related concerns.",
    "learning_objective": "TTA-6.1",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "106",
    "question_text": "A test manager wants to measure the effectiveness of the testing process. Which of the following metrics would be most suitable for evaluating test efficiency?",
    "options": {
      "A": "Defect density",
      "B": "Test execution time",
      "C": "Test case coverage",
      "D": "Defect leakage"
    },
    "answers": ["B", "C"],
    "explanation": "B) Correct. Test execution time measures how efficiently tests are executed within a given time frame. C) Correct. Test case coverage provides insight into how much of the software has been tested, reflecting efficiency. A) Defect density and D) Defect leakage are more suited for evaluating product quality, not test efficiency.",
    "learning_objective": "TTA-1.4",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "107",
    "question_text": "In a sprint-based agile environment, which of the following activities would best help ensure that test automation is integrated effectively into the continuous integration pipeline?",
    "options": {
      "A": "Automate test cases for each user story as they are created",
      "B": "Automate tests only after all manual testing is complete",
      "C": "Automate test cases for features that are stable and unlikely to change",
      "D": "Integrate automated tests into the continuous integration pipeline and run tests after each build"
    },
    "answers": ["D"],
    "explanation": "D) Correct. Integrating automated tests into the continuous integration pipeline allows for tests to be executed after each build, ensuring rapid feedback. A) Automating test cases as user stories are created is not effective if the functionality is still being developed. B) Automating tests after manual testing is completed is too late for early feedback. C) Automation should be done for critical tests, not just stable features.",
    "learning_objective": "TTA-7.1",
    "klevel": "K2",
    "points": 2
  },
  {
    "question_id": "108",
    "question_text": "Which of the following test types is primarily used to evaluate the system’s ability to handle extreme conditions, such as high traffic or large volumes of data?",
    "options": {
      "A": "Load testing",
      "B": "Stress testing",
      "C": "Volume testing",
      "D": "Endurance testing"
    },
    "answers": ["B", "C"],
    "explanation": "B) Correct. Stress testing evaluates the system’s ability to handle extreme conditions and break points. C) Correct. Volume testing checks how the system handles large volumes of data. A) Load testing is about expected traffic, and D) Endurance testing checks for system performance over long periods, not extremes.",
    "learning_objective": "TTA-4.3",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "109",
    "question_text": "During testing, you notice that the application is not behaving as expected. Which of the following actions is most appropriate for debugging the issue?",
    "options": {
      "A": "Log the issue and report it immediately",
      "B": "Use debugging tools to trace the issue in the code",
      "C": "Run a set of predefined tests to confirm the issue",
      "D": "Attempt to fix the issue without further analysis"
    },
    "answers": ["B"],
    "explanation": "B) Correct. Debugging tools help trace the issue in the code and identify the root cause. A) Reporting the issue immediately without analyzing it is premature. C) Running predefined tests may not identify the specific issue without further debugging. D) Fixing the issue without analysis could result in an incorrect solution.",
    "learning_objective": "TTA-2.4",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "110",
    "question_text": "When evaluating the quality of a test case, which of the following characteristics would be most critical to ensure test case effectiveness?",
    "options": {
      "A": "The test case is clear, concise, and provides good coverage of the functionality",
      "B": "The test case is simple and easy to execute, even if it misses some functionality",
      "C": "The test case provides a high level of detail, regardless of coverage",
      "D": "The test case includes complex edge cases and error handling, even if not relevant"
    },
    "answers": ["A"],
    "explanation": "A) Correct. Effective test cases should be clear, concise, and provide adequate coverage of the system’s functionality. B) Simplicity is good, but it should not come at the expense of coverage. C) High detail without adequate coverage can lead to inefficiencies. D) Including irrelevant complexity can make the test case harder to maintain without adding value.",
    "learning_objective": "TTA-3.4",
    "klevel": "K2",
    "points": 2
  },
   {
    "question_id": "111",
    "question_text": "A team is performing load testing on a web application, and the results show the following behavior:\n\n```plaintext\n Test 1: 100 users - Response Time: 2 seconds\n Test 2: 500 users - Response Time: 5 seconds\n Test 3: 1000 users - Response Time: 15 seconds\n Test 4: 2000 users - Response Time: 30 seconds\n``` \n\nBased on the data provided, which of the following conclusions would be most accurate?",
    "options": {
      "A": "The system is able to handle up to 2000 concurrent users with acceptable performance",
      "B": "The system's response time increases non-linearly as the number of users increases",
      "C": "The system’s performance is stable under load and will not degrade further",
      "D": "The system may be approaching its performance limits at 1000 users"
    },
    "answers": ["B", "D"],
    "explanation": "B) Correct. The response time increases at a higher rate with more users, indicating non-linear performance degradation. D) Correct. The significant increase in response time at 1000 users suggests the system may be approaching its performance limits. A) Incorrect. The system shows a considerable degradation in performance at 2000 users. C) Incorrect. The performance continues to degrade as more users are added.",
    "learning_objective": "TTA-4.3",
    "klevel": "K3",
    "points": 3
  },
  {
    "question_id": "112",
    "question_text": "You are conducting a risk-based testing exercise on a financial application. Based on the following risk matrix, which of the following risks should be prioritized?\n\n```plaintext\n Risk                 | Impact   | Likelihood\n----------------------------------------------\n Incorrect Interest Calculation | High     | High\n Data Loss                    | High     | Medium\n Incorrect Login Mechanism     | Medium   | High\n``` \n\nWhich of the following actions would be the most effective in mitigating risks?",
    "options": {
      "A": "Prioritize testing for Incorrect Interest Calculation, as it has both high impact and high likelihood",
      "B": "Test for Incorrect Login Mechanism first, as it has high likelihood",
      "C": "Focus testing efforts on Data Loss, as it has high impact",
      "D": "None, as all risks have similar priority"
    },
    "answers": ["A"],
    "explanation": "A) Correct. Incorrect Interest Calculation has both high impact and high likelihood, making it the most critical risk to mitigate first. B) Incorrect. While the Incorrect Login Mechanism has high likelihood, its impact is lower than that of the other risks. C) Incorrect. Data Loss has a high impact but lower likelihood, making it secondary to other high-likelihood issues. D) Incorrect. Prioritization is crucial for effective risk mitigation.",
    "learning_objective": "TTA-2.3",
    "klevel": "K3",
    "points": 3
  },
  {
    "question_id": "113",
    "question_text": "You are performing a security test for an e-commerce platform. During penetration testing, you notice a vulnerability in the login page. Which of the following actions should be your next step to confirm the vulnerability and assess its impact?",
    "options": {
      "A": "Try exploiting the vulnerability to see if an attacker could gain unauthorized access",
      "B": "Report the vulnerability to the development team for immediate patching",
      "C": "Document the vulnerability and analyze its potential impact on the system’s security",
      "D": "Ignore the vulnerability if no immediate threats are detected"
    },
    "answers": ["C"],
    "explanation": "C) Correct. Documenting and analyzing the vulnerability's potential impact is crucial for understanding its risk and preparing for remediation. A) Exploiting the vulnerability could be risky and should only be done in a controlled environment. B) Reporting is important, but proper documentation and analysis must precede it. D) Ignoring vulnerabilities could lead to potential security breaches.",
    "learning_objective": "TTA-6.1",
    "klevel": "K3",
    "points": 3
  },
  {
    "question_id": "114",
    "question_text": "You are testing a multi-tier web application with a database back-end. Which of the following testing approaches is most appropriate for testing the communication and data flow between the application layers?",
    "options": {
      "A": "Unit testing individual layers",
      "B": "End-to-end integration testing between the client and the server",
      "C": "Performance testing to simulate concurrent user interactions",
      "D": "API testing to verify data exchange between components"
    },
    "answers": ["B", "D"],
    "explanation": "B) Correct. End-to-end integration testing verifies the correct communication and data flow between the client, application server, and database. D) Correct. API testing ensures that the data exchange between the components is correct and efficient. A) Unit testing focuses on isolated layers, not the entire system. C) Performance testing is important but does not focus on data flow.",
    "learning_objective": "TTA-3.2",
    "klevel": "K3",
    "points": 3
  },
  {
    "question_id": "115",
    "question_text": "You are testing a mobile app that uses GPS for location-based services. The app needs to work seamlessly with various location data inputs. Which testing technique would be most effective in identifying issues related to GPS functionality?",
    "options": {
      "A": "Equivalence partitioning based on geographic zones",
      "B": "Boundary value analysis for GPS coordinates",
      "C": "User acceptance testing with different real-world locations",
      "D": "Compatibility testing on multiple devices with GPS functionality"
    },
    "answers": ["A", "B"],
    "explanation": "A) Correct. Equivalence partitioning can be used to categorize different geographic zones for testing location-based functionality. B) Correct. Boundary value analysis is critical for testing extreme GPS coordinates and edge cases. C) User acceptance testing is important but doesn’t focus specifically on the GPS functionality. D) Compatibility testing is important but does not directly address GPS functionality.",
    "learning_objective": "TTA-3.3",
    "klevel": "K3",
    "points": 3
  },
  {
    "question_id": "116",
    "question_text": "You are conducting a load test on an e-commerce website, and you notice that the website starts to experience a degradation in performance when 80% of the system's resources are utilized. What would be your next action?",
    "options": {
      "A": "Stop testing and report the issue to the development team immediately",
      "B": "Increase the load to see how the system behaves under maximum capacity",
      "C": "Analyze system logs and metrics to identify the bottleneck or cause of the issue",
      "D": "Continue testing and disregard the performance degradation, as it’s expected under load"
    },
    "answers": ["C"],
    "explanation": "C) Correct. Analyzing logs and metrics is essential for identifying the specific cause of performance degradation. A) Stopping the test early without analyzing the root cause would not be effective. B) Increasing the load further without understanding the cause of the issue might lead to system failure. D) Disregarding performance degradation could allow issues to persist without resolution.",
    "learning_objective": "TTA-4.4",
    "klevel": "K3",
    "points": 3
  },
  {
    "question_id": "117",
    "question_text": "During the testing of a banking application, you find that some features are not working as expected under high load. Which of the following techniques would best help identify performance bottlenecks?",
    "options": {
      "A": "Code review and static analysis",
      "B": "Profiling tools to analyze CPU and memory usage",
      "C": "System configuration review to optimize server settings",
      "D": "Load testing and stress testing with high concurrency"
    },
    "answers": ["B", "D"],
    "explanation": "B) Correct. Profiling tools allow you to analyze system resources like CPU and memory usage, helping identify performance bottlenecks. D) Correct. Load and stress testing under high concurrency helps simulate real-world usage and highlight potential performance issues. A) Code review and static analysis focus more on code quality than on performance bottlenecks. C) Reviewing system configuration can help, but it’s secondary to testing for performance under load.",
    "learning_objective": "TTA-4.2",
    "klevel": "K3",
    "points": 3
  },
  {
    "question_id": "118",
    "question_text": "During a security test, you discover that sensitive data is being stored in plain text in the database. What should be your first course of action to mitigate this issue?",
    "options": {
      "A": "Encrypt the sensitive data before storing it in the database",
      "B": "Immediately inform the development team to patch the issue",
      "C": "Perform a risk analysis to evaluate the impact of the issue",
      "D": "Report the issue to the security team and wait for instructions"
    },
    "answers": ["A", "C"],
    "explanation": "A) Correct. Encrypting sensitive data before storing it is a best practice to ensure data protection. C) Correct. A risk analysis will help assess the potential impact of storing sensitive data in plain text. B) Informing the development team is important, but the first action should be to mitigate the issue through encryption. D) Reporting to the security team is necessary but should follow mitigation steps.",
    "learning_objective": "TTA-6.2",
    "klevel": "K3",
    "points": 3
  },
  {
    "question_id": "119",
    "question_text": "A developer writes unit tests for a new feature in a web application. However, these tests are not covering all possible input conditions. What should be the most appropriate action to improve test coverage?",
    "options": {
      "A": "Increase the number of test cases to cover additional input conditions",
      "B": "Re-write the code to ensure better test coverage",
      "C": "Focus on manual testing to cover the remaining input conditions",
      "D": "Analyze the test results and re-run the tests"
    },
    "answers": ["A"],
    "explanation": "A) Correct. Increasing the number of test cases will help cover additional input conditions and improve test coverage. B) Re-writing code for better test coverage is not necessary if the tests can be expanded. C) Manual testing is useful, but unit tests should be the primary method for covering input conditions. D) Analyzing test results and re-running tests does not address coverage gaps directly.",
    "learning_objective": "TTA-3.1",
    "klevel": "K3",
    "points": 3
  },
  {
    "question_id": "120",
    "question_text": "Which of the following is the primary goal of component testing?",
    "options": {
      "A": "To ensure that individual components perform correctly in isolation",
      "B": "To ensure that the system functions as a whole",
      "C": "To validate the system’s security features",
      "D": "To simulate real-world usage scenarios"
    },
    "answers": ["A"],
    "explanation": "A) Correct. Component testing focuses on validating the functionality of individual components in isolation. B) This is the goal of system testing. C) Security testing is a separate activity. D) Real-world usage scenarios are typically part of user acceptance testing.",
    "learning_objective": "TTA-1.1",
    "klevel": "K1",
    "points": 1
  },
  {
    "question_id": "121",
    "question_text": "Which of the following is an example of a boundary value in testing?",
    "options": {
      "A": "Test the login functionality with a username that is 10 characters long",
      "B": "Test the search feature by entering a variety of common queries",
      "C": "Test a form with a value greater than the maximum allowed limit",
      "D": "Test a login attempt with a random password"
    },
    "answers": ["C"],
    "explanation": "C) Correct. Boundary value testing involves testing values at the boundary of valid input ranges, such as values greater than the maximum limit. A) While testing with a specific input is important, it's not specifically related to boundary testing. B) This is functional testing, but not boundary value testing. D) This is not a boundary value test; it’s a valid functional test.",
    "learning_objective": "TTA-3.2",
    "klevel": "K1",
    "points": 1
  },
  {
    "question_id": "122",
    "question_text": "In a risk-based testing approach, what is the main focus of testing?",
    "options": {
      "A": "Testing the most critical areas with the highest probability of failure",
      "B": "Testing all features equally regardless of risk",
      "C": "Testing only the critical path in the application",
      "D": "Testing the system in the most realistic environment"
    },
    "answers": ["A"],
    "explanation": "A) Correct. Risk-based testing focuses on identifying and testing the most critical areas that have the highest likelihood of failure. B) Incorrect. Risk-based testing prioritizes areas with higher risks. C) Testing only the critical path is not a comprehensive risk-based approach. D) While environment testing is important, risk-based testing focuses on risk prioritization, not the environment.",
    "learning_objective": "TTA-2.1",
    "klevel": "K1",
    "points": 1
  },
  
  {
    "question_id": "123",
    "question_text": "Which of the following best describes the purpose of integration testing?",
    "options": {
      "A": "To validate individual components of the system in isolation",
      "B": "To verify the interaction between different system components",
      "C": "To simulate real-world usage of the entire system",
      "D": "To ensure the system meets security requirements"
    },
    "answers": ["B"],
    "explanation": "B) Correct. Integration testing focuses on verifying that different system components interact correctly. A) This is the focus of unit testing. C) This describes user acceptance testing, which is done after integration testing. D) Security testing is a separate activity.",
    "learning_objective": "TTA-3.1",
    "klevel": "K1",
    "points": 1
  },
  
  {
    "question_id": "124",
    "question_text": "What does the acronym 'TTA' stand for in the ISTQB context?",
    "options": {
      "A": "Test Technique Analyst",
      "B": "Test Technical Analyst",
      "C": "Technical Test Analyst",
      "D": "Test Tactical Analyst"
    },
    "answers": ["C"],
    "explanation": "C) Correct. 'TTA' stands for Technical Test Analyst in the ISTQB context. A) Test Technique Analyst is not a recognized role. B) Test Technical Analyst is incorrect; it's not the full form. D) Test Tactical Analyst does not match the ISTQB terminology.",
    "learning_objective": "TTA-1.1",
    "klevel": "K1",
    "points": 1
  },
  
  {
    "question_id": "125",
    "question_text": "In which phase of testing would you most likely use a risk-based testing approach?",
    "options": {
      "A": "Unit Testing",
      "B": "Integration Testing",
      "C": "System Testing",
      "D": "Acceptance Testing"
    },
    "answers": ["C"],
    "explanation": "C) Correct. Risk-based testing is most commonly applied in system testing, where risks are assessed and the focus is placed on the most critical parts of the system. A) Unit testing focuses on isolated components. B) Integration testing is about ensuring components work together, but risk-based testing is broader. D) Acceptance testing ensures the system meets business requirements, not necessarily risks.",
    "learning_objective": "TTA-2.1",
    "klevel": "K1",
    "points": 1
  },
  
  {
    "question_id": "126",
    "question_text": "What is the purpose of test design techniques in software testing?",
    "options": {
      "A": "To identify the types of testing tools to be used",
      "B": "To structure and organize test cases for efficient execution",
      "C": "To ensure the system is compatible with different platforms",
      "D": "To determine the budget and resources for testing"
    },
    "answers": ["B"],
    "explanation": "B) Correct. Test design techniques help structure and organize test cases to ensure efficient and effective testing. A) Test tools are important but not the main purpose of test design techniques. C) Compatibility is a testing objective but not specifically related to test design techniques. D) Budget and resource allocation are part of test planning, not design.",
    "learning_objective": "TTA-1.2",
    "klevel": "K1",
    "points": 1
  },
  
  {
    "question_id": "127",
    "question_text": "Which of the following testing techniques is best suited for identifying defects in the interactions between different modules of a system?",
    "options": {
      "A": "Unit Testing",
      "B": "Integration Testing",
      "C": "System Testing",
      "D": "Acceptance Testing"
    },
    "answers": ["B"],
    "explanation": "B) Correct. Integration testing is best suited for identifying defects in the interactions between different system modules. A) Unit testing focuses on individual components, not interactions. C) System testing tests the system as a whole, not just interactions between modules. D) Acceptance testing ensures the system meets business requirements.",
    "learning_objective": "TTA-3.1",
    "klevel": "K1",
    "points": 1
  },
  
  {
    "question_id": "128",
    "question_text": "What is the primary difference between manual and automated testing?",
    "options": {
      "A": "Manual testing is more time-consuming but can find more defects",
      "B": "Automated testing can test more effectively but requires more skilled testers",
      "C": "Automated testing is faster but less effective for finding defects in complex scenarios",
      "D": "Manual testing requires more time and effort to repeat tests, whereas automated testing can be repeated easily"
    },
    "answers": ["D"],
    "explanation": "D) Correct. Automated testing can be easily repeated, making it more efficient for repetitive tests. A) Manual testing is time-consuming, but it doesn't necessarily find more defects. B) Automated testing is faster, but it doesn’t require more skilled testers – both manual and automated testing require skills. C) Automated testing is more effective for repetitive tests and regression testing, not less effective.",
    "learning_objective": "TTA-5.1",
    "klevel": "K1",
    "points": 1
  },
  {
    "question_id": "129",
    "question_text": "You are testing a new mobile application. The application works well in your local test environment but fails when deployed to production. Which of the following would be the most likely cause of the issue?",
    "options": {
      "A": "The local test environment is using a different version of the database",
      "B": "The application code is outdated",
      "C": "The production environment has stricter security settings",
      "D": "The testing environment didn’t simulate real user conditions"
    },
    "answers": ["A", "D"],
    "explanation": "A) Correct. Differences in the environment, such as the database version, can cause unexpected issues. D) Correct. The production environment may differ significantly from the testing environment in terms of real-world usage, leading to issues not seen in testing. B) Outdated code could cause issues, but the primary focus here is the environmental difference. C) While security settings can affect functionality, the environment issue is more likely.",
    "learning_objective": "TTA-3.3",
    "klevel": "K2",
    "points": 2
  },
  
  {
    "question_id": "130",
    "question_text": "Given the following test scenario, what would be the best testing technique to identify potential edge cases?\n\nA web application has a form that accepts numeric input from the user, but it only accepts values between 1 and 1000. What test cases would best address potential edge cases?",
    "options": {
      "A": "Test the form with the values 1 and 1000",
      "B": "Test the form with values just below and above 1 and 1000",
      "C": "Test the form with values that are randomly distributed between 1 and 1000",
      "D": "Test the form with values that are all greater than 1000"
    },
    "answers": ["A", "B"],
    "explanation": "A) Correct. Testing with the boundary values (1 and 1000) is critical for edge cases. B) Correct. Testing with values just outside the boundaries helps identify defects related to boundary handling. C) Randomly distributed values might not be as effective as focused boundary testing. D) Testing values greater than 1000 is important but does not fully address edge cases.",
    "learning_objective": "TTA-3.2",
    "klevel": "K2",
    "points": 2
  },
  {
    "question_id": "131",
    "question_text": "You have been asked to test a feature where users can upload and download documents. The system allows uploads of documents up to 10MB, but the uploaded document is converted into a standardized format before it’s stored. Which of the following testing techniques would best cover all relevant test cases?",
    "options": {
      "A": "Load testing to check how the system handles multiple concurrent uploads",
      "B": "Boundary value analysis to test file size limits",
      "C": "Equivalence partitioning to check different types of document formats",
      "D": "Exploratory testing to see if users can bypass the file size check"
    },
    "answers": ["A", "B", "C"],
    "explanation": "A) Correct. Load testing will help determine how the system handles concurrent uploads and user traffic. B) Correct. Boundary value analysis ensures that file size limits are correctly enforced. C) Correct. Equivalence partitioning helps test different document formats that the system should handle. D) While exploratory testing is important, it is not the best method for validating file size checks and format handling.",
    "learning_objective": "TTA-5.1",
    "klevel": "K3",
    "points": 3
  },
  
  {
    "question_id": "132",
    "question_text": "You are tasked with testing a mobile app’s performance under different network conditions. You need to identify how the app behaves with fluctuating network speeds. Which of the following approaches will provide the most accurate insights?",
    "options": {
      "A": "Use a network simulation tool to simulate various network conditions and measure the app’s response times and throughput",
      "B": "Test the app on a variety of mobile devices in real-world network environments",
      "C": "Perform load testing with a constant high-speed network to see how it handles heavy traffic",
      "D": "Test the app with a limited number of users on the local Wi-Fi network"
    },
    "answers": ["A", "B"],
    "explanation": "A) Correct. Using a network simulation tool allows you to control and test different network conditions systematically. B) Correct. Testing in real-world conditions provides realistic data on how the app behaves under fluctuating network speeds. C) Load testing with a constant network speed does not focus on the effect of fluctuating network conditions. D) Testing with a limited number of users may not reveal how the app performs in variable network conditions.",
    "learning_objective": "TTA-4.2",
    "klevel": "K3",
    "points": 3
  },
  {
    "question_id": "133",
    "question_text": "You are testing a system’s performance under high load. The system starts to behave erratically when the number of concurrent users exceeds 1000. Which performance testing technique is most appropriate to further investigate this issue?",
    "options": {
      "A": "Stress Testing",
      "B": "Load Testing",
      "C": "Volume Testing",
      "D": "Endurance Testing"
    },
    "answers": ["A"],
    "explanation": "A) Correct. Stress testing involves testing the system beyond its normal operational capacity to determine its breaking point and identify potential weaknesses. B) Load testing measures the system's performance under expected conditions, not extreme loads. C) Volume testing is about handling large amounts of data, not concurrent users. D) Endurance testing checks performance over prolonged periods but does not focus on breaking points.",
    "learning_objective": "TTA-4.2",
    "klevel": "K2",
    "points": 2
  },
  
  {
    "question_id": "134",
    "question_text": "During security testing, you identify that an application does not properly sanitize user inputs. What type of security risk does this most likely introduce?",
    "options": {
      "A": "Cross-Site Scripting (XSS)",
      "B": "SQL Injection",
      "C": "Denial of Service (DoS)",
      "D": "Buffer Overflow"
    },
    "answers": ["B"],
    "explanation": "B) Correct. SQL injection is a common vulnerability when user inputs are not sanitized, allowing attackers to execute arbitrary SQL queries on the database. A) XSS involves injecting malicious scripts into webpages, which is different from SQL injection. C) DoS attacks are designed to make a system unavailable, not related to unsanitized inputs. D) Buffer overflow occurs when more data is written to a buffer than it can hold, unrelated to input sanitization.",
    "learning_objective": "TTA-6.3",
    "klevel": "K2",
    "points": 2
  },
  
  {
    "question_id": "135",
    "question_text": "You are performing exploratory testing on a web application. Which of the following activities would you prioritize during this testing phase?",
    "options": {
      "A": "Following predefined test scripts to check for known defects",
      "B": "Exploring the application’s features randomly to discover potential defects",
      "C": "Focusing only on functionality and ignoring performance and security",
      "D": "Testing for performance issues by simulating high traffic"
    },
    "answers": ["B"],
    "explanation": "B) Correct. Exploratory testing is an approach where testers actively explore the system's features, focusing on discovering defects that may not be identified through scripted testing. A) Following predefined scripts is not the goal of exploratory testing. C) Ignoring performance and security can lead to undetected issues in those areas. D) Performance testing is a different activity and is not the focus of exploratory testing.",
    "learning_objective": "TTA-3.1",
    "klevel": "K3",
    "points": 3
  },
  
  {
    "question_id": "136",
    "question_text": "Which of the following would be an appropriate first step in testing a newly developed API?",
    "options": {
      "A": "Perform load testing to check how the API handles a large number of requests",
      "B": "Perform functional testing to ensure the API returns the correct responses",
      "C": "Test for security vulnerabilities by attempting to exploit known weaknesses",
      "D": "Test the API under extreme stress to see if it crashes"
    },
    "answers": ["B"],
    "explanation": "B) Correct. Functional testing is the first step to ensure that the API behaves as expected, returning the correct responses to valid requests. A) Load testing should be done after functional testing to verify the API’s performance. C) Security testing is important but should come after functional verification. D) Stress testing should come after ensuring the API is functional and secure.",
    "learning_objective": "TTA-4.1",
    "klevel": "K2",
    "points": 2
  },
  
  {
    "question_id": "137",
    "question_text": "You are conducting a usability test on a website. What would be the best approach to identify usability issues?",
    "options": {
      "A": "Performing automated functional tests to ensure that the website works properly",
      "B": "Observing users interact with the website and gathering feedback about their experience",
      "C": "Testing the website under heavy load to simulate real-world conditions",
      "D": "Testing the security features of the website to prevent unauthorized access"
    },
    "answers": ["B"],
    "explanation": "B) Correct. Usability testing focuses on the user experience, so observing users interact with the website and gathering feedback about their experience is essential. A) Automated functional tests check correctness, but not usability. C) Load testing focuses on performance, not usability. D) Security testing is important but unrelated to usability testing.",
    "learning_objective": "TTA-6.1",
    "klevel": "K2",
    "points": 2
  },
  
  {
    "question_id": "138",
    "question_text": "Which of the following would be the most appropriate technique for determining if a system meets its non-functional requirements?",
    "options": {
      "A": "Functional testing",
      "B": "Usability testing",
      "C": "Performance testing",
      "D": "Security testing"
    },
    "answers": ["C"],
    "explanation": "C) Correct. Performance testing is focused on evaluating non-functional requirements like speed, responsiveness, and stability under load. A) Functional testing verifies that the system performs specific functions, not non-functional ones. B) Usability testing evaluates the user experience, which is important but not part of non-functional requirements. D) Security testing ensures that the system is secure but does not directly measure non-functional requirements like performance.",
    "learning_objective": "TTA-4.1",
    "klevel": "K2",
    "points": 2
  },
  
  {
    "question_id": "139",
    "question_text": "In the context of regression testing, which of the following would be the most effective strategy to ensure that previously fixed defects do not reoccur?",
    "options": {
      "A": "Retest the fixed defects manually and perform some exploratory testing",
      "B": "Automate the tests for previously fixed defects and run them for each release",
      "C": "Only test the new functionality and ignore previously fixed defects",
      "D": "Test only the defects reported by the development team"
    },
    "answers": ["B"],
    "explanation": "B) Correct. Automating tests for previously fixed defects allows for efficient and consistent checking with each release, helping to ensure that issues do not reoccur. A) Manual retesting is effective but less efficient than automation. C) Ignoring previously fixed defects could result in reintroducing old issues. D) Only testing defects reported by the development team could miss issues that occur in new code.",
    "learning_objective": "TTA-3.3",
    "klevel": "K2",
    "points": 2
  },
  
  {
    "question_id": "140",
    "question_text": "You are conducting load testing for a web application that is expected to handle a high number of concurrent users. What is the primary goal of load testing in this scenario?",
    "options": {
      "A": "Determine the system’s breaking point by pushing it beyond normal operational limits",
      "B": "Assess the system’s performance under expected user loads",
      "C": "Identify security vulnerabilities under load",
      "D": "Check how the system behaves under continuous use over an extended period"
    },
    "answers": ["B"],
    "explanation": "B) Correct. Load testing is conducted to assess the system’s performance under expected or normal user loads, ensuring that the system can handle anticipated traffic. A) Stress testing is the technique for pushing a system beyond normal limits. C) Security testing is not the focus of load testing, although performance could be impacted by security issues. D) Endurance testing is used to assess behavior over extended periods, not load testing.",
    "learning_objective": "TTA-4.1",
    "klevel": "K2",
    "points": 2
  },
  {
    "question_id": "141",
    "question_text": "You are tasked with performing **security testing** on a mobile application. During testing, you discover that sensitive user data, such as passwords, is being stored in plaintext. Which of the following actions should be prioritized to address this issue?",
    "options": {
      "A": "Encrypt sensitive data before storing it in the database",
      "B": "Perform vulnerability scanning to identify other weaknesses in the application",
      "C": "Test the application for other types of security vulnerabilities like SQL injection",
      "D": "Report the issue to the development team for further investigation"
    },
    "answers": ["A"],
    "explanation": "A) Correct. The most effective solution to protect sensitive user data is to encrypt it before storing it in the database. This ensures that the data is protected even if unauthorized access occurs. B) Vulnerability scanning is useful but does not specifically address the issue of plaintext password storage. C) Security testing for other vulnerabilities should follow after addressing the data encryption issue. D) While reporting is necessary, it is not a solution in itself; encryption should be the first action taken.",
    "learning_objective": "TTA-6.2",
    "klevel": "K3",
    "points": 3
  },
  
  {
    "question_id": "142",
    "question_text": "During **performance testing**, you notice that the response time of a web application increases significantly as the number of users grows, especially beyond 1000 users. What would be your first action to diagnose and address this performance issue?",
    "options": {
      "A": "Increase the number of server resources (CPU and memory) to handle more users",
      "B": "Identify and resolve any bottlenecks in the code or database queries",
      "C": "Perform a security audit to ensure there are no attacks slowing down the system",
      "D": "Test the system under even more users to see when it crashes"
    },
    "answers": ["B"],
    "explanation": "B) Correct. Identifying and resolving bottlenecks in the code or database queries is crucial to improving the application's performance under load. Bottlenecks are often the cause of increased response times, especially as user numbers grow. A) Increasing server resources may improve performance, but it’s important to first identify and address the root causes of the issue. C) A security audit is important but not directly related to performance bottlenecks. D) Testing with more users before resolving existing issues can lead to inaccurate results and wasted resources.",
    "learning_objective": "TTA-4.3",
    "klevel": "K3",
    "points": 3
  },

  {
    "question_id": "143",
    "question_text": "You are testing a new feature of an **e-commerce** platform that allows users to add products to their shopping cart and proceed to checkout. Which of the following is the most appropriate testing strategy for this feature?",
    "options": {
      "A": "Perform functional testing to ensure the feature works as expected for various use cases",
      "B": "Conduct exploratory testing to discover potential defects not covered by scripted tests",
      "C": "Test the feature under high load conditions to assess its performance during checkout",
      "D": "Perform security testing to ensure sensitive user information is not exposed during the checkout process"
    },
    "answers": ["A", "B"],
    "explanation": "A) Correct. Functional testing is essential to ensure the core functionality of adding products to the cart and completing the checkout process works correctly. B) Correct. Exploratory testing can uncover issues that may not be caught by automated or predefined tests, particularly in complex, user-interactive features like e-commerce checkouts. C) Performance testing is also important but should be done after functional and exploratory testing. D) Security testing should be a priority, but not the first step in this scenario, as functionality and usability need to be ensured first.",
    "learning_objective": "TTA-3.2",
    "klevel": "K3",
    "points": 3
  },

  {
    "question_id": "144",
    "question_text": "You are tasked with performing **endurance testing** on a streaming platform that allows users to watch videos continuously. The application works fine under moderate load, but starts to show degradation in performance after several hours. What is the primary focus of endurance testing in this context?",
    "options": {
      "A": "To determine how the system behaves under extreme stress with a high number of users",
      "B": "To verify if the system can handle prolonged usage over extended periods without performance degradation",
      "C": "To test how the system handles spikes in traffic during peak times",
      "D": "To measure the system’s overall throughput and maximum capacity under load"
    },
    "answers": ["B"],
    "explanation": "B) Correct. Endurance testing (also known as soak testing) is designed to assess how a system performs over a long period of continuous use, identifying any issues that arise due to prolonged stress, such as memory leaks or resource exhaustion. A) Extreme stress testing focuses on breaking the system, not long-term performance. C) Traffic spikes are tested in stress testing or load testing, not endurance testing. D) Throughput and capacity are typically tested during load testing, not endurance testing.",
    "learning_objective": "TTA-4.4",
    "klevel": "K3",
    "points": 3
  },
  
  {
    "question_id": "145",
    "question_text": "During a **usability testing** session for a mobile app, several users report difficulty navigating the app due to complex menu structures. What action should be taken first to improve the user experience?",
    "options": {
      "A": "Modify the app's menu structure to simplify navigation and improve discoverability",
      "B": "Introduce more in-app tutorials to guide users through the app’s features",
      "C": "Perform further usability tests to gather additional feedback before making changes",
      "D": "Optimize the app’s performance to reduce loading times"
    },
    "answers": ["A"],
    "explanation": "A) Correct. The primary issue reported by users is related to the app’s navigation. The first step should be to simplify the menu structure to enhance usability. B) While in-app tutorials are helpful, simplifying the navigation should be the first step to improve usability. C) Further usability tests are necessary after the changes, but the immediate action should address the primary issue. D) Optimizing performance is important, but it doesn't address the core usability issue related to navigation.",
    "learning_objective": "TTA-6.1",
    "klevel": "K3",
    "points": 3
  },

  {
    "question_id": "146",
    "question_text": "You are conducting **regression testing** on a web application after a new feature has been added. The feature interacts with an existing payment gateway. Which of the following test types should be prioritized during regression testing?",
    "options": {
      "A": "Test the new feature to ensure that it integrates properly with the payment gateway",
      "B": "Test the payment gateway to ensure it functions as expected after the new feature has been added",
      "C": "Test the entire application to ensure that no existing functionality is broken by the new feature",
      "D": "Test the user interface for visual issues caused by the new feature"
    },
    "answers": ["C"],
    "explanation": "C) Correct. In regression testing, the focus is on ensuring that new changes have not broken any existing functionality, so the entire application should be tested. A) While testing the new feature’s integration with the payment gateway is important, regression testing focuses on existing functionality. B) The payment gateway should be tested as part of regression testing, but the entire application should be tested to ensure comprehensive validation. D) Visual testing is important but secondary to ensuring functionality is not compromised.",
    "learning_objective": "TTA-3.3",
    "klevel": "K3",
    "points": 3
  },
  {
    "question_id": "147",
    "question_text": "You are tasked with performing **load testing** on an API that handles customer transactions. During testing, you notice that the response time increases significantly when the number of concurrent users exceeds 500. Which of the following is the first action you should take to identify and resolve the performance issue?",
    "options": {
      "A": "Increase the API server’s resources (CPU, memory, etc.) to handle more traffic",
      "B": "Analyze the API’s logs to identify slow or inefficient database queries",
      "C": "Conduct stress testing to find the breaking point of the API",
      "D": "Optimize the API code to reduce the response time for each request"
    },
    "answers": ["B"],
    "explanation": "B) Correct. The first step in identifying performance issues is to analyze the logs and find any slow or inefficient database queries. Poorly optimized queries are often the root cause of performance degradation under load. A) Increasing server resources can help, but it's important to first identify and fix the underlying bottlenecks. C) Stress testing is useful but should be done after identifying performance bottlenecks. D) Optimizing the code is a valid approach, but identifying the root cause (e.g., database issues) should come first.",
    "learning_objective": "TTA-4.3",
    "klevel": "K3",
    "points": 3
  },

  {
    "question_id": "148",
    "question_text": "During **integration testing**, you discover that two modules are not communicating properly due to mismatched data formats. Which of the following actions should be prioritized to resolve this issue?",
    "options": {
      "A": "Update both modules to use a common data format for communication",
      "B": "Perform system testing to verify if other modules are impacted by this issue",
      "C": "Revert the changes made to one of the modules and test the integration again",
      "D": "Test each module separately to confirm they function correctly in isolation"
    },
    "answers": ["A"],
    "explanation": "A) Correct. The issue arises from mismatched data formats between two modules. To resolve this, both modules need to be updated to use a common data format to ensure smooth communication. B) System testing can be performed later, but the focus should be on fixing the integration issue first. C) Reverting changes might be a temporary solution but does not address the root cause of the communication issue. D) Testing modules in isolation does not resolve integration problems and should not be the first step.",
    "learning_objective": "TTA-5.1",
    "klevel": "K3",
    "points": 3
  },

  {
    "question_id": "149",
    "question_text": "You are testing a **distributed system** that has multiple nodes communicating with each other. One of the nodes is frequently timing out during communication with others. What would be the best approach to identify the root cause of the issue?",
    "options": {
      "A": "Analyze the network traffic between the nodes to identify any packet loss or delays",
      "B": "Check the hardware resources on the node to ensure there is no CPU or memory bottleneck",
      "C": "Test the node in isolation to ensure it works correctly without any other nodes connected",
      "D": "Perform a load test on the entire system to simulate high network traffic and observe the issue"
    },
    "answers": ["A", "B"],
    "explanation": "A) Correct. Analyzing network traffic can help identify packet loss, delays, or other issues in communication between the nodes. B) Correct. Checking the hardware resources on the node will help identify any resource limitations, such as CPU or memory, that could be causing the timeouts. C) Testing the node in isolation may not reveal issues related to its communication with other nodes. D) Load testing may help identify broader system issues but is not the most efficient first step for identifying the cause of timeouts between specific nodes.",
    "learning_objective": "TTA-5.2",
    "klevel": "K3",
    "points": 3
  },

  {
    "question_id": "150",
    "question_text": "You are performing **security testing** on an application and discover a potential vulnerability in the authentication mechanism. The system uses weak passwords and does not require multi-factor authentication. Which of the following actions should be prioritized to address this vulnerability?",
    "options": {
      "A": "Implement multi-factor authentication to improve security",
      "B": "Strengthen password policies to enforce the use of complex passwords",
      "C": "Encrypt the authentication tokens to prevent interception during transmission",
      "D": "Report the vulnerability and ask for more time to investigate"
    },
    "answers": ["B", "A"],
    "explanation": "B) Correct. Strengthening password policies by requiring complex passwords is an essential first step in improving the security of the authentication system. A) Correct. Implementing multi-factor authentication adds an additional layer of security, making it harder for attackers to bypass the authentication mechanism. C) Encrypting authentication tokens is also important but should be considered after strengthening the password policies and implementing multi-factor authentication. D) Reporting the vulnerability is necessary, but immediate action should be taken to address it.",
    "learning_objective": "TTA-6.3",
    "klevel": "K3",
    "points": 3
  },

  {
    "question_id": "151",
    "question_text": "You are conducting **usability testing** for a web-based application. During testing, several users report difficulty in finding the search function due to its placement in the navigation bar. Which of the following actions should you take to improve the user experience?",
    "options": {
      "A": "Move the search function to a more prominent location on the page for easier access",
      "B": "Add a tooltip or an on-screen instruction to guide users to the search function",
      "C": "Test the search functionality on different devices to ensure it’s accessible",
      "D": "Conduct another round of usability tests after the change is made"
    },
    "answers": ["C", "D"],
    "explanation": "A) Correct. Moving the search function to a more prominent location will make it easier for users to find and use. B) Correct. Adding a tooltip or on-screen instruction is a helpful way to guide users to the search function and enhance usability. C) Testing on different devices is important, but the main issue here is the location of the search function. D) Conducting another round of usability tests should follow after implementing the changes to ensure they address the issues.",
    "learning_objective": "TTA-6.1",
    "klevel": "K3",
    "points": 3
  },

  {
    "question_id": "152",
    "question_text": "You are conducting a **security audit** of a web application that allows users to upload files. Upon testing, you find that there are no file size limits in place, and users can upload large files that may cause a denial of service. Which action should be taken first to address this issue?",
    "options": {
      "A": "Implement a file size limit to prevent large files from being uploaded",
      "B": "Test the file upload functionality to ensure that other security vulnerabilities are not present",
      "C": "Encrypt all uploaded files to prevent unauthorized access",
      "D": "Monitor file uploads for unusual activity and report it to the security team"
    },
    "answers": ["A"],
    "explanation": "A) Correct. The first step is to implement a file size limit to prevent users from uploading excessively large files, which could overwhelm the server and cause a denial of service. B) While it’s important to test for other security vulnerabilities, addressing the file size limit should be the first priority to mitigate this immediate risk. C) Encrypting files is a good security measure, but it does not address the denial of service issue caused by large file uploads. D) Monitoring uploads is important but should be done after implementing preventative measures such as file size limits.",
    "learning_objective": "TTA-6.4",
    "klevel": "K3",
    "points": 3
  },
{
    "question_id": "153",
    "question_text": "TTA-4.3.1 (K2) Explain the reasons for including security testing in a test approach\n                                                                                  \n        A new personal banking system is to be developed for use on mobile devices. Which ONE of the\n        following options is valid reason to include security testing in the test approach?\n Select 1 option(s).",
    "options": {
      "A": "Ensuring that automated mobile app updates do not block users from accessing their accounts",
      "B": "Ensuring that no confidential information is left in temporary files on the phone’s SIM card memory",
      "C": "Ensuring that the application installs correctly on many different mobile phone models and OS versions",
      "D": "Ensuring that the application provides the planned functionality without overloading the phone’s CPU"
    },
    "answers": [
      "B"
    ],
    "explanation": "a) Is not correct. This is more likely to be an installability concern, not a TTA-4.3.1 K2 1\n                              security concern. If users cannot access their account, the security risk\n                              is reduced\n                            b) Is correct. This is an example of a reason for considering security\n                                                                             -\n                              testing given in the syllabus: “Software which exhibits unintended side\n                              effects when performing its intended function“\n                            c) Is not correct. This is an installability concern, not a security concern\n                            d) Is not correct. This is a performance concern, a not security concern",
    "learning_objective": "TTA-4.3.1",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "154",
    "question_text": "TTA-4.4.1 (K2) Explain the reasons for including reliability testing in a test approach\n        Which of the following factors must be considered when planning reliability tests?\n Select 1 option(s).",
    "options": {
      "A": "Ability to simulate hardware and operating system defects",
      "B": "Monitoring resources used",
      "C": "Identifying vulnerabilities that lead to a denial of service",
      "D": "Determining the peak loads for the system"
    },
    "answers": [
      "A"
    ],
    "explanation": "a) Is correct. Testing fault tolerance to hardware and OS TTA-4.4.1 K2  1\n                                           a system’s\n                              defects is part of reliability testing, and we use fault injection testing to\n                              create defects in hardware or in the OS to occur\n                            b) Is not correct. This relates to performance efficiency testing\n                            c) Is not correct. Vulnerabilities leading to a denial of service would be\n                              associated with security testing\n                            d) Is not correct. This relates to performance efficiency testing",
    "learning_objective": "TTA-4.4.1",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "155",
    "question_text": "TTA-4.5.1 (K2) Explain the reasons for including performance testing in a test approach\n                                                                                  \n        A web-based holiday booking system expects to handle three times its average number of visitors\n        during the peak month of the year.                                        \n                                                                                  \n        Which of the following reasons would justify including performance testing in the test approach?\n Select 2 option(s).",
    "options": {
      "A": "The web servers may be unable to handle the maximum number of transactions",
      "B": "The expected peak load defined by the business analysts may be too high",
      "C": "Functional tests can be re-used for performance testing",
      "D": "The response time to holiday enquiries may be unacceptable for users",
      "E": "Skills in using performance testing tools are available"
    },
    "answers": [
      "A",
      "D"
    ],
    "explanation": "a) Is correct. The ability of the web servers to support the expected peak TTA-4.5.1 K2 1\n                              number of transactions is a risk that can be addressed by performance\n                              testing\n                            b) Is not correct. If the expected peak load was defined to be too high\n                              (rather than too low), then it is unlikely to lead to a risk high enough to\n                              need mitigating by performance testing\n                            c) Is not correct. Re-using functional tests is not a reason for conducting\n                              performance tests. Being able to reuse test cases is a bonus, but not a\n                              reason. Performing the tests and analyzing the results is still extra effort\n                              that needs justification\n                            d) Is correct. People may abandon the site if their enquiry responses take\n                              too long, which may occur during the peak month. This is a risk that can\n                              be addressed by performance testing\n                            e) Is not correct. Having skills in performance testing tools is good, but it is\n                              not a reason to conduct performance tests",
    "learning_objective": "TTA-4.5.1",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "156",
    "question_text": "TTA-4.8.1 (K2) Explain the reasons for including co-existence testing in a test approach\n                                                                                  \n        Which of the following is an example of compatibility testing?\n Select 1 option(s).",
    "options": {
      "A": "Checking if there is a resource conflict between the application being tested and another application",
      "B": "Checking if a component from outside the system can be a replacement for an existing component",
      "C": "Checking if a loan installment is computed in the same currency as the input data describing the loan size",
      "D": "Checking if all modules within a system are written in the same programming language"
    },
    "answers": [
      "A"
    ],
    "explanation": "a) Is correct. This is an example of co-existence testing, and co-existence TTA-4.8.1 K2 1\n                              is a sub-characteristic of compatibility\n                            b) Is not correct. This is an example of replaceability testing, and\n                              replaceability is a sub-characteristic of portability, not compatibility\n                            c) Is not correct. This is an example of functional testing. Compatibility\n                              testing is testing of a non-functional characteristic\n                            d) Is not correct. This may be relevant to maintainability testing but has\n                              nothing to do with compatibility testing",
    "learning_objective": "TTA-4.8.1",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "157",
    "question_text": "You are testing a **distributed system** where the nodes are intermittently unable to sync data with the main server. The network bandwidth seems sufficient, and there are no clear hardware issues. What is the first step you should take to diagnose the issue?",
    "options": {
      "A": "Check the system's network protocol configuration to ensure proper data synchronization",
      "B": "Check for software bugs in the synchronization logic of the distributed system",
      "C": "Increase the system's bandwidth to ensure better synchronization",
      "D": "Perform a load test to simulate heavy traffic and check if the issue is related to system overload"
    },
    "answers": ["B"],
    "explanation": "B) Correct. Software bugs in the synchronization logic are a likely cause of the intermittent failures in syncing data, so investigating the code and logs for potential bugs is the first step. A) Network protocol configuration may cause issues, but there’s no indication that network bandwidth is the cause. C) Increasing bandwidth may not address the root cause if the issue lies in the synchronization logic. D) Load testing is useful but should be performed after resolving potential software-related issues.",
    "learning_objective": "TTA-5.2",
    "klevel": "K3",
    "points": 3
  },

  {
    "question_id": "158",
    "question_text": "You are performing **security testing** on a web application and discover that sensitive data is being transmitted in plain text. Which of the following is the most appropriate action to mitigate this vulnerability?",
    "options": {
      "A": "Encrypt all sensitive data before transmission using SSL/TLS",
      "B": "Use a VPN to encrypt the data during transmission",
      "C": "Mask sensitive data in the database to prevent unauthorized access",
      "D": "Store sensitive data in encrypted files on the server"
    },
    "answers": ["A"],
    "explanation": "A) Correct. The most effective way to secure sensitive data during transmission is to use SSL/TLS encryption, which ensures that the data is protected from interception. B) A VPN could provide encryption, but SSL/TLS is specifically designed for web communication. C) Masking sensitive data in the database is important but does not protect data during transmission. D) Storing sensitive data in encrypted files is a good security practice, but it does not address the issue of transmitting data in plain text.",
    "learning_objective": "TTA-6.4",
    "klevel": "K3",
    "points": 3
  },

  {
    "question_id": "159",
    "question_text": "During **performance testing**, you notice that the application performs well under moderate load but begins to degrade significantly under heavy load, especially during peak hours. Which of the following is the most appropriate strategy to identify and resolve the issue?",
    "options": {
      "A": "Analyze the application’s performance during peak hours to identify bottlenecks",
      "B": "Conduct stress testing to determine the application’s breaking point",
      "C": "Increase the server resources to handle more load",
      "D": "Optimize the code to improve efficiency under high load"
    },
    "answers": ["A", "B"],
    "explanation": "A) Correct. Analyzing performance during peak hours will help identify specific bottlenecks that occur when the application is under load. B) Correct. Stress testing can help you identify the maximum load the application can handle and find the breaking point. C) Increasing server resources might provide a temporary fix but will not address the root cause. D) Code optimization is a valid approach but should come after identifying specific bottlenecks in the performance analysis.",
    "learning_objective": "TTA-4.2",
    "klevel": "K3",
    "points": 3
  },

  {
    "question_id": "160",
    "question_text": "You are tasked with conducting **usability testing** for a mobile application. Users consistently have trouble accessing key features, such as settings and notifications, which are buried under multiple layers of the interface. What should be your first action?",
    "options": {
      "A": "Simplify the navigation by making key features more accessible from the main menu",
      "B": "Conduct another round of usability testing to confirm the findings",
      "C": "Improve the layout and appearance of the settings page to make it more visually appealing",
      "D": "Gather user feedback to understand why they are having trouble accessing the features"
    },
    "answers": ["B", "D"],
    "explanation": "A) Correct. Simplifying navigation by making key features more accessible from the main menu will immediately address the usability issues. D) Correct. Gathering user feedback helps in understanding the specific pain points and can guide the design of more user-friendly interfaces. B) While conducting additional testing is important, addressing the issue by simplifying the navigation should be prioritized first. C) Improving the layout is helpful, but the key issue is making features accessible.",
    "learning_objective": "TTA-6.1",
    "klevel": "K3",
    "points": 3
  },
  {
  "question_id": "161",
  "question_text": "Which two types of testing are primarily concerned with ensuring that the system can handle a high number of transactions without crashing?",
  "options": {
    "A": "Load testing",
    "B": "Stress testing",
    "C": "Performance testing",
    "D": "Usability testing"
  },
  "answers": ["A", "B"],
  "explanation": "A) Load testing ensures the system can handle expected traffic levels without failure. B) Stress testing goes further to determine the system's behavior under extreme conditions, including overloading the system. C) Performance testing focuses on how well the system performs under normal and peak load but is not necessarily about extreme failure conditions. D) Usability testing is unrelated to system capacity or handling transactions.",
  "learning_objective": "TTA-4.2.4",
  "klevel": "K2",
  "points": 2
},
{
  "question_id": "162",
  "question_text": "You are conducting white-box testing on a module with a complex decision structure. To achieve 100% Modified Condition/Decision Coverage (MC/DC), how many independent conditions must be tested?",
  "options": {
    "A": "One",
    "B": "Two",
    "C": "Three",
    "D": "Four"
  },
  "answers": ["B"],
  "explanation": "B) To achieve 100% MC/DC, each condition in a decision must be independently tested to ensure it affects the decision’s outcome. Typically, two conditions are required for testing in a module with multiple decision points. A) A single condition is not enough to test for MC/DC. C) Three conditions are needed in certain complex cases but not always. D) Four is unnecessary unless specified by the decision logic.",
  "learning_objective": "TTA-3.2.1",
  "klevel": "K3",
  "points": 3
},
{
  "question_id": "163",
  "question_text": "Which two testing techniques should be used for ensuring the correct integration between several independently developed modules of a complex system?",
  "options": {
    "A": "Integration testing",
    "B": "Unit testing",
    "C": "System testing",
    "D": "Interface testing"
  },
  "answers": ["A", "D"],
  "explanation": "A) Integration testing is specifically aimed at ensuring that different system modules interact correctly. D) Interface testing checks for issues in the communication between modules or systems. B) Unit testing is focused on individual components, not the interaction between multiple modules. C) System testing evaluates the system as a whole but is not specifically about module interaction.",
  "learning_objective": "TTA-2.3.2",
  "klevel": "K2",
  "points": 2
},
{
  "question_id": "164",
  "question_text": "Which two are the primary concerns of performance testing during the software lifecycle?",
  "options": {
    "A": "Ensuring the system can handle large data volumes",
    "B": "Testing the system’s usability in extreme conditions",
    "C": "Verifying the response time under load",
    "D": "Checking for functional correctness"
  },
  "answers": ["A", "C"],
  "explanation": "A) Performance testing ensures the system can handle large amounts of data without degradation in performance. C) Verifying response time under load is a key part of performance testing. B) While usability is important, it is not the focus of performance testing. D) Functional correctness is covered by functional testing, not performance testing.",
  "learning_objective": "TTA-4.2.4",
  "klevel": "K3",
  "points": 3
},
{
    "question_id": "165",
    "question_text": "You are conducting **regression testing** on a web application after a new feature has been added. The feature interacts with an existing module. Which two actions should you prioritize to ensure that the new feature doesn’t break existing functionality?",
    "options": {
      "A": "Test the new feature in isolation without considering other modules",
      "B": "Test the entire application to verify that no existing functionality has been broken",
      "C": "Automate regression tests to ensure consistency in repeated testing",
      "D": "Focus on testing only the affected module"
    },
    "answers": ["B", "C"],
    "explanation": "B) Correct. Regression testing ensures that new features do not affect existing functionality, and testing the entire application helps uncover issues. C) Correct. Automating regression tests improves efficiency and ensures tests are consistent and can be easily repeated. A) Testing only the new feature is insufficient since you also need to validate the rest of the application. D) Focusing only on the affected module misses the chance to catch potential integration issues with other parts of the system.",
    "learning_objective": "TTA-3.3",
    "klevel": "K2",
    "points": 3
  },
  {
    "question_id": "166",
    "question_text": "Which two testing techniques are most commonly used for ensuring that the user interface (UI) is functional and behaves as expected during **functional testing**?",
    "options": {
      "A": "Boundary Value Analysis",
      "B": "Equivalence Partitioning",
      "C": "Usability Testing",
      "D": "Interaction Testing"
    },
    "answers": ["B", "D"],
    "explanation": "B) Correct. Equivalence Partitioning divides the input data into equivalent partitions to ensure all possible cases are tested. D) Correct. Interaction Testing focuses on how different UI elements interact with each other, which is critical for functional testing of the UI. A) Boundary Value Analysis is more suited for testing input ranges, not specifically for UI functionality. C) Usability Testing focuses on user experience, not functional behavior of the UI.",
    "learning_objective": "TTA-2.1",
    "klevel": "K2",
    "points": 3
  },
  {
    "question_id": "167",
    "question_text": "When performing **performance testing** for a web application, which two factors are most important to assess?",
    "options": {
      "A": "The user interface responsiveness",
      "B": "The application’s throughput and response time",
      "C": "The system’s CPU and memory usage under load",
      "D": "The aesthetic design of the website"
    },
    "answers": ["B", "C"],
    "explanation": "B) Correct. Throughput and response time are crucial for assessing how well the system handles traffic and how quickly it responds under load. C) Correct. Monitoring CPU and memory usage helps identify potential bottlenecks and ensures the system is resource-efficient under load. A) User interface responsiveness is important but is part of usability testing, not performance testing. D) The aesthetic design is irrelevant to performance testing.",
    "learning_objective": "TTA-4.2",
    "klevel": "K3",
    "points": 3
  },
  {
    "question_id": "168",
    "question_text": "You are testing a component of a **microservices-based** system. Which two types of testing are essential for ensuring that the individual microservices interact correctly and the system functions as a whole?",
    "options": {
      "A": "Unit testing",
      "B": "Integration testing",
      "C": "System testing",
      "D": "Performance testing"
    },
    "answers": ["B", "C"],
    "explanation": "B) Correct. Integration testing ensures that individual microservices communicate correctly and handle the interactions as expected. C) Correct. System testing ensures that the entire system, consisting of many services, works together as intended. A) Unit testing focuses on individual components, but the interaction between services requires integration testing. D) Performance testing is important but does not focus on the interaction between microservices.",
    "learning_objective": "TTA-3.1",
    "klevel": "K2",
    "points": 3
  },
  {
    "question_id": "169",
    "question_text": "Which two testing types would be best suited for verifying that an application works properly under extreme conditions, such as high traffic or excessive load?",
    "options": {
      "A": "Stress testing",
      "B": "Load testing",
      "C": "Functional testing",
      "D": "Endurance testing"
    },
    "answers": ["A", "B"],
    "explanation": "A) Correct. Stress testing simulates extreme load to determine how the system behaves under failure conditions and breaks. B) Correct. Load testing evaluates the system's performance under normal and peak load conditions, ensuring it can handle expected user traffic. C) Functional testing verifies the correctness of features, but it doesn't focus on load or extreme conditions. D) Endurance testing checks performance over time but isn't designed to simulate extreme load scenarios.",
    "learning_objective": "TTA-4.3",
    "klevel": "K3",
    "points": 3
  },
  {
    "question_id": "170",
    "question_text": "You are testing a **web application** and find that certain users can bypass authentication by manipulating HTTP requests. Which of the following should be your next step to address this issue?",
    "options": {
      "A": "Perform a penetration test to identify potential vulnerabilities",
      "B": "Report the vulnerability and escalate it to the development team",
      "C": "Fix the vulnerability in the authentication mechanism and retest",
      "D": "Conduct a code review to identify all potential security flaws"
    },
    "answers": ["B", "C"],
    "explanation": "B) Correct. As a tester, reporting the vulnerability to the development team and escalating it for remediation is a priority. C) Correct. Fixing the vulnerability and retesting it ensures that the authentication mechanism is secure. A) Penetration testing is valuable but should be done after identifying and addressing specific vulnerabilities. D) Code reviews are essential but are typically carried out by developers, not testers, to address security flaws.",
    "learning_objective": "TTA-6.2",
    "klevel": "K3",
    "points": 3
  },
  {
    "question_id": "171",
    "question_text": "Which two activities are most critical when conducting **acceptance testing** to ensure the system meets user requirements?",
    "options": {
      "A": "Testing the system against the requirements and user stories",
      "B": "Validating that the system is performance-optimized",
      "C": "Checking that the system’s functionality is in line with the business goals",
      "D": "Performing security tests to find vulnerabilities"
    },
    "answers": ["A", "C"],
    "explanation": "A) Correct. Acceptance testing ensures that the system meets the specified requirements and user stories, confirming it fulfills the intended purpose. C) Correct. Validating that the system aligns with business goals is a core part of acceptance testing, ensuring it delivers value to the stakeholders. B) Performance optimization is important but is typically handled during performance testing, not acceptance testing. D) Security testing is critical but isn't the main focus during acceptance testing.",
    "learning_objective": "TTA-2.2",
    "klevel": "K2",
    "points": 3
  },
  {
    "question_id": "172",
    "question_text": "You are tasked with verifying the correctness of **boundary conditions** in a piece of software. Which testing technique would be most effective in this case?",
    "options": {
      "A": "Equivalence partitioning",
      "B": "Boundary value analysis",
      "C": "State transition testing",
      "D": "Decision table testing"
    },
    "answers": ["B"],
    "explanation": "B) Correct. Boundary value analysis is specifically designed to test boundary conditions, focusing on values at the edge of input ranges. A) Equivalence partitioning divides the input into groups but doesn't focus on the boundaries. C) State transition testing is more focused on state changes and event sequences. D) Decision table testing is useful for complex decision logic, but boundary conditions are better addressed with boundary value analysis.",
    "learning_objective": "TTA-3.2",
    "klevel": "K2",
    "points": 3
  },
  {
    "question_id": "173",
    "question_text": "During **security testing** of a web application, you find that a user can access data they should not be able to by modifying URLs. What type of security vulnerability is this likely to be?",
    "options": {
      "A": "Cross-Site Scripting (XSS)",
      "B": "Insecure Direct Object Reference (IDOR)",
      "C": "SQL Injection",
      "D": "Broken Authentication"
    },
    "answers": ["B"],
    "explanation": "B) Correct. Insecure Direct Object Reference (IDOR) occurs when an attacker can access objects or data by manipulating input such as URLs. A) XSS involves injecting scripts into web pages, not URL manipulation. C) SQL Injection allows attackers to inject malicious SQL, not access unauthorized data via URL. D) Broken Authentication relates to issues with logging in and authentication mechanisms, not direct object access.",
    "learning_objective": "TTA-6.3",
    "klevel": "K3",
    "points": 3
  },
  {
    "question_id": "174",
    "question_text": "You are conducting **model-based testing** (MBT) for a complex system that has multiple interacting components with conditional behaviors. Which two actions would ensure that your MBT approach provides sufficient coverage of all potential interactions between components?",
    "options": {
      "A": "Ensure that the model includes both normal and exceptional scenarios for all components",
      "B": "Focus on generating tests only for the most frequently used components",
      "C": "Incorporate state transition models for each component to handle different input conditions",
      "D": "Limit test generation to paths with the highest probability of execution"
    },
    "answers": ["A", "C"],
    "explanation": "A) Correct. Ensuring that the model includes both normal and exceptional scenarios for all components is critical for providing comprehensive test coverage. B) Focusing only on the most frequently used components will leave the less common paths untested. C) Correct. Incorporating state transition models allows for capturing the different inputs and outputs, ensuring that all states and conditions are tested. D) Limiting test generation to high-probability paths can leave critical corner cases untested.",
    "learning_objective": "TTA-2.4",
    "klevel": "K3",
    "points": 3
  },
  {
    "question_id": "175",
    "question_text": "You are testing a **highly dynamic** cloud-based application where resources (CPU, memory, etc.) are provisioned on-demand. The application’s performance is crucial, and you need to measure the system’s response time under varying resource conditions. Which two testing techniques should you prioritize to ensure that the system performs optimally in a real-world environment?",
    "options": {
      "A": "Load testing with fluctuating resources to simulate real-world traffic patterns",
      "B": "Endurance testing to monitor system behavior under prolonged use",
      "C": "Stress testing to push the system beyond its resource limits",
      "D": "Usability testing to ensure the application meets user expectations"
    },
    "answers": ["A", "B"],
    "explanation": "A) Correct. Load testing with fluctuating resources ensures that the system can handle dynamic resource allocation under real-world conditions. B) Correct. Endurance testing is critical to monitoring the system’s behavior over extended periods, ensuring stability during sustained use. C) Stress testing helps identify system limits but isn't as relevant for performance under normal conditions. D) Usability testing is important but is not focused on performance metrics.",
    "learning_objective": "TTA-4.2",
    "klevel": "K3",
    "points": 3
  },
  {
    "question_id": "176",
    "question_text": "In **security testing** for a financial application, you notice that sensitive transaction data is being exposed in server logs. Which two actions should be prioritized to address this issue effectively?",
    "options": {
      "A": "Encrypt sensitive data before it is written to logs",
      "B": "Delete all logs that contain sensitive data immediately",
      "C": "Mask sensitive information in logs, displaying only necessary details",
      "D": "Implement strict log access controls to prevent unauthorized access to logs"
    },
    "answers": ["A", "C"],
    "explanation": "A) Correct. Encrypting sensitive data before logging it ensures that even if logs are accessed by unauthorized users, the data is unreadable. C) Correct. Masking sensitive information in logs ensures that only necessary, non-sensitive details are exposed, reducing the risk of data leakage. B) Deleting logs immediately isn't a sustainable solution, as logs are critical for troubleshooting and auditing. D) While log access controls are important, they don't address the fundamental issue of sensitive data being logged in the first place.",
    "learning_objective": "TTA-6.3",
    "klevel": "K3",
    "points": 3
  },
  {
    "question_id": "177",
    "question_text": "You are tasked with performing **boundary value analysis** on an e-commerce application that accepts customer ages ranging from 18 to 100. What would be the most comprehensive set of test inputs for boundary value analysis?",
    "options": {
      "A": "18, 100, 17, 101",
      "B": "17, 18, 19, 99, 100, 101",
      "C": "18, 100, 99, 101",
      "D": "17, 18, 100, 101"
    },
    "answers": ["B"],
    "explanation": "B) Correct. Boundary value analysis requires testing the boundaries and values just outside them. The set 17, 18, 19 (below and at the lower boundary) and 99, 100, 101 (just below and above the upper boundary) covers all critical boundary conditions. A) While 17 and 101 test the boundaries, it misses values near 19 and 99, which are essential for full coverage. C) Testing only 99 and 101 misses the lower boundary. D) Missing critical middle values, like 19 or 99, makes this set less comprehensive.",
    "learning_objective": "TTA-3.2",
    "klevel": "K2",
    "points": 3
  },
  {
    "question_id": "178",
    "question_text": "During **exploratory testing**, you discover a defect where the application crashes when the user performs a specific sequence of actions. What should be your next step as a tester?",
    "options": {
      "A": "Attempt to reproduce the defect and document the exact steps",
      "B": "Notify the development team to fix the bug immediately",
      "C": "Check if the issue is related to recent changes in the codebase",
      "D": "Run automated tests to see if the defect is already covered"
    },
    "answers": ["A", "C"],
    "explanation": "A) Correct. As a tester, your first step is to reproduce the defect and document the exact steps so that developers can reliably recreate and fix the issue. C) Correct. Checking if the issue relates to recent changes helps identify potential regression issues or areas where code changes may have introduced the defect. B) Reporting is essential, but you should first gather data about the defect. D) Automated tests might not cover this specific issue, so manual testing is necessary to identify and document it.",
    "learning_objective": "TTA-5.1",
    "klevel": "K3",
    "points": 3
  },
  {
    "question_id": "179",
    "question_text": "Which two of the following are most important considerations when selecting a test automation tool for testing a **cloud-based system**?",
    "options": {
      "A": "The tool’s ability to scale with cloud resources",
      "B": "Support for running tests across multiple cloud environments",
      "C": "Integration with version control systems for code management",
      "D": "Availability of pre-built test cases for cloud applications"
    },
    "answers": ["A", "B"],
    "explanation": "A) Correct. The tool’s ability to scale with cloud resources is crucial for testing cloud-based systems, ensuring that it can handle varying loads and resources effectively. B) Correct. Support for running tests across multiple cloud environments ensures compatibility and coverage across different platforms and configurations. C) Version control integration is useful but not as critical for cloud-based system testing as scalability and environment support. D) Pre-built test cases can be helpful, but they are less important than scalability and environment compatibility.",
    "learning_objective": "TTA-2.4",
    "klevel": "K3",
    "points": 3
  },
  {
    "question_id": "180",
    "question_text": "You are conducting **integration testing** for a web application with multiple third-party APIs. One API is intermittently failing during tests. What should be your first step to diagnose and address the issue?",
    "options": {
      "A": "Verify the status and reliability of the third-party API during test execution",
      "B": "Test the other APIs to ensure they are functioning correctly",
      "C": "Check the application’s integration points to see if the issue is internal",
      "D": "Report the issue to the third-party API provider immediately"
    },
    "answers": ["A", "C"],
    "explanation": "A) Correct. Verifying the status and reliability of the third-party API during test execution is crucial to determine if the issue lies with the external service. C) Correct. Checking the integration points internally ensures that the application is correctly interacting with the API and that the issue isn’t within your code. B) Testing other APIs may help, but it doesn't directly address the issue with the failing API. D) Reporting to the API provider may be necessary but should be done after confirming the issue on your end.",
    "learning_objective": "TTA-2.2",
    "klevel": "K3",
    "points": 3
  },
  {
    "question_id": "181",
    "question_text": "You are tasked with performing **security testing** on a web application. During your testing, you discover that the application is not enforcing strong password policies. What should be your next step?",
    "options": {
      "A": "Report the issue to the development team for remediation",
      "B": "Check other parts of the application for additional security vulnerabilities",
      "C": "Test the password reset functionality to see if it’s secure",
      "D": "Test with different weak passwords to confirm the issue"
    },
    "answers": ["A", "B"],
    "explanation": "A) Correct. As a tester, your next step should be to report the weak password policy to the development team so that it can be addressed and remediated. B) Correct. It's important to check other areas of the application for security vulnerabilities, as this could be a symptom of a broader security issue. C) Testing the password reset functionality is useful but secondary to addressing the weak password policy first. D) Testing with weak passwords further can confirm the issue but isn't necessary once you've identified the problem.",
    "learning_objective": "TTA-6.2",
    "klevel": "K3",
    "points": 3
  },
  {
    "question_id": "182",
    "question_text": "You are testing an **autonomous vehicle control system** responsible for braking decisions. The logic for applying brakes depends on the conditions: (OBSTACLE_DETECTED AND SPEED > 60) OR (ROAD_WET AND SPEED > 40). Which white-box test technique would provide the highest level of confidence while remaining feasible for such a safety-critical system?",
    "options": {
      "A": "Decision testing",
      "B": "Modified Condition/Decision Coverage (MC/DC)",
      "C": "Statement testing",
      "D": "Multiple condition testing"
    },
    "answers": ["B"],
    "explanation": "MC/DC testing is the most appropriate for safety-critical systems as it ensures that each atomic condition independently affects the decision outcome without requiring exhaustive multiple condition testing, which would be infeasible.",
    "learning_objective": "TTA-2.8.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "183",
    "question_text": "A Technical Test Analyst is reviewing a function that calculates insurance premiums. Static analysis reports indicate high **cyclomatic complexity** and low **cohesion**. Which recommendation should be made first to improve maintainability?",
    "options": {
      "A": "Increase unit test coverage to 100%",
      "B": "Split the function into smaller, more focused subroutines",
      "C": "Add more inline comments to clarify business logic",
      "D": "Replace all conditional logic with switch statements"
    },
    "answers": ["B"],
    "explanation": "Splitting large, complex, and low-cohesion functions into smaller, single-purpose modules reduces complexity, improves readability, and enhances maintainability. Comments help but do not address the core structural issue.",
    "learning_objective": "TTA-3.2.3",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "184",
    "question_text": "You are performing **dynamic analysis** on a financial transaction module that has recently shown intermittent crashes. The tool reports multiple memory leaks and one null pointer dereference. Which of the following should be your next step?",
    "options": {
      "A": "Increase the load on the system to reproduce the issue faster",
      "B": "Perform static code analysis to identify uninitialized variables",
      "C": "Add assertions in the code to catch the null pointer condition early",
      "D": "Rerun the dynamic analysis with garbage collection disabled"
    },
    "answers": ["C"],
    "explanation": "After identifying a null pointer dereference, adding assertions or defensive programming measures is a valid next step to confirm and prevent the fault at runtime. Dynamic findings should guide targeted preventive action.",
    "learning_objective": "TTA-3.3.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "185",
    "question_text": "A new healthcare monitoring system must process patient data securely and meet regulatory compliance for **data confidentiality and integrity**. Which combination of test types should be prioritized by the Technical Test Analyst?",
    "options": {
      "A": "Security testing and reliability testing",
      "B": "Maintainability testing and performance efficiency testing",
      "C": "Usability testing and compatibility testing",
      "D": "Portability testing and installability testing"
    },
    "answers": ["A"],
    "explanation": "For regulatory healthcare systems, security (to ensure confidentiality and integrity) and reliability (to ensure consistent operation) are top priorities per quality characteristic alignment.",
    "learning_objective": "TTA-4.2.1",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "186",
    "question_text": "You are analyzing logs from a **load test** on a new e-commerce platform. Response times increase significantly after 5,000 concurrent users, though no errors are reported. Which type of non-functional testing should be extended to identify the cause?",
    "options": {
      "A": "Scalability testing",
      "B": "Stress testing",
      "C": "Reliability testing",
      "D": "Operability testing"
    },
    "answers": ["A"],
    "explanation": "Scalability testing focuses on how performance efficiency changes as load increases. The degradation after 5,000 users suggests scalability limits rather than outright system failure.",
    "learning_objective": "TTA-4.2.4",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "187",
    "question_text": "During API testing of a payment gateway, you discover that the API returns full credit card numbers in the response payloads. Which quality characteristic is being violated, and what should be your immediate action?",
    "options": {
      "A": "Security – Report the issue as a critical confidentiality breach",
      "B": "Reliability – Increase the number of test repetitions",
      "C": "Performance – Measure response latency impact",
      "D": "Maintainability – Suggest masking logic in documentation"
    },
    "answers": ["A"],
    "explanation": "Exposing full credit card numbers breaches data confidentiality and violates security standards (e.g., PCI DSS). This must be reported immediately as a critical security issue.",
    "learning_objective": "TTA-4.3.2",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "188",
    "question_text": "While planning system integration testing for a **distributed AI analytics platform**, multiple components are hosted across different cloud regions. Which of the following risks should be prioritized?",
    "options": {
      "A": "Test environment scalability limitations",
      "B": "Organizational coordination between distributed teams",
      "C": "Tool acquisition for regression testing",
      "D": "Stakeholder agreement on feature priority"
    },
    "answers": ["B"],
    "explanation": "Distributed system integration often introduces coordination and synchronization risks among geographically dispersed teams and components. This is a key risk area for TTA to address.",
    "learning_objective": "TTA-4.2.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "189",
    "question_text": "A Technical Test Analyst is designing **security tests** for a cloud-based HR application. Which test would BEST evaluate the **integrity** of the stored employee data?",
    "options": {
      "A": "Attempt to modify salary data through unauthorized API access",
      "B": "Check response times under simultaneous logins",
      "C": "Verify encryption strength for stored credentials",
      "D": "Review password reset functionality"
    },
    "answers": ["A"],
    "explanation": "Testing integrity involves ensuring that only authorized users can modify data. Attempting unauthorized data modification directly validates integrity protection mechanisms.",
    "learning_objective": "TTA-4.3.2",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "190",
    "question_text": "You are reviewing the results of static analysis performed on a large legacy codebase. The report shows numerous **dead code segments** and variables that are **defined but never used**. Which of the following statements is TRUE?",
    "options": {
      "A": "These issues are examples of control flow and data flow anomalies respectively",
      "B": "These issues can only be detected using dynamic analysis",
      "C": "Both issues represent potential memory leaks during execution",
      "D": "Neither issue affects maintainability"
    },
    "answers": ["A"],
    "explanation": "Dead code (unreachable) represents control flow anomalies, while variables defined but not used are data flow anomalies. Both can be detected by static analysis and reduce maintainability.",
    "learning_objective": "TTA-3.2.2",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "191",
    "question_text": "After performing **modified condition/decision coverage** testing on a safety-critical module, you notice that one atomic condition has never independently affected the decision outcome. What should you do NEXT?",
    "options": {
      "A": "Add a new test case to isolate the impact of that condition",
      "B": "Mark it as covered since the decision was evaluated",
      "C": "Perform statement coverage to validate all paths",
      "D": "Stop testing because MC/DC coverage has been achieved"
    },
    "answers": ["A"],
    "explanation": "If an atomic condition has not independently affected the decision outcome, MC/DC has not been achieved. A new test case must be added to demonstrate its independent influence.",
    "learning_objective": "TTA-2.4.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "192",
    "question_text": "Which of the following BEST describes the main objective of static analysis in technical testing?",
    "options": {
      "A": "To execute code to identify logical errors during runtime",
      "B": "To detect defects such as unreachable code or unused variables without execution",
      "C": "To assess system performance under high load conditions",
      "D": "To ensure compliance with customer business requirements"
    },
    "answers": ["B"],
    "explanation": "Static analysis identifies issues in code, design, or documentation without executing the program. Examples include detecting unreachable code, naming violations, or uninitialized variables.",
    "learning_objective": "TTA-3.2.1",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "193",
    "question_text": "During reviews, the Technical Test Analyst notices that multiple modules have similar algorithms implemented separately. Which quality characteristic is MOST likely affected?",
    "options": {
      "A": "Efficiency",
      "B": "Maintainability",
      "C": "Reliability",
      "D": "Portability"
    },
    "answers": ["B"],
    "explanation": "Duplicated code reduces maintainability because changes must be replicated across multiple modules, increasing the risk of inconsistency.",
    "learning_objective": "TTA-3.2.3",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "194",
    "question_text": "Which of the following test types primarily targets **confidentiality** as a sub-characteristic of security?",
    "options": {
      "A": "Stress testing",
      "B": "Penetration testing",
      "C": "Recovery testing",
      "D": "Usability testing"
    },
    "answers": ["B"],
    "explanation": "Penetration testing checks whether unauthorized users can access confidential data or system resources, directly addressing confidentiality.",
    "learning_objective": "TTA-4.3.2",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "195",
    "question_text": "In the context of **API testing**, which defect would most likely be discovered through boundary value analysis?",
    "options": {
      "A": "Incorrect HTTP response codes",
      "B": "Failure when parameter values reach defined limits",
      "C": "Inconsistent data serialization format",
      "D": "Missing endpoint authentication"
    },
    "answers": ["B"],
    "explanation": "Boundary value analysis is used to detect defects when input parameters reach their upper or lower boundaries, typical in numerical API parameters.",
    "learning_objective": "TTA-2.7.1",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "196",
    "question_text": "You are asked to identify **product risks** for a new web-based booking system. Which of the following risks falls under the Technical Test Analyst’s responsibility?",
    "options": {
      "A": "Late delivery of project documentation",
      "B": "Unreliable integration with external payment gateways",
      "C": "Frequent changes in business requirements",
      "D": "Lack of stakeholder engagement"
    },
    "answers": ["B"],
    "explanation": "The Technical Test Analyst focuses on technical product risks such as integration failures, security vulnerabilities, or performance inefficiencies.",
    "learning_objective": "TTA-1.2.1",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "197",
    "question_text": "When selecting a test automation tool for performance testing, which criterion should the Technical Test Analyst consider FIRST?",
    "options": {
      "A": "The cost of annual license renewals",
      "B": "Compatibility with the system’s technology stack",
      "C": "Availability of pre-written test cases",
      "D": "Number of testers trained on the tool"
    },
    "answers": ["B"],
    "explanation": "Tool compatibility with the system’s architecture, interfaces, and protocols is essential before considering cost or team training.",
    "learning_objective": "TTA-5.1.1",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "198",
    "question_text": "A Technical Test Analyst is preparing to use a static code analyzer for a project written in Java. Which of the following defect types is the tool LEAST likely to identify?",
    "options": {
      "A": "Unused imports",
      "B": "Unreachable code blocks",
      "C": "Incorrect algorithm output",
      "D": "Variables declared but never used"
    },
    "answers": ["C"],
    "explanation": "Static analysis cannot detect logical errors related to incorrect output since it does not execute the program.",
    "learning_objective": "TTA-3.2.1",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "199",
    "question_text": "You are executing **reliability testing** for a mobile banking application. Which of the following metrics would provide the MOST useful measurement?",
    "options": {
      "A": "Mean Time To Failure (MTTF)",
      "B": "Number of concurrent users",
      "C": "Transaction throughput rate",
      "D": "Code coverage percentage"
    },
    "answers": ["A"],
    "explanation": "MTTF measures the average time the system operates before failure, directly indicating reliability.",
    "learning_objective": "TTA-4.2.2",
    "klevel": "K3",
    "points": 2
  },
  {
    "question_id": "200",
    "question_text": "Which of the following statements about **dynamic analysis** is TRUE?",
    "options": {
      "A": "It identifies potential performance bottlenecks by analyzing code execution",
      "B": "It focuses on non-executable documentation such as design diagrams",
      "C": "It can only be performed after all static analysis issues are resolved",
      "D": "It cannot be used to detect memory leaks"
    },
    "answers": ["A"],
    "explanation": "Dynamic analysis involves executing software to monitor runtime behavior such as memory usage, performance, and potential bottlenecks.",
    "learning_objective": "TTA-3.3.1",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "201",
    "question_text": "In technical testing, which of the following is a correct example of **maintainability testing**?",
    "options": {
      "A": "Evaluating how easily a module’s source code can be modified after static analysis findings",
      "B": "Checking if the software functions correctly on multiple operating systems",
      "C": "Determining the maximum number of users before response time degrades",
      "D": "Assessing data recovery after a server crash"
    },
    "answers": ["A"],
    "explanation": "Maintainability testing evaluates how easily software can be modified, corrected, or enhanced — often following static analysis or reviews.",
    "learning_objective": "TTA-4.2.3",
    "klevel": "K2",
    "points": 1
  },
  {
    "question_id": "202",
    "question_text": "You are testing a drone control module whose flight path logic depends on three atomic conditions: GPS_LOCKED, OBSTACLE_DETECTED, and BATTERY_OK. The decision is: IF (GPS_LOCKED AND BATTERY_OK) OR OBSTACLE_DETECTED THEN LAND_IMMEDIATELY. Due to certification rules, the system must comply with **DO-178C Level A**. Which test approach provides adequate coverage while maintaining test efficiency?",
    "options": {
      "A": "Decision testing with all combinations of conditions",
      "B": "Modified Condition/Decision Coverage (MC/DC) showing each atomic condition’s independent effect",
      "C": "Statement coverage of the landing decision logic",
      "D": "Multiple condition testing of all eight combinations"
    },
    "answers": ["B"],
    "explanation": "For airborne safety-critical systems, DO-178C Level A requires Modified Condition/Decision Coverage (MC/DC). It ensures that each condition independently affects the outcome, achieving the required rigor without full multiple-condition explosion.",
    "learning_objective": "TTA-2.8.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "203",
    "question_text": "A Technical Test Analyst must select test techniques to achieve the **most cost-effective coverage** for a control system that uses multiple nested IF-ELSE constructs, but time constraints prevent full MC/DC testing. Which combination of test techniques provides a justified compromise?",
    "options": {
      "A": "Statement coverage combined with decision testing on high-risk modules",
      "B": "Equivalence partitioning combined with path testing",
      "C": "Branch coverage on all code plus boundary value analysis",
      "D": "Use-case testing plus condition coverage"
    },
    "answers": ["A"],
    "explanation": "Statement coverage alone is insufficient, but combining it with decision testing on critical modules balances cost and thoroughness when MC/DC is infeasible. This hybrid approach targets logical branches most likely to fail.",
    "learning_objective": "TTA-2.3.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "204",
    "question_text": "You review the results of a static analysis report showing 80% of functions have high cyclomatic complexity and low cohesion. The project manager suggests delaying refactoring until after release. As a Technical Test Analyst, what should you recommend and why?",
    "options": {
      "A": "Agree; static findings are not critical to release quality",
      "B": "Disagree; refactoring should be prioritized because complexity and low cohesion increase future defect rates and testing costs",
      "C": "Agree only if full decision coverage tests exist",
      "D": "Disagree; postpone testing until code metrics improve"
    },
    "answers": ["B"],
    "explanation": "High cyclomatic complexity and low cohesion indicate poor maintainability and high defect probability. Addressing them early reduces long-term cost and improves test effectiveness; delaying increases risk.",
    "learning_objective": "TTA-3.2.3",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "205",
    "question_text": "During dynamic analysis of a **real-time trading system**, multiple short-duration CPU spikes were detected but without functional errors. What is the MOST likely interpretation, and what should be your next step?",
    "options": {
      "A": "Minor issue; continue testing since no functional defect occurred",
      "B": "Indicates potential performance bottlenecks—perform detailed profiling to isolate inefficient code segments",
      "C": "Suggest disabling garbage collection to reduce latency",
      "D": "Report as reliability defect related to memory leaks"
    },
    "answers": ["B"],
    "explanation": "CPU spikes under real-time constraints may lead to latency breaches. Profiling helps locate inefficient loops or synchronization issues causing transient peaks—vital in time-sensitive systems.",
    "learning_objective": "TTA-3.3.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "206",
    "question_text": "You are preparing non-functional tests for a **distributed IoT monitoring platform** that transmits continuous sensor data. The customer is concerned about **data loss and timing delays**. Which combination of test types addresses both issues effectively?",
    "options": {
      "A": "Reliability and performance efficiency testing",
      "B": "Security and maintainability testing",
      "C": "Compatibility and usability testing",
      "D": "Portability and recovery testing"
    },
    "answers": ["A"],
    "explanation": "Data loss relates to reliability, while timing delays relate to performance efficiency. Together, they verify the platform’s resilience and timeliness under realistic load conditions.",
    "learning_objective": "TTA-4.2.2",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "207",
    "question_text": "A Technical Test Analyst must evaluate whether **security logging** in a financial application supports accountability and non-repudiation. Which test strategy provides the most valid verification?",
    "options": {
      "A": "Injecting invalid credentials and verifying log entries for user identity and timestamp",
      "B": "Simulating SQL injection to test data integrity protection",
      "C": "Disabling logging to test confidentiality",
      "D": "Running a performance load test on the authentication API"
    },
    "answers": ["A"],
    "explanation": "To test accountability and non-repudiation, auditors must verify that each action is traceable with authenticated identity and timestamps—achieved by validating detailed and tamper-proof log entries.",
    "learning_objective": "TTA-4.3.2",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "208",
    "question_text": "You are integrating a new **load-testing tool** into an existing CI/CD pipeline. During dry runs, test results vary significantly across executions. As the Technical Test Analyst, which factor should you analyze FIRST to ensure data reliability?",
    "options": {
      "A": "Network latency variations and test environment stability",
      "B": "License limitations of the tool",
      "C": "Differences in script parameter naming",
      "D": "Output formatting of generated reports"
    },
    "answers": ["A"],
    "explanation": "Performance test reproducibility depends on consistent test environments and stable network conditions. Variability in these factors leads to inconsistent metrics even if the tool works correctly.",
    "learning_objective": "TTA-5.1.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "209",
    "question_text": "After defect clustering analysis, you discover that 70% of system failures originate from two components. How should this information influence your next test cycle?",
    "options": {
      "A": "Reduce testing in these components since they’ve already failed",
      "B": "Increase test depth for these high-defect components while applying lightweight regression elsewhere",
      "C": "Distribute test effort evenly to avoid bias",
      "D": "Archive those components until design refactoring is complete"
    },
    "answers": ["B"],
    "explanation": "Defect clustering suggests that focused retesting and intensified testing in fault-prone components increases efficiency, aligning with Pareto analysis (80/20 rule) for risk-based prioritization.",
    "learning_objective": "TTA-6.1.4",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "210",
    "question_text": "In a continuous delivery project, automated unit and integration tests run with every build. However, several **performance regressions** were detected in production. Which improvement should the Technical Test Analyst recommend?",
    "options": {
      "A": "Integrate performance and reliability tests into the CI pipeline before deployment",
      "B": "Reduce the frequency of code commits to stabilize builds",
      "C": "Shift performance testing to post-release monitoring only",
      "D": "Focus solely on static code metrics to predict performance"
    },
    "answers": ["A"],
    "explanation": "Integrating non-functional (performance/reliability) checks into CI/CD ensures early detection of regressions, embodying the shift-left principle and continuous quality improvement.",
    "learning_objective": "TTA-5.2.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "211",
    "question_text": "During a root-cause analysis of escaped defects, you observe that **API response errors** were not detected during system testing because test data lacked edge-case payloads. As a Technical Test Analyst, which corrective action BEST prevents recurrence?",
    "options": {
      "A": "Enhance data design and generation procedures to include boundary and negative test data in automated suites",
      "B": "Increase execution frequency of existing tests",
      "C": "Focus future reviews on functional specifications only",
      "D": "Delegate test data creation entirely to developers"
    },
    "answers": ["A"],
    "explanation": "Including edge and negative data during automated API testing improves defect detection and data coverage. The issue originated from inadequate test data design rather than execution frequency.",
    "learning_objective": "TTA-6.2.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "202",
    "question_text": "You are testing a drone control module whose flight path logic depends on three atomic conditions: GPS_LOCKED, OBSTACLE_DETECTED, and BATTERY_OK. The decision is: IF (GPS_LOCKED AND BATTERY_OK) OR OBSTACLE_DETECTED THEN LAND_IMMEDIATELY. Due to certification rules, the system must comply with **DO-178C Level A**. Which test approach provides adequate coverage while maintaining test efficiency?",
    "options": {
      "A": "Decision testing with all combinations of conditions",
      "B": "Modified Condition/Decision Coverage (MC/DC) showing each atomic condition’s independent effect",
      "C": "Statement coverage of the landing decision logic",
      "D": "Multiple condition testing of all eight combinations"
    },
    "answers": ["B"],
    "explanation": "For airborne safety-critical systems, DO-178C Level A requires Modified Condition/Decision Coverage (MC/DC). It ensures that each condition independently affects the outcome, achieving the required rigor without full multiple-condition explosion.",
    "learning_objective": "TTA-2.8.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "203",
    "question_text": "A Technical Test Analyst must select test techniques to achieve the **most cost-effective coverage** for a control system that uses multiple nested IF-ELSE constructs, but time constraints prevent full MC/DC testing. Which combination of test techniques provides a justified compromise?",
    "options": {
      "A": "Statement coverage combined with decision testing on high-risk modules",
      "B": "Equivalence partitioning combined with path testing",
      "C": "Branch coverage on all code plus boundary value analysis",
      "D": "Use-case testing plus condition coverage"
    },
    "answers": ["A"],
    "explanation": "Statement coverage alone is insufficient, but combining it with decision testing on critical modules balances cost and thoroughness when MC/DC is infeasible. This hybrid approach targets logical branches most likely to fail.",
    "learning_objective": "TTA-2.3.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "204",
    "question_text": "You review the results of a static analysis report showing 80% of functions have high cyclomatic complexity and low cohesion. The project manager suggests delaying refactoring until after release. As a Technical Test Analyst, what should you recommend and why?",
    "options": {
      "A": "Agree; static findings are not critical to release quality",
      "B": "Disagree; refactoring should be prioritized because complexity and low cohesion increase future defect rates and testing costs",
      "C": "Agree only if full decision coverage tests exist",
      "D": "Disagree; postpone testing until code metrics improve"
    },
    "answers": ["B"],
    "explanation": "High cyclomatic complexity and low cohesion indicate poor maintainability and high defect probability. Addressing them early reduces long-term cost and improves test effectiveness; delaying increases risk.",
    "learning_objective": "TTA-3.2.3",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "205",
    "question_text": "During dynamic analysis of a **real-time trading system**, multiple short-duration CPU spikes were detected but without functional errors. What is the MOST likely interpretation, and what should be your next step?",
    "options": {
      "A": "Minor issue; continue testing since no functional defect occurred",
      "B": "Indicates potential performance bottlenecks—perform detailed profiling to isolate inefficient code segments",
      "C": "Suggest disabling garbage collection to reduce latency",
      "D": "Report as reliability defect related to memory leaks"
    },
    "answers": ["B"],
    "explanation": "CPU spikes under real-time constraints may lead to latency breaches. Profiling helps locate inefficient loops or synchronization issues causing transient peaks—vital in time-sensitive systems.",
    "learning_objective": "TTA-3.3.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "206",
    "question_text": "You are preparing non-functional tests for a **distributed IoT monitoring platform** that transmits continuous sensor data. The customer is concerned about **data loss and timing delays**. Which combination of test types addresses both issues effectively?",
    "options": {
      "A": "Reliability and performance efficiency testing",
      "B": "Security and maintainability testing",
      "C": "Compatibility and usability testing",
      "D": "Portability and recovery testing"
    },
    "answers": ["A"],
    "explanation": "Data loss relates to reliability, while timing delays relate to performance efficiency. Together, they verify the platform’s resilience and timeliness under realistic load conditions.",
    "learning_objective": "TTA-4.2.2",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "207",
    "question_text": "A Technical Test Analyst must evaluate whether **security logging** in a financial application supports accountability and non-repudiation. Which test strategy provides the most valid verification?",
    "options": {
      "A": "Injecting invalid credentials and verifying log entries for user identity and timestamp",
      "B": "Simulating SQL injection to test data integrity protection",
      "C": "Disabling logging to test confidentiality",
      "D": "Running a performance load test on the authentication API"
    },
    "answers": ["A"],
    "explanation": "To test accountability and non-repudiation, auditors must verify that each action is traceable with authenticated identity and timestamps—achieved by validating detailed and tamper-proof log entries.",
    "learning_objective": "TTA-4.3.2",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "208",
    "question_text": "You are integrating a new **load-testing tool** into an existing CI/CD pipeline. During dry runs, test results vary significantly across executions. As the Technical Test Analyst, which factor should you analyze FIRST to ensure data reliability?",
    "options": {
      "A": "Network latency variations and test environment stability",
      "B": "License limitations of the tool",
      "C": "Differences in script parameter naming",
      "D": "Output formatting of generated reports"
    },
    "answers": ["A"],
    "explanation": "Performance test reproducibility depends on consistent test environments and stable network conditions. Variability in these factors leads to inconsistent metrics even if the tool works correctly.",
    "learning_objective": "TTA-5.1.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "209",
    "question_text": "After defect clustering analysis, you discover that 70% of system failures originate from two components. How should this information influence your next test cycle?",
    "options": {
      "A": "Reduce testing in these components since they’ve already failed",
      "B": "Increase test depth for these high-defect components while applying lightweight regression elsewhere",
      "C": "Distribute test effort evenly to avoid bias",
      "D": "Archive those components until design refactoring is complete"
    },
    "answers": ["B"],
    "explanation": "Defect clustering suggests that focused retesting and intensified testing in fault-prone components increases efficiency, aligning with Pareto analysis (80/20 rule) for risk-based prioritization.",
    "learning_objective": "TTA-6.1.4",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "210",
    "question_text": "In a continuous delivery project, automated unit and integration tests run with every build. However, several **performance regressions** were detected in production. Which improvement should the Technical Test Analyst recommend?",
    "options": {
      "A": "Integrate performance and reliability tests into the CI pipeline before deployment",
      "B": "Reduce the frequency of code commits to stabilize builds",
      "C": "Shift performance testing to post-release monitoring only",
      "D": "Focus solely on static code metrics to predict performance"
    },
    "answers": ["A"],
    "explanation": "Integrating non-functional (performance/reliability) checks into CI/CD ensures early detection of regressions, embodying the shift-left principle and continuous quality improvement.",
    "learning_objective": "TTA-5.2.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "211",
    "question_text": "During a root-cause analysis of escaped defects, you observe that **API response errors** were not detected during system testing because test data lacked edge-case payloads. As a Technical Test Analyst, which corrective action BEST prevents recurrence?",
    "options": {
      "A": "Enhance data design and generation procedures to include boundary and negative test data in automated suites",
      "B": "Increase execution frequency of existing tests",
      "C": "Focus future reviews on functional specifications only",
      "D": "Delegate test data creation entirely to developers"
    },
    "answers": ["A"],
    "explanation": "Including edge and negative data during automated API testing improves defect detection and data coverage. The issue originated from inadequate test data design rather than execution frequency.",
    "learning_objective": "TTA-6.2.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "212",
    "question_text": "You are a Technical Test Analyst assigned to a medical device project using a third-party encryption library. During risk analysis, the Product Owner highlights potential exposure of patient data if the library fails to meet compliance standards. Which is the BEST risk mitigation action for the Technical Test Analyst?",
    "options": {
      "A": "Define additional performance efficiency tests for the encryption module",
      "B": "Plan static and dynamic security tests focusing on encryption boundary behavior",
      "C": "Add usability tests for all data entry forms to detect weak input validation",
      "D": "Postpone encryption testing until integration with the user interface is complete"
    },
    "answers": ["B"],
    "explanation": "The primary risk concerns data exposure due to noncompliant encryption. The Technical Test Analyst should mitigate this by planning both static analysis (code review of cryptographic calls) and dynamic security tests around encryption boundary behavior.",
    "learning_objective": "TTA-1.2.2",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "213",
    "question_text": "You are testing a decision-making algorithm that computes loan approval outcomes based on multiple input parameters (credit score, income, loan amount, and risk category). The project must demonstrate that each input independently affects the final decision. Which coverage criterion ensures this requirement is met?",
    "options": {
      "A": "Statement coverage",
      "B": "Decision coverage",
      "C": "Modified Condition/Decision Coverage (MC/DC)",
      "D": "Multiple condition coverage"
    },
    "answers": ["C"],
    "explanation": "MC/DC ensures each atomic condition can independently affect the overall decision outcome, which fulfills regulatory and business audit requirements for explainability in decision-making algorithms.",
    "learning_objective": "TTA-2.4.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "214",
    "question_text": "Static analysis results show that 30% of the code in a telecommunications subsystem has unreachable blocks and redundant variable assignments. The development manager argues that these are harmless since the system passes all unit tests. As the Technical Test Analyst, what is your BEST argument?",
    "options": {
      "A": "Unreachable and redundant code may indicate hidden defects and increase maintenance risk; they must be addressed before integration testing",
      "B": "Since unit tests pass, these findings can be deprioritized",
      "C": "Static analysis reports can be ignored if dynamic tests achieve full decision coverage",
      "D": "Unreachable code only affects readability, not system quality"
    },
    "answers": ["A"],
    "explanation": "Static analysis findings such as dead code and redundant variables point to poor control and data flow integrity, leading to higher defect probability during future maintenance. Addressing them early reduces future rework and improves quality.",
    "learning_objective": "TTA-3.2.2",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "215",
    "question_text": "During dynamic analysis of a multimedia streaming platform, you observe frequent buffer overflows under peak load, even though average throughput meets requirements. What should be your next step as a Technical Test Analyst?",
    "options": {
      "A": "Extend the test duration to observe whether performance remains stable over time",
      "B": "Conduct focused code profiling to locate memory allocation inefficiencies causing the buffer issues",
      "C": "Increase the concurrency of the test to simulate worse conditions",
      "D": "Report it as an expected condition caused by network latency"
    },
    "answers": ["B"],
    "explanation": "Buffer overflows under load are signs of poor memory handling. Profiling helps locate root causes such as inefficient allocation or missing deallocation logic, ensuring reliable performance under stress.",
    "learning_objective": "TTA-3.3.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "216",
    "question_text": "You are defining the non-functional test strategy for a **real-time navigation system**. The product must remain available with an update rate of less than one second under normal traffic conditions. Which two test types should be prioritized to verify these requirements?",
    "options": {
      "A": "Reliability testing and performance efficiency testing",
      "B": "Security testing and maintainability testing",
      "C": "Usability testing and compatibility testing",
      "D": "Portability testing and recovery testing"
    },
    "answers": ["A"],
    "explanation": "Reliability ensures continuous operation, while performance efficiency verifies update frequency and response time — both directly validate the system’s real-time behavior and availability constraints.",
    "learning_objective": "TTA-4.2.2",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "217",
    "question_text": "You are conducting **security testing** on a distributed payroll application. During testing, you discover that user session tokens are not invalidated after logout. What should your next step be as a Technical Test Analyst?",
    "options": {
      "A": "Report a defect since it violates session management best practices and may lead to session hijacking",
      "B": "Ignore the behavior since users can close the browser to end the session",
      "C": "Perform performance tests to confirm token expiration delay",
      "D": "Test other unrelated functionalities before reporting"
    },
    "answers": ["A"],
    "explanation": "Session tokens that persist after logout violate confidentiality and security best practices, creating risk for hijacking. Immediate reporting and retesting after remediation are essential.",
    "learning_objective": "TTA-4.3.2",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "218",
    "question_text": "Your organization is automating regression tests for a microservices architecture using a continuous integration pipeline. Intermittent test failures occur when services are deployed asynchronously. Which action should the Technical Test Analyst take?",
    "options": {
      "A": "Implement synchronization mechanisms or service health checks within the automation framework before test execution",
      "B": "Increase test execution speed to minimize environmental instability",
      "C": "Run tests manually to confirm intermittent behavior",
      "D": "Disable automated regression temporarily until all services stabilize"
    },
    "answers": ["A"],
    "explanation": "Intermittent failures in CI are typically caused by asynchronous service readiness. Implementing service health checks or synchronization waits stabilizes automated execution.",
    "learning_objective": "TTA-5.2.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "219",
    "question_text": "A Technical Test Analyst reviews the defect trend chart over three releases. Although the number of executed tests increased, defect detection rates dropped sharply. What is the MOST likely interpretation, and what should be done?",
    "options": {
      "A": "The system quality has improved; maintain the same strategy",
      "B": "Tests are redundant or poorly targeted; review and optimize test design and risk prioritization",
      "C": "The defect management tool is underreporting defects; recalibrate reporting metrics",
      "D": "Developers are fixing defects faster, reducing reported numbers"
    },
    "answers": ["B"],
    "explanation": "A decreasing detection rate despite higher execution volume often signals inefficiency or redundancy in test design. The TTA should refine test coverage and ensure focus on risk-prone areas.",
    "learning_objective": "TTA-6.1.4",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "220",
    "question_text": "After conducting a root-cause analysis of several production defects, you find that missing boundary test cases were a common factor. How should this outcome guide future process improvement?",
    "options": {
      "A": "Enhance test design reviews to verify boundary coverage for all numerical input fields",
      "B": "Increase system-level exploratory testing sessions",
      "C": "Adopt static analysis tools to catch data flow anomalies automatically",
      "D": "Reduce regression testing frequency to focus on new features"
    },
    "answers": ["A"],
    "explanation": "Root-cause analysis identified inadequate boundary coverage. The best corrective action is to strengthen review checklists to ensure thorough boundary value test design.",
    "learning_objective": "TTA-6.2.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "221",
    "question_text": "Your organization is implementing defect classification metrics to support continuous improvement. The Technical Test Analyst notices that most high-severity defects originate during requirements review, not execution. What process improvement should be prioritized?",
    "options": {
      "A": "Strengthen early static analysis and formal review procedures",
      "B": "Reduce test execution time to catch defects earlier",
      "C": "Add more integration-level tests to the regression suite",
      "D": "Delay defect classification until post-release analysis"
    },
    "answers": ["A"],
    "explanation": "If high-severity defects originate during requirements review, the process weakness lies in early analysis. Enhancing static analysis and formal review rigor prevents defects before implementation.",
    "learning_objective": "TTA-6.2.3",
    "klevel": "K4",
    "points": 3
  },
   {
    "question_id": "222",
    "question_text": "You are defining a risk-based test strategy for an **autonomous navigation system**. Which TWO actions should the Technical Test Analyst take to ensure risks are properly addressed in test planning?",
    "options": {
      "A": "Map identified product risks to specific test conditions and techniques",
      "B": "Delegate risk prioritization entirely to the project manager",
      "C": "Align test intensity with risk likelihood and impact",
      "D": "Focus only on functional risks since non-functional risks are handled separately"
    },
    "answers": ["A", "C"],
    "explanation": "A) Correct: Mapping risks to test conditions ensures traceability. C) Correct: Risk-based testing adjusts effort based on impact and likelihood. B and D are incorrect — risk prioritization and non-functional risks are also part of the TTA’s responsibility.",
    "learning_objective": "TTA-1.2.2",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "223",
    "question_text": "You are designing white-box tests for a **complex decision module**. Which TWO test techniques provide effective structural coverage without exhaustive testing?",
    "options": {
      "A": "Decision coverage",
      "B": "Modified Condition/Decision Coverage (MC/DC)",
      "C": "Path coverage",
      "D": "Statement coverage"
    },
    "answers": ["A", "B"],
    "explanation": "Decision coverage ensures each decision outcome is tested, while MC/DC confirms that each atomic condition independently influences the decision. Path coverage is exhaustive and impractical, while statement coverage is too shallow.",
    "learning_objective": "TTA-2.4.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "224",
    "question_text": "Static analysis of a control system shows several **data flow anomalies**. Which TWO examples correctly represent data flow anomalies?",
    "options": {
      "A": "A variable is used before it is defined",
      "B": "A variable is defined but never used",
      "C": "A variable is declared within a nested loop",
      "D": "A variable is used and then redefined before being output"
    },
    "answers": ["A", "B"],
    "explanation": "A) and B) represent data flow anomalies — using variables before definition and defining without use both indicate potential logical or design issues. C and D describe code structure or style, not anomalies.",
    "learning_objective": "TTA-3.2.2",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "225",
    "question_text": "You are executing dynamic analysis on an **embedded control unit**. Which TWO findings would indicate a potential **real-time performance defect**?",
    "options": {
      "A": "Increased response time under constant input conditions",
      "B": "Memory utilization remains stable throughout the test",
      "C": "Thread synchronization delays during interrupt handling",
      "D": "CPU usage decreases as workload increases"
    },
    "answers": ["A", "C"],
    "explanation": "A) Rising response time indicates timing inefficiency. C) Synchronization delays reveal scheduling or locking issues. B shows stability, and D is an abnormal trend but not specific evidence of real-time failure.",
    "learning_objective": "TTA-3.3.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "226",
    "question_text": "A Technical Test Analyst is preparing non-functional tests for a **mission-critical healthcare platform**. Which TWO quality characteristics should receive the highest testing priority?",
    "options": {
      "A": "Security",
      "B": "Reliability",
      "C": "Portability",
      "D": "Usability"
    },
    "answers": ["A", "B"],
    "explanation": "Security ensures patient data confidentiality, and reliability ensures continuous safe operation — both are vital in healthcare systems. Portability and usability, though important, are secondary priorities here.",
    "learning_objective": "TTA-4.2.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "227",
    "question_text": "During **security testing**, you discover that the application fails to enforce role-based access control (RBAC) and also transmits sensitive data over HTTP. Which TWO actions are appropriate next steps?",
    "options": {
      "A": "Report both issues as critical security defects",
      "B": "Verify if other modules enforce proper access restrictions",
      "C": "Ignore the HTTP issue since it’s unrelated to authentication",
      "D": "Perform performance tests to measure impact of security fixes"
    },
    "answers": ["A", "B"],
    "explanation": "A) Both findings are severe confidentiality and authorization violations. B) Checking other modules helps determine if the problem is systemic. C and D don’t directly address the security risk.",
    "learning_objective": "TTA-4.3.2",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "228",
    "question_text": "You are evaluating **two candidate tools** for test automation in a CI/CD pipeline. Which TWO technical factors should guide the final selection?",
    "options": {
      "A": "Compatibility with the application’s technology stack and APIs",
      "B": "Ability to integrate with version control and build systems",
      "C": "Total number of GUI test cases already automated",
      "D": "The tool’s graphical interface style and color theme"
    },
    "answers": ["A", "B"],
    "explanation": "A) Integration and compatibility are essential for CI/CD automation reliability. B) Seamless linkage with build and version control ensures maintainable automation. C and D are irrelevant selection criteria.",
    "learning_objective": "TTA-5.1.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "229",
    "question_text": "A Technical Test Analyst observes repeated test automation failures due to **environment configuration drift**. Which TWO measures can effectively prevent such instability?",
    "options": {
      "A": "Containerize the test environment using consistent infrastructure as code",
      "B": "Run automation scripts manually for each new build",
      "C": "Integrate environment setup scripts into the CI pipeline",
      "D": "Reduce automation scope to high-priority smoke tests only"
    },
    "answers": ["A", "C"],
    "explanation": "A) Containerization ensures consistent environments. C) Automating setup in CI eliminates manual drift. B and D treat symptoms, not the root cause.",
    "learning_objective": "TTA-5.2.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "230",
    "question_text": "After analyzing defect distribution over five sprints, you find that most critical defects occur during **integration testing** and relate to **interface mismatches**. Which TWO process improvements should be recommended?",
    "options": {
      "A": "Introduce earlier API contract validation or service virtualization",
      "B": "Increase manual regression testing frequency post-integration",
      "C": "Conduct static interface reviews during component development",
      "D": "Postpone integration testing until all features are complete"
    },
    "answers": ["A", "C"],
    "explanation": "A) Early validation of interface contracts reduces mismatch defects. C) Static interface reviews prevent design-level inconsistencies. B and D delay detection and increase cost of rework.",
    "learning_objective": "TTA-6.1.4",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "231",
    "question_text": "A Technical Test Analyst is performing root cause analysis on recurring production defects. The investigation reveals that test data did not reflect realistic production edge cases, and reviewers missed several design inconsistencies. Which TWO preventive actions address these root causes?",
    "options": {
      "A": "Enhance test data design using production data patterns and boundary analysis",
      "B": "Strengthen technical review checklists to include interface consistency checks",
      "C": "Reduce review effort to accelerate development velocity",
      "D": "Perform performance testing earlier in the project"
    },
    "answers": ["A", "B"],
    "explanation": "A) Better test data coverage prevents false confidence. B) Improved reviews catch early design inconsistencies. C and D do not directly address the identified root causes.",
    "learning_objective": "TTA-6.2.1",
    "klevel": "K4",
    "points": 3
  },
   {
    "question_id": "232",
    "question_text": "You are reviewing the following pseudo-code for white-box testing:\n\n```\nIF (x > 10 OR y < 5) THEN\n   IF (z = 0) THEN\n      result = A\n   ELSE\n      result = B\n   ENDIF\nELSE\n   result = C\nENDIF\n```\n\nWhich TWO statements are TRUE regarding achieving **Modified Condition/Decision Coverage (MC/DC)**?",
    "options": {
      "A": "At least one test case must show that changing 'x > 10' alone affects the outcome",
      "B": "At least one test case must vary both 'x' and 'y' simultaneously to observe the decision outcome",
      "C": "A minimum of four test cases are required to achieve full MC/DC for this code",
      "D": "Statement coverage can be achieved with fewer tests than MC/DC coverage"
    },
    "answers": ["A", "D"],
    "explanation": "A) Correct: MC/DC requires showing that each condition independently affects the decision. D) Correct: Statement coverage is less demanding. B) violates independence (two conditions vary together), and C) overestimates — typically 3–4 tests suffice but not always required by rule.",
    "learning_objective": "TTA-2.4.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "233",
    "question_text": "You are analyzing a **control flow graph** for a module. It has 10 nodes and 15 edges. One entry and one exit point exist. Based on this, which TWO conclusions are correct?",
    "options": {
      "A": "The cyclomatic complexity of the module is 6",
      "B": "At least 6 linearly independent paths exist",
      "C": "Decision coverage requires fewer test cases than path coverage",
      "D": "Achieving path coverage requires executing 15 test cases"
    },
    "answers": ["A", "B"],
    "explanation": "Cyclomatic complexity = E - N + 2 = 15 - 10 + 2 = 7. However, with one entry/exit, complexity = 7; so at least 7 independent paths exist. B) is valid for independence count. C) is true generally but not deducible directly; D) is incorrect as number of paths is not equal to edges.",
    "learning_objective": "TTA-2.3.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "234",
    "question_text": "A dynamic analysis tool shows the following runtime results for a C program:\n\n| Metric | Value |\n|---------|-------|\n| Memory leaks detected | 3 |\n| Null pointer dereferences | 0 |\n| Average heap usage | 92% |\n| CPU utilization | 55% |\n\nWhich TWO conclusions are most appropriate for the Technical Test Analyst?",
    "options": {
      "A": "Memory leaks are present and should be investigated via code profiling",
      "B": "Null pointer safety is acceptable in current runs",
      "C": "CPU utilization indicates potential algorithmic inefficiency",
      "D": "Heap usage is within optimal range and poses no risk"
    },
    "answers": ["A", "B"],
    "explanation": "A) Memory leaks must be analyzed via profiling. B) No dereference errors appeared, indicating stable pointer handling. C) 55% CPU does not indicate inefficiency, and D) 92% heap use is high and risky.",
    "learning_objective": "TTA-3.3.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "235",
    "question_text": "The following **static analysis summary** is produced for a Java class:\n\n| Metric | Result |\n|---------|--------|\n| Cyclomatic Complexity | 16 |\n| Lines of Code | 210 |\n| Coupling Between Objects (CBO) | 12 |\n| Lack of Cohesion (LCOM) | 0.85 |\n\nWhich TWO actions should the Technical Test Analyst recommend?",
    "options": {
      "A": "Suggest refactoring the class into smaller components to improve cohesion and reduce complexity",
      "B": "Increase test coverage to compensate for maintainability risks",
      "C": "Ignore findings since LCOM < 1 is acceptable",
      "D": "Reduce decision coverage to simplify test execution"
    },
    "answers": ["A", "B"],
    "explanation": "A) High complexity and low cohesion indicate maintainability risk — refactor. B) Additional testing mitigates short-term risk. C) LCOM of 0.85 is poor, and D) reducing coverage is not a solution.",
    "learning_objective": "TTA-3.2.3",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "236",
    "question_text": "You receive the following **performance test graph** showing response times under increasing user load:\n\n```\nUsers: 100 → 200 → 400 → 800 → 1600\nResponse time (ms): 300 → 320 → 380 → 850 → 2500\n```\n\nWhich TWO conclusions are valid?",
    "options": {
      "A": "The system exhibits a performance threshold around 800 users",
      "B": "Response degradation is linear, indicating scalability readiness",
      "C": "Performance tuning should focus on database or I/O bottlenecks",
      "D": "The system meets scalability expectations for expected user loads"
    },
    "answers": ["A", "C"],
    "explanation": "Response time grows exponentially beyond 800 users, suggesting a scalability threshold. Likely causes include database contention or I/O latency. Linear degradation (B) is false, and (D) indicates unmet expectations.",
    "learning_objective": "TTA-4.2.4",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "237",
    "question_text": "After running **load tests**, the Technical Test Analyst examines system logs and observes:\n\n- 502 Gateway errors during peak load\n- Increased response times before errors\n- No memory or CPU resource exhaustion\n\nWhich TWO root causes should be investigated?",
    "options": {
      "A": "Connection pool size limits in the application server",
      "B": "Thread synchronization deadlocks",
      "C": "Network timeouts or proxy misconfiguration",
      "D": "Memory leak in heap allocation"
    },
    "answers": ["A", "C"],
    "explanation": "502 errors often indicate upstream connectivity failures, commonly due to connection pool exhaustion (A) or proxy timeouts (C). Deadlocks or leaks would show resource starvation, which is not observed here.",
    "learning_objective": "TTA-4.2.4",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "238",
    "question_text": "A code coverage report for a module shows:\n\n| Metric | Value |\n|---------|-------|\n| Statement Coverage | 100% |\n| Decision Coverage | 60% |\n| Condition Coverage | 40% |\n\nWhich TWO actions should the Technical Test Analyst recommend?",
    "options": {
      "A": "Design additional tests to increase decision and condition coverage",
      "B": "Conclude that all logic paths are fully tested since statement coverage is 100%",
      "C": "Prioritize testing of untested decision branches",
      "D": "Remove redundant test cases to save effort"
    },
    "answers": ["A", "C"],
    "explanation": "Full statement coverage does not ensure decision logic has been exercised. A) and C) are correct: add tests for untested branches and conditions to achieve thorough logical coverage.",
    "learning_objective": "TTA-2.3.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "239",
    "question_text": "The following output is observed in a **SQL injection test** log:\n\n```\nInput: user=' OR '1'='1';--\nResponse: 200 OK\nUser authenticated successfully\n```\n\nWhich TWO actions are appropriate next steps for the Technical Test Analyst?",
    "options": {
      "A": "Report a critical security vulnerability due to successful injection",
      "B": "Perform further testing to identify the extent of SQL injection impact",
      "C": "Ignore since this is expected test input for boundary conditions",
      "D": "Run stress tests to check load tolerance"
    },
    "answers": ["A", "B"],
    "explanation": "Successful SQL injection means authentication bypass. Report immediately (A) and extend testing (B) to assess how deep the vulnerability goes. C and D are unrelated.",
    "learning_objective": "TTA-4.3.2",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "240",
    "question_text": "A defect trend chart shows:\n\n| Iteration | Tests Executed | Defects Found |\n|------------|----------------|----------------|\n| Sprint 1 | 200 | 40 |\n| Sprint 2 | 250 | 20 |\n| Sprint 3 | 300 | 5 |\n\nWhich TWO interpretations are plausible for the Technical Test Analyst?",
    "options": {
      "A": "The defect detection rate is dropping, possibly indicating weaker test effectiveness",
      "B": "System stability is improving as major defects are already removed",
      "C": "The test process is unreliable and should be abandoned",
      "D": "Defect clustering indicates new features are not being tested"
    },
    "answers": ["A", "B"],
    "explanation": "A) A declining rate might mean tests are not exposing new defects. B) It can also reflect improved software quality. Both interpretations require correlation with release data before conclusion.",
    "learning_objective": "TTA-6.1.4",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "241",
    "question_text": "You are analyzing test automation logs that show 20% of scripts failed due to 'element not found' errors after UI changes. Which TWO corrective actions are most effective?",
    "options": {
      "A": "Introduce robust locators and page object model abstraction",
      "B": "Increase test data variability in automation scripts",
      "C": "Implement versioned UI mapping aligned with build releases",
      "D": "Disable flaky tests to improve overall pass rate"
    },
    "answers": ["A", "C"],
    "explanation": "A) Page object abstraction reduces locator fragility. C) Versioned UI maps ensure automation stays in sync with UI updates. B and D don’t resolve root cause; they mask or sidestep it.",
    "learning_objective": "TTA-5.2.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "242",
    "question_text": "You are reviewing a static analysis report for a C++ module handling sensor data. The tool flags several warnings for ‘variable used before initialization’ and ‘unreachable return statements’. Which ONE recommendation is most appropriate for the Technical Test Analyst?",
    "options": {
      "A": "Recommend code inspection to confirm uninitialized variable usage and remove dead code",
      "B": "Ignore these findings because they are compiler-level optimizations",
      "C": "Focus testing only on dynamic analysis since static warnings are non-critical",
      "D": "Increase statement coverage to validate compiler optimizations"
    },
    "answers": ["A"],
    "explanation": "Uninitialized variables and unreachable statements indicate control-flow and data-flow anomalies. A) is correct because manual inspection validates them before dynamic execution. Others misunderstand static analysis purpose.",
    "learning_objective": "TTA-3.2.2",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "243",
    "question_text": "A decision table for tax calculation has four conditions and sixteen possible rules. Only nine rules are implemented in code. Which TWO actions should the Technical Test Analyst take?",
    "options": {
      "A": "Investigate missing rules to verify whether they represent unreachable or invalid combinations",
      "B": "Create test cases for all sixteen rules to achieve completeness",
      "C": "Perform pairwise testing instead of full combination coverage",
      "D": "Mark unimplemented rules as 'not applicable' after business review"
    },
    "answers": ["A", "D"],
    "explanation": "A) Check missing rules for business relevance. D) If confirmed invalid, document them formally. Full 16-rule testing (B) may waste effort; C) changes technique rather than addressing risk.",
    "learning_objective": "TTA-2.7.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "244",
    "question_text": "You are analyzing this pseudo-code fragment:\n\n```\nIF (A AND B) OR (C AND NOT D) THEN\n   executeTask()\nENDIF\n```\n\nWhich TWO statements are TRUE regarding test design for decision coverage?",
    "options": {
      "A": "At least two tests are required to achieve decision coverage",
      "B": "At least four tests are required to achieve full MC/DC coverage",
      "C": "A single test with A=B=C=D=TRUE achieves both statement and decision coverage",
      "D": "Changing D alone should be shown to affect the decision outcome under MC/DC"
    },
    "answers": ["A", "D"],
    "explanation": "A) Decision coverage needs one TRUE and one FALSE outcome. D) Under MC/DC, each condition—including D—must independently affect the result. B) may require more but isn’t fixed; C) achieves only statement coverage.",
    "learning_objective": "TTA-2.4.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "245",
    "question_text": "You receive a **code coverage report**:\n\n| Coverage Type | Percentage |\n|----------------|-------------|\n| Statement | 95% |\n| Decision | 80% |\n| Condition | 60% |\n\nWhich ONE interpretation is most accurate?",
    "options": {
      "A": "The current tests do not exercise all logical paths; more condition tests are needed",
      "B": "Full decision coverage implies full condition coverage, so this result is inconsistent",
      "C": "Statement coverage ensures sufficient logical testing; no improvement is needed",
      "D": "Condition coverage cannot be lower than decision coverage"
    },
    "answers": ["A"],
    "explanation": "Condition coverage being lower indicates that some Boolean sub-conditions never evaluated to both TRUE and FALSE. Logical completeness is missing, requiring extra condition-focused tests.",
    "learning_objective": "TTA-2.3.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "246",
    "question_text": "Dynamic analysis shows intermittent latency spikes in a messaging server, though CPU and memory remain stable. The log reveals repeated connection re-establishments. Which TWO potential root causes should be investigated?",
    "options": {
      "A": "Network socket timeout configuration",
      "B": "Inefficient loop computation in message handler",
      "C": "Garbage collection frequency",
      "D": "Connection pool exhaustion under load"
    },
    "answers": ["A", "D"],
    "explanation": "A) and D) relate to connection churn and reconnection overhead, matching log evidence. B) would affect CPU, and C) would manifest as memory fluctuations.",
    "learning_objective": "TTA-3.3.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "247",
    "question_text": "A performance test produces this throughput chart:\n\nUsers: 100→200→400→800\nTransactions/sec: 220→420→800→810\n\nWhich TWO interpretations are correct?",
    "options": {
      "A": "System throughput plateaus near 800 users, indicating a bottleneck",
      "B": "Performance efficiency scales linearly across all loads",
      "C": "Bottleneck investigation should start with database or I/O subsystems",
      "D": "The system meets infinite scalability expectations"
    },
    "answers": ["A", "C"],
    "explanation": "Throughput stabilizes despite higher load (A), signaling a saturation point. I/O or DB limits often cause this (C). Linear scaling (B) and infinite scalability (D) are false.",
    "learning_objective": "TTA-4.2.4",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "248",
    "question_text": "A Technical Test Analyst examines **security scan results** showing outdated third-party libraries and missing input validation. Which ONE next step is MOST appropriate?",
    "options": {
      "A": "Prioritize patching outdated libraries and perform input-fuzzing to validate remediation",
      "B": "Defer patching since the issue is non-functional",
      "C": "Execute performance tests to confirm throughput after patching",
      "D": "Close the issue because dependency management is handled by operations"
    },
    "answers": ["A"],
    "explanation": "Outdated components and missing validation represent direct vulnerability vectors. Immediate patching and fuzz testing confirm secure behavior post-remediation.",
    "learning_objective": "TTA-4.3.2",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "249",
    "question_text": "During automation execution, 30% of UI tests fail after a layout redesign. The errors report 'element not interactable'. Which TWO actions should the Technical Test Analyst prioritize?",
    "options": {
      "A": "Refactor selectors using a page-object model to abstract UI changes",
      "B": "Temporarily disable failing scripts to stabilize CI pipeline",
      "C": "Add wait conditions or synchronization to handle asynchronous rendering",
      "D": "Convert UI tests to API tests without validation changes"
    },
    "answers": ["A", "C"],
    "explanation": "A) Abstract locators reduce maintenance cost. C) Proper waits handle timing issues. B) hides problems, and D) changes test intent.",
    "learning_objective": "TTA-5.2.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "250",
    "question_text": "A defect trend chart shows high defect density in module X over three iterations. Root-cause analysis reveals poor input validation logic. Which ONE improvement should the Technical Test Analyst recommend?",
    "options": {
      "A": "Strengthen unit tests and reviews focusing on input validation paths",
      "B": "Increase exploratory testing in unrelated modules",
      "C": "Reduce regression testing frequency to save effort",
      "D": "Ignore the trend since defect discovery is expected to decline naturally"
    },
    "answers": ["A"],
    "explanation": "Focusing validation tests and static reviews on module X addresses the repeated source of faults, improving prevention and test efficiency.",
    "learning_objective": "TTA-6.2.1",
    "klevel": "K4",
    "points": 3
  },
  {
    "question_id": "251",
    "question_text": "You are evaluating historical defect data and notice that 70% of post-release defects originated from insufficient integration testing. Which TWO measures will most effectively prevent recurrence?",
    "options": {
      "A": "Introduce service virtualization to enable earlier integration testing",
      "B": "Add additional usability tests after release",
      "C": "Strengthen static interface analysis and contract validation",
      "D": "Increase system-level exploratory testing sessions only"
    },
    "answers": ["A", "C"],
    "explanation": "A) and C) directly improve integration reliability by enabling early validation and detecting interface mismatches. Usability or exploratory focus doesn’t address integration causes.",
    "learning_objective": "TTA-6.1.4",
    "klevel": "K4",
    "points": 3
  }


]
